---
title: "Comparative RNA-Seq Analysis"
author: "Thomas Nicholson"
date: "14/09/2020"
output: 
  html_document:
    toc: true
runtime: shiny
---
##setup
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# suppressMessages(library(comparativeSRA))
library(tidyverse)
library(VennDiagram)
library(shiny)
library(ggplot2)
library(viridis)
library(RColorBrewer)
#library(stringr)
#library(plyr)
library(devtools)
#library(tidyr)
library(shinyjs)
library(shinyWidgets)
library(DT)
library(lubridate)
library(dplyr)
library(svglite)
library(genoPlotR)
library(drake)
library(ape)
library(Biostrings)
library(ggtree)
# library(treeio)
library(geiger)
library(ROSE)
library(reshape2)
library(igraph)
library("viridis") 
library(randomForest)
library(ROCR)
library(corrplot)

library(reticulate)
library(rjson)
filePath <- "~/phd/RNASeq/r_files/"
# use_python("/Users/thomasnicholson/anaconda3/bin/python")
# use_condaenv("comparativesrna")
```

```{r functions, include=F}
plotKnownvsConserved <- function(dat, columns, not_zero = F){
  dat <- dat%>%mutate(conserved = F)
if(not_zero){
  for(i in 1:nrow(dat)){
    dat[i, ncol(dat)] <- ("1" %in% dat[i, columns])
    if(dat[i, ncol(dat)] == F){
    dat[i, ncol(dat)] <- ("0-1" %in% dat[i, columns])
    }

  }
}else{
  for(i in 1:nrow(dat)){
    dat[i, ncol(dat)] <- ("1" %in% dat[i, columns])
  }
}


  conservedSet <- dat%>%filter(conserved)
  knownSet <- dat%>%filter(new_feature == F)

  vennSet <- conservedSet%>%bind_rows(knownSet)%>%unique()



  area1 <- nrow(subset(vennSet, conserved == T))
  area2 <- nrow(subset(vennSet, new_feature == F))
  cross.area <- nrow(subset(vennSet, new_feature == F & conserved == T))

  grid.newpage()
  draw.pairwise.venn(area1 = area1, area2 = area2, cross.area = cross.area, fill = c("blue", "red"),
                     scaled = T,
                     #cat.default.pos= "text",
                     #cat.pos = c(-50, 50),
                     #category = c("Conserved and Expressed", "Known")
                     category = c("", "")
  )
}





assignConservationLevel <- function(ids_lookup, main_col = 7, genera_col, species_col, any_col = c(7:ncol(ids_lookup))){
  ids_lookup <- ids_lookup%>%mutate(type = "")
  for(i in 1:nrow(ids_lookup)){
    if("1" %in% ids_lookup[i, main_col]){
      ids_lookup[i, ncol(ids_lookup)] <- "Family_1"
    }else if("0-1" %in% ids_lookup[i, main_col]){
      ids_lookup[i, ncol(ids_lookup)] <- "Family_0-1"
    }else if("1" %in% ids_lookup[i, genera_col]){
      ids_lookup[i, ncol(ids_lookup)] <- "Genera_1"
    }else if("0-1" %in% ids_lookup[i, genera_col]){
      ids_lookup[i, ncol(ids_lookup)] <- "Genera_0-1"
    }else if("1" %in% ids_lookup[i, species_col]){
      ids_lookup[i, ncol(ids_lookup)] <- "Species_1"
    }else if("0-1" %in% ids_lookup[i, species_col]){
      ids_lookup[i, ncol(ids_lookup)] <- "Species_0-1"
    }else if("1" %in% ids_lookup[i, any_col]){
      ids_lookup[i, ncol(ids_lookup)] <- "Species_1"
    }else if("0-1" %in% ids_lookup[i, any_col]){
      ids_lookup[i, ncol(ids_lookup)] <- "Species_0-1"
    }

  }
  return(ids_lookup)
}
firstup <- function(x) {
  substr(x, 1, 1) <- toupper(substr(x, 1, 1))
  x
}

cumulativeCounts <- function(dists, smooth = T){

  groups <- unique(dists$group)
  for(i in groups){
    dat <- dists %>% filter(group == i)
    dat <- dat %>% mutate(count = 1) %>% 
    arrange(-max_dist) %>% group_by(group) %>% 
    mutate(cumulativeCount = cumsum(count)) %>% ungroup() %>% 
    group_by(group, max_dist) %>% summarise(cumulative_prop = max(cumulativeCount)/ nrow(dat))
    
    if(smooth){
      dat <- as.data.frame(spline(x = dat$max_dist,y =  dat$cumulative_prop))
    }
    dat <- dat %>% ungroup() %>% mutate(group = i)
    if(exists('combinedDat')){
      combinedDat <- combinedDat %>% bind_rows(dat)
    }else{
      combinedDat <- dat 
    }
  }
  return(combinedDat)  

}

```

```{python pysetup, include=F}
import sys
from Bio import SeqIO
import Bio
import pandas as pd
import seaborn as sns
import os
import random
#from BCBio import GFF
from Bio.Seq import Seq
import matplotlib.pyplot as plt
import numpy as np
from pylab import savefig
from matplotlib.pyplot import figure
import json
run_all = False
```

```{python py_functions, include=F}
def package_test():
	print("comparativesrna.py loaded")

def file_len(fname):
    with open(fname) as f:
        for i, l in enumerate(f):
            pass
    return i


def intergenicSequence(accession, my_seq, shuffled):
    start = 0
    end = 0
    random_seq = Seq("AG", generic_dna)
    try:

        in_handle = open("/Users/thomasnicholson/phd/RNASeq/sequences/%s.gff" % accession)
        for rec in GFF.parse(in_handle):
            for feature in rec.features:
                qualifiers = feature.qualifiers
                try:
                    location = feature.location
                    end = location.start
                    intergeneicSeq = my_seq[start:end]
                    if shuffled == True:
                        shuffledSeq = ''.join(random.sample(str(intergeneicSeq), len(intergeneicSeq)))
                        random_seq = random_seq + shuffledSeq
                    else:
                        random_seq = random_seq + intergeneicSeq
                    start = location.end
                    #print(len(random_seq))
                except KeyError:
                    pass

        in_handle.close()

    except IOError:
        print("/Users/thomasnicholson/phd/RNASeq/sequences/%s.gff not found" % accession)
        sys.exit(2)
    return random_seq


def intergenicPositions(accession):
    start = 0
    end = 0
    positions = [0]
    try:

        in_handle = open("/Users/thomasnicholson/phd/RNASeq/sequences/%s.gff" % accession)
        for rec in GFF.parse(in_handle):
            i = 0
            for feature in rec.features:
                qualifiers = feature.qualifiers
                try:
                    qualifiers['gene_biotype']
                except KeyError:
                    continue
                try:
                    i += 1
                    location = feature.location
                    end = location.start - 49
                    if end < start:
                        continue
                    tmpPos = range(start,end)
                    positions = positions + tmpPos
                    start = location.end + 50
                except KeyError:
                    pass

        in_handle.close()

    except IOError:
        print("/Users/thomasnicholson/phd/RNASeq/sequences/%s.gff not found" % accession)
        sys.exit(2)
    return positions


def makeoutputdirectory(write_path):
    if os.path.isdir(write_path) == False:
        try:
            os.mkdir(write_path)
        except OSError:
            print("Creation of the directory %s failed" % write_path)
            sys.exit(2)
    directory = os.listdir(write_path)
    if len(directory) != 0:
        print("Examples of files in %s" % write_path)
        print(directory[0:4])
        query_user = input("%s is not an empty directory. Continue anyway y/n (this may write over existing files): " % write_path)
        if query_user == "y":
            print("Using %s as directory" % write_path)
        else:
            print("Exiting script")
            sys.exit(2)


def concatenateSequence(fastaFile):
    my_seq = fastaFile[0].seq
    i = 0
    for seq in fastaFile:
        if i == 0:
            i += 1
            continue
        i += 1
        my_seq = my_seq + seq.seq
    return my_seq


def selectRandomLocation(inFile, positions,fileLength, random_seq, accession):

    randomFile = open("/Users/thomasnicholson/phd/RNASeq/new_calls/random/python_version_1/%s_random_no_shuffle_new_calls.txt" % accession, "w")
    randomFile.write("start\tend\tstrand\tsequence\n")

    shuffledIndexes = random.sample(positions, fileLength)
    seqLength = len(random_seq)
    seqIndexes = random.sample(range(0,seqLength), fileLength)

    srnaLengths = []
    srnaStrands = []
    srnaIDs = []
    i = 0
    for line in inFile:
        i += 1
        words = line.rstrip()
        words = words.split("\t")
        start = words[2]
        try:
            start = int(start)
        except ValueError:
            continue
        end = words[3]
        end = int(end)
        srna = words[-1]
        srna_length = end - start
        srnaLengths.append(srna_length)
        strand = words[4]
        srnaStrands.append(strand)
        srnaIDs.append(srna)
    for i in range(0,len(shuffledIndexes)):
        index = shuffledIndexes[i]
        length = srnaLengths[i]
        strand = srnaStrands[i]
        seqIndex = seqIndexes[i]
        srna = srnaIDs[i]
        if strand == "+":
            start = index
            end = start + length
            seqStart = seqIndex
            seqEnd  = seqStart + length
        else:
            end = index
            start = end - length
            seqEnd = seqIndex
            seqStart  = seqEnd - length
        if start < 1:
            continue
        if end < 1:
            continue
        if length < 50:
            continue
        if length > 500:
            continue
        if seqStart < 1:
            continue
        if seqEnd < 1:
            continue
        if seqEnd > seqLength:
            continue
        if seqStart > seqLength:
            continue
        sequence  = random_seq[seqStart:seqEnd]
        randomFile = open("/Users/thomasnicholson/phd/RNASeq/new_calls/random/python_version_1/%s_random_no_shuffle_new_calls.txt" % accession, "a")
        randomFile.write("%s\t%s\t%s\t%s\n" % (start, end, strand, sequence))

        srna_type = "random"

        write_path = "/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/negative_control_no_shuffle"
        srnaFile = open("%s/%s.fna" % (write_path, accession), "a")
        srnaFile.write(">%s[%s-%s,%s,%s]\n%s\n" % (srna, seqStart, seqEnd, strand, srna_type, sequence))


def getreaddepths(accession):
    try:
        df = None
        for filename in os.listdir("/Users/thomasnicholson/phd/RNASeq/plot_files/%s/" % accession):
            filesize = os.path.getsize(
                "/Users/thomasnicholson/phd/RNASeq/plot_files/%s/%s" % (accession, filename))
            if filesize == 0:
                print("No data in %s" % filename)
                continue
            plotFile = pd.read_csv(
                os.path.join("/Users/thomasnicholson/phd/RNASeq/plot_files/%s/" % accession, filename),
                sep='\t', header=None)
            print(filename)
            plotFile['selected'] = plotFile.iloc[:].max(axis=1)
            tmpDf = plotFile.iloc[:, 2]
            if df is not None:
                df = pd.concat([df.reset_index(drop=True), tmpDf], axis=1)
            else:
                df = tmpDf
        dfOut = df
        dfOut['mean'] = df.iloc[:].mean(axis=1)
        dfOut['median'] = df.median(axis=1)
        dfOut['max'] = df.max(axis=1)
        return dfOut

    except IOError:
        print("Cannot open a file in /Users/thomasnicholson/phd/RNASeq/plot_files/%s/" % accession)


def sRNA_read_depths(inFile, read_depths_df,accession, random):
    if random == False:
        outFile  = open("/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/read_depths/%s_read_depths.txt" % accession, 'w')
        outFile.write("ID\tstart\tend\tgroup\tfeature\tmean_mean\tmean_median\tmean_max\tmedian_mean\tmedian_median\tmedian_max\tmax_mean\tmax_median\tmax_max\n")
        outFile.close()
        outFile  = open("/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/read_depths/%s_read_depths.txt" % accession, 'a')
    else:
        outFile  = open("/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/read_depths_negative_control/%s_read_depths.txt" % accession, 'w')
        outFile.write("ID\tstart\tend\tgroup\tfeature\tmean_mean\tmean_median\tmean_max\tmedian_mean\tmedian_median\tmedian_max\tmax_mean\tmax_median\tmax_max\n")
        outFile.close()
        outFile  = open("/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/read_depths_negative_control/%s_read_depths.txt" % accession, 'a')

    if random == False:
        for line in inFile:
            words = line.rstrip()
            words = words.split("\t")
            srna = words[-1]
            start = words[2]
            try:
                start = int(start)
            except ValueError:
                continue
            end = words[3]
            end = int(end)
            new_feature = words[8]
            feature = words[1]
            if new_feature == "FALSE":
                srna_type = "known"
            else:
                srna_type = "novel"

            subsetDF = read_depths_df[start:end]

            mean_mean = subsetDF['mean'].mean()
            mean_median = subsetDF['mean'].median()
            mean_max = subsetDF['mean'].max()
            median_mean = subsetDF['median'].mean()
            median_median = subsetDF['median'].median()
            median_max = subsetDF['median'].mean()
            max_mean = subsetDF['max'].mean()
            max_median = subsetDF['max'].median()
            max_max = subsetDF['max'].max()

            outFile.write("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n" % (srna, start, end, srna_type, feature, mean_mean, mean_median, mean_max, median_mean, median_median, median_max, max_mean, max_median, max_max))
    else:
        i = 0
        for line in inFile:
            i += 1
            words = line.rstrip()
            words = words.split("\t")
            srna = "%s_%s" % (accession, i)
            start = words[0]
            try:
                start = int(start)
            except ValueError:
                continue
            end = words[1]
            end = int(end)
            feature = "intergenic"
            srna_type = "negative_control"

            subsetDF = read_depths_df[start:end]

            mean_mean = subsetDF['mean'].mean()
            mean_median = subsetDF['mean'].median()
            mean_max = subsetDF['mean'].max()
            median_mean = subsetDF['median'].mean()
            median_median = subsetDF['median'].median()
            median_max = subsetDF['median'].mean()
            max_mean = subsetDF['max'].mean()
            max_median = subsetDF['max'].median()
            max_max = subsetDF['max'].max()

            outFile.write("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n" % (
            srna, start, end, srna_type, feature, mean_mean, mean_median, mean_max, median_mean, median_median,
            median_max, max_mean, max_median, max_max))


def single_fasta(fastaFile, folder):
    for seq in fastaFile:
        id = seq.id
        outname = id.split("[")
        outname = outname[0]
        my_seq = seq.seq
        outFile = open("/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/%s/%s.fna" % (folder, outname), "w")
        outFile.write(">%s\n%s\n" % (id, my_seq))


def openNHMMER(nhmmername):
    nhmmerDF = pd.read_csv(nhmmername, delim_whitespace=True, header=None, comment='#')
    nhmmerDF.columns = ["target_name", "accession", "query_name", "accession_2", "hmmfrom", "hmmto", "alifrom", "alito", "envfrom", "envto", "sq_len", "strand", "E_value", "score", "bias", "description_of_target"]
    nhmmerDF[["ID", "descriptors"]] = nhmmerDF.target_name.str.split("[", expand = True)
    nhmmerDF[["ID_2", "descriptors_2"]] = nhmmerDF.query_name.str.split("[", expand = True)
    d = nhmmerDF.groupby('ID')['ID_2'].apply(list).to_dict()
    return(d)


def openReadDepths(readdepthsname, d):
    readdepthsDF = pd.read_csv(readdepthsname, sep = "\t", comment='#')
    readdepthsDF = readdepthsDF[readdepthsDF['ID'] != "ID"]

    ##when being done in jupyter the columns were all read in as string and the lines below were necessary...
    ##it seems to work fine now

    # print(readdepthsDF.dtypes)
    # readdepthsDF[["mean_value", "mean_decimal"]] = readdepthsDF.max_mean.str.split(".", expand = True)
    # print(1)
    # readdepthsDF[["median_value", "median_decimal"]] = readdepthsDF.max_median.str.split(".", expand = True)
    # readdepthsDF[["max_value", "max_decimal"]] = readdepthsDF.max_max.str.split(".", expand = True)
    # readdepthsDF[['mean_value', 'median_value', 'max_value']] = readdepthsDF.loc[:,['mean_value', 'median_value', 'max_value']].apply(pd.to_numeric)


    readdepthsDF["mean_value"] = readdepthsDF['max_mean']
    readdepthsDF["median_value"] = readdepthsDF['max_median']
    readdepthsDF["max_value"] = readdepthsDF['max_max']
    readdepthsDF[['mean_value', 'median_value', 'max_value']] = readdepthsDF.loc[:,['mean_value', 'median_value', 'max_value']].apply(pd.to_numeric)


    idList = list(d.keys())
    readdepthsKept = readdepthsDF[readdepthsDF['ID'].isin(idList)]
    return(readdepthsKept)


def writeReadDepths(outname, readDepths, d):
    seen = []
    d2 = {}
    i = 0

    outFile = open(outname, "w")
    outFile.write(
        "ID\tmean_mean\tmean_median\tmean_max\tmedian_mean\tmedian_median\tmedian_max\tmax_mean\tmax_median\tmax_max\tID_2\n")
    outFile.close()
    outFile = open(outname, "a")
    values = []
    for key in d:
        #     print(i)
        #     i += 1
        #     if i > 100:
        #         break
        #     if key in seen:
        #         continue
        #     print(key)
        #     print(seen)
        values = d[key]
        seen.append(values)
        df = readDepths[readDepths['ID'].isin(values)]
        #     print(df['mean_value'].dtypes)

        #     print(df['mean_value'].dtypes)
        mean_mean = df['mean_value'].mean()
        mean_median = df['mean_value'].median()
        mean_max = df['mean_value'].max()
        median_mean = df['median_value'].mean()
        median_median = df['median_value'].median()
        median_max = df['median_value'].max()
        max_mean = df['max_value'].mean()
        max_median = df['max_value'].median()
        max_max = df['max_value'].max()
        #     print(key)
        #     print("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n" % (key,mean_mean,mean_median,mean_max,median_mean,median_median,median_max,max_mean,max_median,max_max,values))
        outFile.write("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n" % (
        key, mean_mean, mean_median, mean_max, median_mean, median_median, median_max, max_mean, max_median, max_max,
        values))
    outFile.close()


def writeSequences(inFile,my_seq,accession,write_path):
    i = 0
    for line in inFile:
        i += 1
        words = line.rstrip()
        words = words.split("\t")
        srna = words[-1]
        start = words[2]
        try:
            start = int(start)
        except ValueError:
            continue
        end = words[3]
        end = int(end)
        if end - start > 50:
            strand = words[4]
            new_feature = words[8]
            feature = words[1]
            overlap = words[7]
            if new_feature == "FALSE":
                srna_type = "known"
            else:
                srna_type = "novel"
            srnaSeq = my_seq[start:end]
            srnaSeqRev = srnaSeq.reverse_complement()
            if strand == "-":
                srnaSeq = srnaSeqRev
            if srna_type == "known":
                srnaPCFile = open("%s/positive_control/%s.fna" % (write_path, accession), "a")
                srnaPCFile.write(">%s[%s-%s,%s,%s,%s,%s]\n%s\n" % (srna, start, end, strand, srna_type, feature, overlap, srnaSeq))
            else:
                srnaPredictedFile = open("%s/predicted/%s.fna" % (write_path, accession), "a")
                srnaPredictedFile.write(">%s[%s-%s,%s,%s,%s,%s]\n%s\n" % (srna, start, end, strand, srna_type, feature, overlap, srnaSeq))
                
def get_overlap_vals(subsetDat, overlaps):
    dat_len = len(subsetDat.index)
    overlapping_ids = []
    lengths = []
    start_val = 0
    end_val = 0
    for i in range(0,dat_len):
        query_val = subsetDat.iloc[i]['query_id']    
        new_start_val = min([subsetDat.iloc[i]['target_start'], subsetDat.iloc[i]['target_end']])
        new_end_val = max([subsetDat.iloc[i]['target_start'], subsetDat.iloc[i]['target_end']]) 
        if end_val > new_start_val:
            overlapping_ids.append(query_val)
            len_1 = end_val - start_val
            len_2 = new_end_val - new_start_val
            shortest_seq = min([len_1, len_2])
            overlap_start = max([start_val, new_start_val])
            overlap_end = min([end_val, new_end_val])
            overlap = (overlap_end - overlap_start)/shortest_seq
            overlaps.append(overlap)
        else:
            end_val = new_end_val
            start_val = new_start_val
            overlapping_ids = [query_val]
    return(overlaps)

def get_overlap_list(subsetDat):
    overlapping_ids = []
    overlap_list = []
    lengths = []
    start_val = 0
    end_val = 0
    shortest_seq = max(subsetDat['target_end'])
    dat_len = len(subsetDat.index)
    for i in range(0,dat_len):
        query_val = subsetDat.iloc[i]['query_id']    
        new_start_val = min([subsetDat.iloc[i]['target_start'], subsetDat.iloc[i]['target_end']])
        new_end_val = max([subsetDat.iloc[i]['target_start'], subsetDat.iloc[i]['target_end']])  
        if end_val > new_start_val:
            len_2 = new_end_val - new_start_val
            shortest_seq = min([shortest_seq, len_2])
            overlap_start = max([start_val, new_start_val])
            overlap_end = min([end_val, new_end_val])
            overlap = (overlap_end - overlap_start)/shortest_seq
            
            if overlap >= 0.5 and overlap_end - overlap_start >= 50:
                if query_val not in overlapping_ids:
                    overlapping_ids.append(query_val)
                end_val = max([end_val, new_end_val])
            else:
                overlap_list.append(overlapping_ids)
                shortest_seq = max(subsetDat['target_end'])
                end_val = new_end_val
                start_val = new_start_val
                overlapping_ids = [query_val]
        else:
            overlap_list.append(overlapping_ids)
            end_val = new_end_val
            start_val = new_start_val
            overlapping_ids = [query_val]
        if i == dat_len - 1:
            overlap_list.append(overlapping_ids)
    return(overlap_list)

def get_overlap_count(overlap_list, d):
    for l in overlap_list:
        list_len = len(l)
        if list_len == 0:
            continue
        for i in range(0,list_len - 1):
            for j in range(i+1, list_len):
                ids =[l[i], l[j]]
                ids.sort()
                current_id = "_".join(ids)
                if current_id in d:
                    d[current_id] += 1
                else:
                    d[current_id] = 1
    return(d)

def unique_set_of_overlaps(all_overlaps, ids_checked, id1, id2):
    make_new = True
    counter = 0
    if id1 in ids_checked:
        if id1 in all_overlaps:
            if id2 not in all_overlaps[id1]:
                all_overlaps[id1].append(id2)    
        else:
            counter = 0
            item_list = []
            for item in all_overlaps:
                if id1 in all_overlaps[item]:
                    item_list.append(item)
                    if id2 not in all_overlaps[item]:
                        all_overlaps[item].append(id2)
                    make_new = False
                    counter += 1
            if counter > 1:
                print(item_list[1:])
                for item in item_list[1:]:
                    for value in all_overlaps[item]:
                        if value not in all_overlaps[item_list[0]]:
                            all_overlaps[item_list[0]].append(value)
                    all_overlaps.pop(item, None)
                     
    else:
        ids_checked.append(id1)
    return(all_overlaps, ids_checked, make_new, counter)                
                
def combined_alignments(query, combined_d, ids_checked, query_matches):
    combined_ids = [query]
    ids_checked.append(query)
    max_query = query
    for i in range(0, len(query_ids)):
        ids =[query, query_ids[i]]
        ids.sort()
        current_id = "_".join(ids)
        if current_id in query_matches:
            if query_ids[i] in ids_checked:
                for key, value in combined_d.items():
                    if query_ids[i] in value:
                        max_query = key
            else:
                combined_ids.append(query_ids[i])
                ids_checked.append(query_ids[i])
                
                
    if max_query in combined_d:
        for item in combined_ids:
            if item not in combined_d[max_query]:
                combined_d[max_query].append(item)
    else:
        combined_d[max_query] = combined_ids
    return(combined_d, ids_checked)



```

##Overview
###Overview of sRNA RNAs play a critical role in a wide range of biological functions such as:

-   Transcription/Translation

    -   rRNA, tRNA, 6sRNA etc.

-   Immune response

    -   CRISPR-cas

-   Gene regulation

    -   Riboswitches, sRNAs binding to mRNA etc.

-   Virulence

![Figure 1. Examples of ncRNAs in bacteria](sRNA_examples.png)

###Overview of Methods

-   Take RNA-Seq data from multiple genomes

    -   >21 strain
    -   >11 genera
    -   >6 families

-   Predict sRNAs based on expressed regions in RNA-Seq data

    -   Use multiple RNA-Seq datasets for each genome

-   Consider a number of different approaches for evaluating the predicted regions

    -   Conservation of transcription
    -   Conservation of sequence (nhmmer search across genomes from the analysed clade).
    -   GC content
    -   Covariation observed in sequence alignments (using R-scape)
    -   Secondary structure (minimum free energy from RNAAlifold and the Z score of the MFE from alifoldz)
    -   Presence of ncRNA motifs (using the rmfam dataset)

-   Two control groups will be used

    -   Annotations from a search of Rfam models were used as a positive control
    -   Random intergenic sequences of the same lengths as the predicted sRNAs will be used as a negative control

![Figure 4. Workflow of methods](method_scripts_workflow.png)

###Current Figures

![Figure 1. Maximum conserved evolutionary distance per sRNA (cumulative))](max_conservation_distance.png)

![Figure 2. Upset plot for the genera for each sRNA](upsetR_plot_genera.png)

![Figure 3. ROC Curves](roc_curve_all_ccombinations.png)

![Figure 4. Correlation Matrix for features](features_spearman_correlation.png)

![Figure 4. Random forest importance plot](random_forest_importance_plot.png)

###Summary of strains used




How to get the summary table for the genera for the RNA-seq data:

-   Search the [SRA](https://www.ncbi.nlm.nih.gov/sra/) section of ncbi with the genus name and ['Organism'] tag.

-   Select "Send results to Run selector"

-   Select the "Metadata" button of the "Total" row and "Download" Column.

-   cat SraRunTable* >> ~/phd/RNASeq/sra_run_tables.csv

    -   This appears to have columns out of order so it is important to consider that there might be more data available and to search sraDatAll for genus names to check.

```{r selecting_more_data, echo=F, eval=F}
run_all <- F
if(run_all){
datAll <- read.csv("~/phd/RNASeq/sra_run_tables.csv")

assayTypes <- datAll %>% group_by(Assay.Type) %>% summarise(count = n())
sraDatAll <- datAll %>% filter(grepl(pattern = "RNA", x = Assay.Type))
                      
                      
dat <- sraDatAll %>% filter(grepl(pattern = "Illumina", Instrument), LibraryLayout == "PAIRED") %>% unique()

dat <- dat %>% select(Run, Experiment, Organism, Strain, ReleaseDate, Sample.Name, SRA.Study, LibraryLayout, LibrarySelection, LibrarySource, Instrument) %>% mutate_all(as.character)

# datAll <- datAll %>% select(Run, Experiment, Organism, Strain, ReleaseDate, Sample.Name, SRA.Study, LibraryLayout, LibrarySelection, LibrarySource, Instrument) %>% mutate_all(as.character)

SRA_bacteria_RNASeq_v2 <- dat
SRA_bacteria_RNASeq_v2_all <- sraDatAll
save(SRA_bacteria_RNASeq_v2, file ="~/bin/r_git/R/r_files/SRA_bacteria_RNASeq_v2.Rda")
save(SRA_bacteria_RNASeq_v2_all, file ="~/bin/r_git/R/r_files/SRA_bacteria_RNASeq_v2_all.Rda")


load("~/bin/r_git/R/r_files/SRA_bacteria_RNASeq_v2.Rda")
load("~/bin/r_git/R/r_files/SRA_bacteria_RNASeq_v2_all.Rda")

sraDat <- SRA_bacteria_RNASeq_v2
sraDatAll <- SRA_bacteria_RNASeq_v2_all

strainsCount <- sraDatAll %>% group_by(Organism, Strain) %>% summarise(count = n())

sraDatAll <- sraDatAll %>% separate(col = Organism, into = "genus", sep = " ", remove = F, extra = 'drop')
library.options <- c("PAIRED", "SINGLE")
sraDatAll1 <- sraDatAll %>% filter(LibraryLayout %in% library.options) 
sraDatAll2 <- sraDatAll %>% filter(SRA.Study %in% library.options) %>% select(-genus) %>% mutate(LibraryLayout = SRA.Study)
sraDatAll3 <- sraDatAll %>% filter(AvgSpotLen %in% library.options) %>% select(-genus) %>% mutate(LibraryLayout = AvgSpotLen)
sraDatAll4 <- sraDatAll %>% filter(Sample.Name %in% library.options) %>% select(-genus) %>% mutate(LibraryLayout = Sample.Name)
sraDatAll5 <- sraDatAll %>% filter(genus %in% library.options) %>% mutate(LibraryLayout = genus) %>% select(-genus) 
sraDatAll6 <- sraDatAll %>% filter(LibrarySelection %in% library.options) %>% select(-genus) %>% mutate(LibraryLayout = LibrarySelection)
sraDatAll7 <- sraDatAll %>% filter(Platform %in% library.options) %>% select(-genus) %>% mutate(LibraryLayout = Platform)



sraDatAll2 <- sraDatAll2  %>% 
  dplyr::mutate(Organism = Bytes)%>% separate(col = Organism, into = "genus", sep = " ", remove = F, extra = 'drop')
sraDatAll3 <- sraDatAll3 %>% 
  dplyr::mutate(Organism = DATASTORE.filetype)%>% separate(col = Organism, into = "genus", sep = " ", remove = F, extra = 'drop')
sraDatAll4 <- sraDatAll4 %>%  
  dplyr::mutate(Organism = Bases)%>% separate(col = Organism, into = "genus", sep = " ", remove = F, extra = 'drop')
sraDatAll5 <- sraDatAll5 %>% 
  dplyr::mutate(Organism = Sample.Name)%>% separate(col = Organism, into = "genus", sep = " ", remove = F, extra = 'drop')
sraDatAll6 <- sraDatAll6 %>% 
  dplyr::mutate(Organism = Platform)%>% separate(col = Organism, into = "genus", sep = " ", remove = F, extra = 'drop')
sraDatAll7 <- sraDatAll7 %>% 
  dplyr::mutate(Organism = SRA.Study)%>% separate(col = Organism, into = "genus", sep = " ", remove = F, extra = 'drop')




genusCount1 <- sraDatAll1 %>% group_by(genus) %>% summarise(count = n())
genusCount2 <- sraDatAll2 %>% group_by(genus) %>% summarise(count = n())
genusCount3 <- sraDatAll3 %>% group_by(genus) %>% summarise(count = n())
genusCount4 <- sraDatAll4 %>% group_by(genus) %>% summarise(count = n())
genusCount5 <- sraDatAll5 %>% group_by(genus) %>% summarise(count = n())
genusCount6 <- sraDatAll6 %>% group_by(genus) %>% summarise(count = n())
genusCount7 <- sraDatAll7 %>% group_by(genus) %>% summarise(count = n())

genusCount <- genusCount1 %>% bind_rows(genusCount2, genusCount3, genusCount4, genusCount5, genusCount6, genusCount7)


sraDatAll <- sraDatAll1 %>% bind_rows(sraDatAll2, sraDatAll3, sraDatAll4, sraDatAll5, sraDatAll6, sraDatAll7)

sraDatAll <- sraDatAll %>% select(Run, Experiment, Organism, Strain, genus, LibraryLayout, ReleaseDate, Sample.Name, SRA.Study, LibrarySelection, LibrarySource, Instrument) %>% mutate_all(as.character)

save(sraDatAll, file = "~/bin/r_git/R/r_files/sraDatAll.Rda")
}

```

```{r summary_of_strains, echo = T, eval = T}
getwd()
load("~/bin/r_git/R/r_files/accession_info.Rda")
accession_info <- accession_info %>% 
  mutate(strain_short = substr(Strain, start = 1, stop = 30)) %>% 
  select(Accession, RNASeq.file.counts, strain_short)
accession_info[1:20,]


load("~/bin/r_git/R/r_files/assembly_summary.Rda") # made from ~/phd/RNASeq/SRA_bacteria_RNAseq.txt


assembly_summary <- assembly_summary %>% separate(col = SPECIES, into = c("Genus"), extra = "drop", remove = F, sep = " ")


genomes <- assembly_summary %>% filter(DESIGN == "PAIRED", grepl(pattern = "Illumina", x = INSTRUMENT)) %>% group_by(Genus) %>% select(Genus, GENOME_ACCESSION) %>% unique() %>% summarise(genome_count = n())
experiments <- assembly_summary %>% filter(DESIGN == "PAIRED", grepl(pattern = "Illumina", x = INSTRUMENT)) %>% group_by(Genus) %>% select(Genus, GENOME_ACCESSION, ACCESSION) %>% unique() %>% summarise(experiment_count = n())

counts <- genomes %>% full_join(experiments, by = "Genus")

load("~/bin/r_git/R/r_files/sraDatAll.Rda")

assembly_summary[1:20,]
sraDatAll[1:20,]

```

-   The genome accession for each added genome was looked up on [NCBI](https://www.ncbi.nlm.nih.gov/) using the strain name in the file or by search for the given experiment in the [SRA](https://www.ncbi.nlm.nih.gov/sra/) section.

-   A taxonomy table was generated with the code below. This had to be supplemented by going through manually to correct mistakes, or fill in missing data.

-   genera_list.txt was made by hand by searching for RNASeq files for each genus as above and if found, the genus was added to the file. 

    -   this would not be practical for a bigger clade.

```{python get_taxonomy, eval=F}
genera = pd.read_csv('/Users/thomasnicholson/bin/python_git/python_files/genera_list.txt', header = None)
df_len = len(genera)

genera['Kingdom'] = 1
genera['Phylum'] = 1
genera['Class'] = 1
genera['Order'] = 1
genera['Family'] = 1
genera['Genus'] = genera.iloc[:,0]

i = -1
for item in genera.iloc[:,0]:
    i += 1
    html_link = 'https://en.wikipedia.org/wiki/%s' % item
    print(html_link)
    
    
    try:
        html_page = urllib.request.urlopen(html_link)
    except urllib.error.HTTPError as exception:
        next
    record_values = False
    pos_val = 0
    taxonomy_levels = []
    for line in html_page:
        mystr = line.decode("utf8")
        if record_values == False:
            if "<td>Kingdom" in mystr:
                record_values = True
            elif "<td>Domain" in mystr:
                record_values = True                
        else:

            if pos_val > 5:
                break
            if 'href="/wiki/' in mystr:
                pos_val += 1
#                 print(pos_val)
                level_name = mystr.split("/")[2]
                level_name = level_name.split('"')[0]
                print(level_name)
#                 print(genera.iloc[i,:])
                genera.iloc[i,pos_val]  = level_name


```

##Predicting sRNAs
###Download data and map reads

**Scripts involved for each Accession**

-   [*callPeaksforGenome.sh*](#section-callpeaksforgenome.sh) *-g* *\<GCA Accession\>* *-s*

    -   The *-s* flag is now used to indicate that a file named *experiments_list.txt* should be used for the list of RNASeq accessions. This is due to the new file containing accessions being less organised and requiring this new input.

    -   Only accessions with \>4 RNA-Seq files are analysed

    -   [*fetch_genomes_from_GCA.sh*](#section-fetch_genomes_from_gca.sh) *-r* *\<GCA Accession\>* *-g*

        -   The genome and gff files are downloaded from ncbi using the GCA acession
        -   *-g* flag is for downloading GFF file

    -   The RNA-Seq data is downloaded using *fasterq-dump* with a given accession

        -   these are selected from a file (shown below) containing a list of RNA-Seq experiment IDs for each strain. (Old)
        -   filtered for paired ends, Illumina HiSeq

    -   [*sra2plot.1.0.3.sh*](#section-sra2plot.1.0.3.sh) *-s* *\<SRA Accession\>* *-r* *\<GCA Accession\>* *-d* *-n* *\<Number of CPUs\>*

        -   Maps the reads
        -   *-d* turns off the downloading function of the script as this is being done separately

    -   [*removeProteinCodingRNA.R*](#section-removeproteincodingrna.r) *-f* *\<SRA Accession\>* *-g* *\<GCA Accession\>*

    -   [*run_rnaPeakCalling.R*](#section-run_rnapeakcalling.r) *-f* *\<SRA Accession\>* *-g* *\<GCA Accession\>*

    -   [*rfamscan*](#section-rfamscan) *\<GCA Accession\>*

        -   Searches the given genome for rFam models and reformats output into GFF format
        -   [*cmscanToGffWrapper.R*](#section-cmscantogffwrapper.r) *-f* *\<GCA Accession\>.tblout* *-g* *\<GCA Accession\>*

    -   [*combine_gff_files.R*](#section-combine_gff_files.r) -f *./gff_files/* *-o* *\<GCA Accession\>*

------------------------------------------------------------------------


###Call peaks on individual RNA-Seq experiments

-   A plot file is produced. This contains a number for each nucleotide that indicates read depth.

-   The read depth gets set to 0 for all coding regions of the file

    -   This is done as identifying ncRNAs inside coding regions is a much more challenging problem than simply peak calling

-   For the remaining positions, the read depth is normalised and any region where the read depth is above a threshold for \>50 nt is called a peak.

    -   Threshold is set to the equivalent of \~15 nt read depth before normalisation

###callPeaksforGenome.sh

Wrapper for a series of scripts that downloads genomes and fastq files, maps reads and calls peaks for a given genome. The fastq files are downloaded from SRA using a list of available experiment IDs.

```{bash callPeaksforGenome.sh, eval = F, echo=F}
#!/bin/bash

##-----------------------------------------------------------------##
##--------------------------- Setup Variables ---------------------##
##-----------------------------------------------------------------##

FILE_PATH=`dirname $0`
number_of_sra="10"
output_path="./"
CPUS='6'
output_log=/dev/stdout
display_available_files="F"

##-----------------------------------------------------------------##
##------------------------ User Input Options ---------------------##
##-----------------------------------------------------------------##

while getopts "g:n:o:c:qth" arg; do
  case $arg in
    g)
      gca=$OPTARG
      ;;
    n)
      number_of_sra=$OPTARG
      ;;      
    o)
      output_path=$OPTARG
      ;;
	c)
      CPUS=$OPTARG
      ;;                  
	q)
      output_log=$gca.log
      ;;
    t)
    display_available_files="T"
    ;; 
    h)
echo '# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -'

      ;;
      
    esac
done    

##-----------------------------------------------------------------##
##-------------------------- Tests For Inputs ---------------------##
##-----------------------------------------------------------------##
if [[ -z $gca ]]; then
echo 'Error: GCA needed. Specify with -g <gca>'
echo ' '
echo 'Use -h for more help.'
echo ' '
exit
fi

counts=`grep $gca ~/phd/RNASeq/SRA_bacteria_RNAseq.txt | grep "PAIRED" | grep "Illumina HiSeq" | wc -l`
if (( $counts == 0 )); then
echo "No valid RNAseq datasets for $gca"

exit
fi

if [[ $display_available_files == "T" ]]; then
grep $gca ~/phd/RNASeq/SRA_bacteria_RNAseq.txt | grep "PAIRED" | grep "Illumina HiSeq"
exit
fi

##-----------------------------------------------------------------##
##---------------------- Set up folders/files ---------------------##
##-----------------------------------------------------------------##

cd $output_path
mkdir -p "$gca.data"
cd "$gca.data"
mkdir gff_files      
echo "Output to $output_log"

if (( $counts > $number_of_sra )); then

grep $gca ~/phd/RNASeq/SRA_bacteria_RNAseq.txt | grep "PAIRED" | cut -f1 | head -n $number_of_sra > tmp1

else

grep $gca ~/phd/RNASeq/SRA_bacteria_RNAseq.txt | grep "PAIRED" | cut -f1 > tmp1

fi


##-----------------------------------------------------------------##
##---------------------- Download Genome and GFF ------------------##
##-----------------------------------------------------------------##

	if [[ -f "${gca}.fna" ]]; then
	echo "$gca.fna already downloaded."
	else
	echo "Downloading $gca Genome and GFF files"
	fetch_genomes_from_GCA.sh -r $gca -g >> $output_log
	fi
	
if [ $? -eq 0 ]; then
    echo " "
else
     echo "Error: Downloading $gca Genome and GFF files failed. See fetch_genomes_from_GCA.sh"
     exit $?
fi


##-----------------------------------------------------------------##
##-------------- Download and Process RNA-Seq Files ----------------##
##-----------------------------------------------------------------##
file_lines=`cat tmp1`

for line in $file_lines ; 
do
	
	if [[ -f "${line}_sra_calls.gff" ]]; then
	
	echo "$line already downloaded."
	
	else
	
	echo "Downloading $line"
    fasterq-dump --split-3 -p $line >> $output_log
	echo "Mapping reads"
    sra2plot.1.0.3.sh -s $line -r $gca -d -n $CPUS  >> $output_log
    
    plot_lenegth=`wc -l $line.plot  | cut -d ' ' -f2`
    rm *.sam    
    	if [ $plot_lenegth -gt 0 ]; then
    	rm ${line}*fwd.plot
    	rm ${line}*.rev.plot
    	rm fastq/${line}*.fastq
    	rm trimmed/${line}*.fastq
    	fi
    rm /Users/thomasnicholson/ncbi/public/sra/*.cache
    echo "Removing CDS"
    removeProteinCodingRNA.R -f $line -g $gca >> $output_log
    echo "Calling Peaks"
    run_rnaPeakCalling.R -f $line  -g $gca >> $output_log
    
    fi
    cp ${line}_sra_calls.gff ./gff_files/
done

##-----------------------------------------------------------------##
##---------------------- Search for rFam models -------------------##
##-----------------------------------------------------------------##

rfamscan() { counts=$( bc -l <<< "scale=2;$(esl-seqstat $1.fna | grep ^"Total" | tr -s ' ' | cut -d ' ' -f4)*2/1000000"); cmscan -Z $counts  --cut_ga --rfam --nohmmonly --tblout $1.tblout --fmt 2 --clanin ~/Downloads/Rfam.clanin.txt ~/Downloads/Rfam.cm $1.fna; cmscanToGffWrapper.R -f $1.tblout -g $1;}

if [[ -f "${gca}_ncRNA.gff" ]]; then
	echo "${gca}_ncRNA.gff exists"
else
	echo "Running cmscan using rfam models"
	rfamscan $gca  >> $output_log
fi

cp $gca.gff ./gff_files/
cp ${gca}_ncRNA.gff ./gff_files


##-----------------------------------------------------------------##
##------------------------ Combine GFF Files ----------------------##
##-----------------------------------------------------------------##

if [[ ! -f "${gca}_new_calls.txt" ]]; then
combine_gff_files.R -f ./gff_files/ -o $gca
fi

echo "Finished."
rm tmp1
```

###fetch_genomes_from_GCA.sh

Downloads a given genome and corresponding annotation file (GFF3 format).

```{bash fetch_genomes_from_GCA.sh, eval = F, echo=F}
#!/bin/bash

##-----------------------------------------------------------------##
##---------------------------- Help Message -----------------------##
##-----------------------------------------------------------------##

usage(){
    echo "fetch_genomes_from_GCA.sh is a script for downloading a genome (and GFF file) from a GCA accession.  
Usage:
 fetch_genomes_from_GCA.sh [opts] [input]

Options:
	-h	Display this help

Input	       
	-r	Reference genome accession (required)
	-o	Output name
	-e Fasta file extension
   	-g include the GFF file

"
}

##-----------------------------------------------------------------##
##------------------------ User Input Options ---------------------##
##-----------------------------------------------------------------##

while getopts "r:o:e:gh" arg; do
case $arg in
	r) 
	GENOME=${OPTARG};;
	o) 
	OUTPUT=${OPTARG};;
	e) 
	EXTENSION=${OPTARG};;
	g)
      GFF='y'
      ;;  
    h)
		usage
		exit
      ;;    
	\?) 
	echo "Unknown option: -${OPTARG}" >&2; exit 1;;
    esac
done

##-----------------------------------------------------------------##
##-------------------------- Tests For Inputs ---------------------##
##-----------------------------------------------------------------##

if [ -z ${GENOME} ]; then
    echo "Error: No input specified." >&2
    usage
    exit 1
fi

if [ -z ${OUTPUT} ]; then

OUTPUT=${GENOME}

fi

if [ -z ${EXTENSION} ]; then

EXTENSION="fna"

fi

##-----------------------------------------------------------------##
##------------------------ Get IDs for download -------------------##
##-----------------------------------------------------------------##

AssemblyName=$(esearch -db assembly -query ${GENOME} | efetch -format docsum | xtract -pattern DocumentSummary -element AssemblyName)
refseqID=$(esearch -db assembly -query ${GENOME} | efetch -format docsum | xtract -pattern DocumentSummary -element RefSeq)

refseq1=$(echo $refseqID | head -c 7 | tail -c 3)
refseq2=$(echo $refseqID | head -c 10 | tail -c 3)
refseq3=$(echo $refseqID | head -c 13 | tail -c 3)



##-----------------------------------------------------------------##
##----------------------- Download fasta file ---------------------##
##-----------------------------------------------------------------##

if [ ! -f $OUTPUT.$EXTENSION ];then

fastaLink="ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/$refseq1/$refseq2/$refseq3/$refseqID._$AssemblyName/$refseqID._$AssemblyName._genomic.fna.gz"

downloadLink=$(echo $fastaLink | sed 's/\._/_/g')

curl $downloadLink > $OUTPUT.$EXTENSION.gz 
sleep 1
gunzip $OUTPUT.$EXTENSION.gz 

if [ $? -eq 0 ]; then
    echo " "
else
    exit $?
fi


echo "$OUTPUT.$EXTENSION downloaded using $downloadLink"

else

fastaLink="ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/$refseq1/$refseq2/$refseq3/$refseqID._$AssemblyName/$refseqID._$AssemblyName._genomic.fna.gz"

downloadLink=$(echo $fastaLink | sed 's/\._/_/g')

echo "$OUTPUT.$EXTENSION already downloaded. To download again use $downloadLink"


fi

##-----------------------------------------------------------------##
##------------------------ Download GFF file ----------------------##
##-----------------------------------------------------------------##

if [[ $GFF = 'y' ]]; then

if [ ! -f $OUTPUT.gff ];then

      
gffLink="ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/$refseq1/$refseq2/$refseq3/$refseqID._$AssemblyName/$refseqID._$AssemblyName._genomic.gff.gz"

downloadLink=$(echo $gffLink | sed 's/\._/_/g')

curl $downloadLink > $OUTPUT.gff.gz 
sleep 1
gunzip $OUTPUT.gff.gz 

if [ $? -eq 0 ]; then
    echo " "
else
     exit $?
fi

echo "$OUTPUT.gff downloaded using $downloadLink"

else

gffLink="ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/$refseq1/$refseq2/$refseq3/$refseqID._$AssemblyName/$refseqID._$AssemblyName._genomic.gff.gz"

downloadLink=$(echo $gffLink | sed 's/\._/_/g')

echo "$OUTPUT.gff already downloaded. To download again use $downloadLink"


fi

fi


```

###sra2plot.1.0.3.sh

Script that maps reads from fastq file to genome and produces a plot file with read depths for each nucleotide.

```{bash sra2plot.1.0.3.sh, eval=F, echo=F}
#!/bin/sh
#Downloads fastq files from SRA, trims, maps and generates plotfiles for visualisation in artemis

#Dependencies:
#curl
#sratoolkit
#samtools 1.6 (older versions may not work for generating plotfiles)
#bowtie2
#trimmomatic 0.36

usage(){
    echo "sra2plot.sh is a wrapper script for downloading, mapping and visualising RNA-seq data from the NCBI Sequence Read Archive (SRA). Currently assumes paired end reads with TruSeq3 adaptors. Path for trimmomatic needs to be set to run. 
Usage sra2plot [opts] [input]
    
    Options:
		-h	Display this help

		Input	       
	       	-r	Reference genome accession (required)
		-s	SRA run accession or name of split fastq files (Required. Format: FILE_1.fastq FILE_2.fastq)
    		-n	Number of cores

		Turn off defaults
		-d	Turn off download. Default: download genome and SRA from NCBI if not found in working directory. 
			(Genome accession must be in Genbank nucleotide format: https://www.ncbi.nlm.nih.gov/Sequin/acc.html)
		-t	Turn off trimming
		-m	Turn off mapping
		-p	Don't make plotfiles
		-x	Don't cleanup files"
}
TPATH="/Users/thomasnicholson/bin/Trimmomatic_binary-0.36"
OUTDIR=""
SRA=""
GENOME=""
TRIM=true
MAP=true
PLOT=true
CLEAN=true
DOWNLOAD=true
THREADS=1

while getopts :s:r:n:thdmpx opt; do
    case "${opt}" in
	h) usage;exit;;
	t) TRIM=false;;
	s) SRA=${OPTARG};;
	r) GENOME=${OPTARG};;
	d) DOWNLOAD=false;;
	m) MAP=false;;
	p) PLOT=false;;
	x) CLEAN=false;;
	n) THREADS=${OPTARG};;
	\?) echo "Unknown option: -${OPTARG}" >&2; exit 1;;
	:) echo "Missing option argument for -${OPTARG}" >&2; exit 1;;
	*) echo "Unimplemented option: -${OPTARG}" >&2; exit;;
    esac
done
shift $((${OPTIND}-1))

if [ -z ${GENOME} ] || [ -z ${SRA} ]; then
    echo "Error: No input specified." >&2
    usage
    exit 1
fi

if [ -z ${TPATH} ]; then
    echo "Error: Path to trimmomatic install folder is not set.\n" >&2
    exit 1
fi

if $DOWNLOAD;then
    if [ ! -f ${GENOME}.fna ];then
	fetch_genomes_from_GCA.sh -r ${GENOME} -g
    fi
    if [ ! -f ${SRA}_*.fastq ];then
	fastq-dump --split-3 ${SRA}
    fi
fi

if $TRIM;then 
    if [ ! -d trimmed ];then
	mkdir trimmed
    fi
    java -jar ${TPATH}/trimmomatic-0.36.jar PE -threads `echo $((2*${THREADS}))` ${SRA}_1.fastq ${SRA}_2.fastq trimmed/${SRA}_1_paired.fastq trimmed/${SRA}_1_unpaired.fastq trimmed/${SRA}_2_paired.fastq trimmed/${SRA}_2_unpaired.fastq ILLUMINACLIP:${TPATH}/adapters/TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36
fi

if $MAP; then
    #Build index of genome if necessary
    if [ ! -d index ]; then
	mkdir index 
	fi
	bowtie2-build ${GENOME}.fna ${GENOME} &&

	mv *.bt2* index/
    
    bowtie2 -p `echo "$((${THREADS}))"` -x index/${GENOME} -1 trimmed/${SRA}_1_paired.fastq -2 trimmed/${SRA}_2_paired.fastq -S ${SRA}.sam
fi

if $PLOT;then
    samtools view -bS -@ ${THREADS} ${SRA}.sam > ${SRA}.bam
    samtools sort -@ ${THREADS} ${SRA}.bam > ${SRA}.sorted.bam
    # Forward strand.
    #alignments of the second in pair if they map to the forward strand
    samtools view -b -f 128 -F 16 -@ ${THREADS} ${SRA}.sorted.bam > ${SRA}.fwd1.bam
    samtools index ${SRA}.fwd1.bam
    #alignments of the first in pair if they map to the reverse strand
    samtools view -b -f 80 -@ ${THREADS} ${SRA}.sorted.bam > ${SRA}.fwd2.bam
    samtools index ${SRA}.fwd2.bam
    #combine alignments that originate on the forward strand
    samtools merge -f ${SRA}.fwd.bam ${SRA}.fwd1.bam ${SRA}.fwd2.bam
    samtools index ${SRA}.fwd.bam

    # Reverse strand
    #alignments of the second in pair if they map to the reverse strand
    samtools view -b -f 144 -@ ${THREADS} ${SRA}.sorted.bam > ${SRA}.rev1.bam
    samtools index ${SRA}.rev1.bam
    #alignments of the first in pair if they map to the forward strand
    samtools view -b -f 64 -F 16 -@ ${THREADS} ${SRA}.sorted.bam > ${SRA}.rev2.bam
    samtools index ${SRA}.rev2.bam
    #combine alignments that originate on the reverse strand.
    samtools merge -f ${SRA}.rev.bam ${SRA}.rev1.bam ${SRA}.rev2.bam
    samtools index ${SRA}.rev.bam

    #Generate plotfiles
    samtools mpileup -aa ${SRA}.fwd.bam > ${SRA}.fwd.mpileup
    samtools mpileup -aa ${SRA}.rev.bam > ${SRA}.rev.mpileup
    cat ${SRA}.fwd.mpileup | cut -f4 > ${SRA}.fwd.plot
    cat ${SRA}.rev.mpileup | cut -f4 > ${SRA}.rev.plot
    paste ${SRA}.rev.plot ${SRA}.fwd.plot > ${SRA}.plot   
fi

if $CLEAN; then
    rm *.bam *.mpileup *.bai
	if [ ! -d fastq ]; then
	    mkdir fastq
	fi
	mv ${SRA}_*.fastq fastq/
fi



#To-do
#add install checks
#add opts for directory outputs
#write readme
#make logs/verbose?


```

###removeProteinCodingRNA.R

In order to call non-coding RNA expression, expression of coding regions must be ignored as not all of the RNA-Seq experiemtns are focused on ncRNA. This script does this by setting coding regions (defined based on the annotation file) to a read depth of 0.

```{r removeProteinCodingRNA.R, eval = F, echo=F}
#!/usr/bin/env Rscript
suppressMessages(library('getopt'))



spec = matrix(c(
  'sra', 'f', 1, "character",
  'help' , 'h', 0, "logical",
  'stranded' , 's', 0, "logical",
  'gff' , 'g', 1, "character",
  'file_path', 'p', 2, "character",
  'range', 'r', 2, "integer",
  'out_name', 'o', 2, "character"
), byrow=TRUE, ncol=4)


opt = getopt(spec)

if ( !is.null(opt$help) ) {
  cat("removeProteinCoding.R version 1.0\n")
  cat(" \n")
  cat("Use removeProteinCoding.R <options> -f <sra plot file> -g <gff file>\n")
  cat(" \n")
  cat("Options:\n")
  cat("  -f <sra plot file> The file that contains the plot data. Do not inclue the .plot file extension\n")
  cat("  -g <gff file> The file that contains the gff data. Do not inclue the gff file extension\n")
  cat("  -s <stranded data> The data is stranded\n")
  cat("  -p <file path> The location of the other files and the output file\n")
  cat("  -r <protein coding range> The number of nucleotides either side of a CDS region that should also be set to zero\n")
  cat("  -o <output file name> The name of the output file. Do not inclue the gff file extension. The default is the same as the sra input\n")
  q(status=1)
}

if ( is.null(opt$sra) ) {
  cat("Error: -f <sra plot file> is required.\n")
  q(status=1)
}
if ( is.null(opt$gff) ) {
  cat("Error: -g <gff file> is required.\n")
q(status=1)
}
suppressMessages(library(tidyverse))
suppressMessages(library(tjnFunctions))

if ( is.null(opt$file_path ) ) { opt$file_path = "." }
if ( is.null(opt$range ) ) { opt$range = 50 }
if ( is.null(opt$out_name ) ) { opt$out_name = opt$sra }
if(is.null(opt$stranded)){
  stranded <- F
}else{
  stranded <- T
}
sraName <- opt$sra
gffName <- opt$gff
filePath <- opt$file_path


plotDat <- read.table(paste(filePath, "/", sraName, ".plot", sep = ""))
gffDat <- read.table(paste(filePath, "/", gffName, ".gff", sep = ""), sep = "\t", fill = T, comment.char = "#", quote = "")

colnames(gffDat) <- c("sequence", "source", "feature", "start", "end", "score", "strand", "phase", "Atrribute")

plotDat <- removeCDSregions(plotDat = plotDat, gffDat = gffDat, stranded = stranded, time.it = T)



cat(paste("Writing the plot output to ", filePath, "/", opt$out_name, "_ncRNA.plot\n", sep = ""))
write.table(plotDat%>%select(V1,V2), file = paste(filePath, "/", opt$out_name, "_ncRNA.plot", sep = ""), quote = F, row.names = F, col.names = F, sep = "\t")


```

###run_rnaPeakCalling.R

Regions of expression are called on each individual RNA-Seq experiment by looking for regions where read depths are > 15 for atleast 50nt.

```{r run_rnaPeakCalling.R, eval = F, echo=F}
#!/usr/bin/env Rscript
suppressMessages(library('getopt'))

spec = matrix(c(
  'sra', 'f', 1, "character",
  'help' , 'h', 0, "logical",
  'stranded' , 's', 0, "logical",
  'quiet' , 'q', 0, "logical",
  'gff' , 'g', 1, "character",
  'file_path', 'p', 2, "character",
  'range', 'r', 2, "integer",
  'out_name', 'o', 2, "character"
), byrow=TRUE, ncol=4)


opt = getopt(spec)

if ( !is.null(opt$help) ) {
  cat("run_rnaPeakCalling.R version 1.0\n")
  cat(" \n")
  cat("Use run_rnaPeakCalling.R <options> -f <sra plot file> -g <gff file>\n")
  cat(" \n")
  cat("Options:\n")
  cat("  -f <sra plot file> The file that contains the plot data. Do not inclue the .plot file extension\n")
  cat("  -g <gff file> The file that contains the gff data. Do not inclue the gff file extension\n")
  cat("  -s <stranded data> The data is stranded\n")
  cat("  -q <quiet> Do not print any updates\n")
  cat("  -p <file path> The location of the other files and the output file\n")
  cat("  -r <protein coding range> The number of nucleotides either side of a CDS region that should also be set to zero\n")
  cat("  -o <output file name> The name of the output file. Do not inclue the gff file extension. The default is the same as the sra input\n")
  q(status=1)
}

if ( is.null(opt$sra) ) {
  cat("Error: -f <sra plot file> is required.\n")
  q(status=1)
}
if ( is.null(opt$gff) ) {
  cat("Error: -g <gff file> is required.\n")
  q(status=1)
}



suppressMessages(library(tidyverse))
suppressMessages(library(tjnFunctions))
###--- column 1 is reverse and column 2 is forward ---###

if ( is.null(opt$file_path ) ) { opt$file_path = "." }
if ( is.null(opt$range ) ) { opt$range = 50 }
if ( is.null(opt$out_name ) ) { opt$out_name = opt$sra }
if(is.null(opt$stranded)){
  stranded <- F
}else{
  stranded <- T
}

if(is.null(opt$quiet)){
  quiet <- F
}else{
  quiet <- T
}

sraName <- opt$sra
gffName <- opt$gff
filePath <- opt$file_path

ptm <- proc.time()


gffDat  <- tryCatch({
  suppressWarnings(gffDat <- read.table(paste(filePath, "/", gffName, ".gff", sep = ""), sep = "\t", fill = T, comment.char = "#", quote = ""))
  gffDat
}, error =  function(e) {
  cat(paste("Error: ", opt$file_path, "/", opt$gff, ".gff not found.\n", sep = ""))
  q(status=1)
})


plotDat  <- tryCatch({
  suppressWarnings(plotDat <- read.table(paste(filePath, "/", sraName, ".plot", sep = "")))
  plotDat
}, error =  function(e) {
  cat(paste("Error: ", opt$file_path, "/", opt$sra, ".plot not found.\n", sep = ""))
  q(status=1)
})

total <- (sum(plotDat$V1) + sum(plotDat$V2))/1000000

colnames(gffDat) <- c("sequence", "source", "feature", "start", "end", "score", "strand", "phase", "Atrribute")

plotDatncRNA  <- tryCatch({
  ##Change this path or put the header file in the working directory
  suppressWarnings(plotDatncRNA <- read.table(paste(filePath, "/", sraName, "_ncRNA.plot", sep = "")))

  plotDatncRNA
}, error =  function(e) {
  plotDat <- read.table(paste(filePath, "/", sraName, ".plot", sep = ""))
  if(quiet == F){
    cat("Running removeCDSregions\n")

  }
  plotDatncRNA <- removeCDSregions(plotDat = plotDat, gffDat = gffDat, stranded = stranded, time.it = T)

  plotDatncRNA
} )

plotDatncRNA$V1 <- plotDatncRNA$V1/total
plotDatncRNA$V2 <- plotDatncRNA$V2/total



cat("Running rnPeakCalling\n")

cat("Calling forward\n")
callsDatFwd <- rnaPeakCalling(dat = plotDatncRNA, col.num = 2, small_peaks = F, plot_threshold = 15/total)

cat("Calling reverse\n")
callsDatRev <- rnaPeakCalling(dat = plotDatncRNA, col.num = 1, small_peaks = F, plot_threshold = 15/total)


callsDatFwd <- callsDatFwd%>%mutate(strand = "+")
callsDatRev <- callsDatRev%>%mutate(strand = "-")

runningTime <- proc.time() - ptm
  printRunningTime(runningTime = runningTime)

  if("feature.length" %in% colnames(callsDatFwd) == F){
    print(colnames(callsDatFwd))
    print(head(callsDatFwd))
    cat("Warning: feature.length column not found in callsDatFwd.\n")
    quitStatus <- T
    callsDatFwdTmp <- callsDatFwd%>%filter(start != 0)%>%
      mutate(feature.length = stop - start)%>%
      mutate(feature.score = feature.length*mean.score)%>%
      filter(feature.score > 3)
  }else{
  callsDatFwdTmp <- callsDatFwd%>%filter(start != 0)%>%
    mutate(feature.score = feature.length*mean.score)%>%
    filter(feature.score > 3)
  }
  if("feature.length" %in% colnames(callsDatRev) == F){
    print(colnames(callsDatRev))
    print(head(callsDatRev))
    cat("Warning: feature.length column not found in callsDatRevTmp.\n")
    quitStatus <- T
    callsDatRevTmp <- callsDatRev%>%filter(start != 0)%>%
      mutate(feature.length = stop - start)%>%
      mutate(feature.score = feature.length*mean.score)%>%
      filter(feature.score > 3)
  }else{
  callsDatRevTmp <- callsDatRev%>%filter(start != 0)%>%
    mutate(feature.score = feature.length*mean.score)%>%
    filter(feature.score > 3)
  }
  
  # if(quitStatus == T){
  #   q(status=1)
  # }

gffMain <- readLines(paste(filePath, "/", gffName, ".gff", sep = ""))
gffMain <- data.frame(text = gffMain)
genomeInfo <- as.character(gffMain[8,1])
genomeBuild <- as.character(gffMain[4,1])
genomeSpecies <- as.character(gffMain[9,1])
accession <- strsplit(genomeInfo, " ")[[1]][2]



gffFwd <- callsDatFwdTmp%>%mutate(strand = "+",
                                                 source = "sraAlignedncRNAExpression",
                                                 seqname = accession,
                                                 median.val = round(mean.score*100),
                                                 feature = "ncRNA",
                                                 frame = ".",
                                                 attribute = paste("ID=rna_fwd_", row_number(), sep = ""))%>%
  select(seqname, source, feature, start, stop, median.val, strand, frame, attribute)

gffRev <- callsDatRevTmp%>%mutate(strand = "-",
                                                 source = "sraAlignedncRNAExpression",
                                                 seqname = accession,
                                                 median.val = round(mean.score*100),
                                                 feature = "ncRNA",
                                                 frame = ".",
                                                 attribute = paste("ID=rna_rev_", row_number(), sep = ""))%>%
  select(seqname, source, feature, start, stop, median.val, strand, frame, attribute)%>%
  arrange(as.numeric(start))



gff <- gffFwd%>%bind_rows(gffRev)%>%arrange(as.numeric(start))
gff <- gff%>%filter(start != 0)




fileConn<-file(paste(filePath, "/", opt$out_name, "_sra_calls.gff", sep = ""))
writeLines(c("##gff-version 3",
             "#!gff-spec-version 1.21",
             "#!processor R script (local) with manual add of top section",
             genomeBuild,
             paste("#!genome-build-accession NCBI_Assembly:", opt$gff, sep = ""),
             paste("#!annotation-date ", Sys.Date(), sep = ""),
             "#!annotation-source sraPlotSummary.R (local version)",
             genomeInfo,
             genomeSpecies), fileConn)
close(fileConn)

cat(paste("Writing the gff output to ", filePath, "/", opt$out_name, "_sra_calls.gff\n", sep = ""))
write.table(x = gff, file = paste(filePath, "/", opt$out_name, "_sra_calls.gff", sep = ""), row.names = F, col.names = F, quote = F, sep = "\t", append = T)



```

###rfamscan

Annotations of known sRNAs in the downloaded annotation file were supplemented by searching for known rFam families in each genome.

```{bash rfamscan, eval = F, echo=F}
rfamscan() { counts=$( bc -l <<< "scale=2;$(esl-seqstat $1.fna | grep ^"Total" | tr -s ' ' | cut -d ' ' -f4)*2/1000000"); cmscan -Z $counts  --cut_ga --rfam --nohmmonly --tblout $1.tblout --fmt 2 --clanin ~/Downloads/Rfam.clanin.txt ~/Downloads/Rfam.cm $1.fna; cmscanToGffWrapper.R -f $1.tblout -g $1;}
```

###cmscanToGFFWrapper.R

The output from running cmscan needs to be in the same format as the rest of the data (GFF3).

```{r cmscanToGFFWrapper.R, eval=F, echo=F}
#!/usr/bin/env Rscript
library('getopt')


spec = matrix(c(
  'cmscanOutput', 'f', 1, "character",
  'gcf', 'g', 1, "character",
  'help' , 'h', 0, "logical",
  'file_path', 'p', 2, "character",
  'out_name', 'o', 2, "character"
), byrow=TRUE, ncol=4)


opt = getopt(spec)
#
# opt$cmscanOutput <- "GCA_000017745.1.tblout"
# opt$gcf <- "GCA_000017745.1"
# opt$file_path <- "~/phd/RNASeq/escherichia/"
# opt$output <- "escherichia_test"

if ( !is.null(opt$help) ) {
  cat("cmscanToGffWrapper.R version 1.0\n\n")
  cat("Use cmscanToGffWrapper.R <options> -f <cmscan ouptut file> -g <gff file>\n\n")
  cat("Options:\n")
  cat("  -f <cmscan ouptut file> The file that contains the cmscan output\n")
  cat("  -g <gff file> The file that contains the gff data. Do not inclue the gff file extension\n")
  cat("  -f <file path> The location of the other files and the output file\n")
  cat("  -o <output file name> The name of the output file. Do not inclue the gff file extension. The default is the same as the gca input\n")
   q(status=1)
}

if ( is.null(opt$cmscanOutput) ) {
  cat("Error: -f <cmscan ouptut file> is required.\n")
  q(status=1)
}
if ( is.null(opt$gcf) ) {
  cat("Error: -g <gff file> is required.\n")
  q(status=1)
}

library(tidyverse)
library(tjnFunctions)

if ( is.null(opt$file_path ) ) { opt$file_path = "." }
if ( is.null(opt$output ) ) { opt$output = opt$gcf }

rfamRes <- read.table(paste(opt$file_path, opt$cmscanOutput, sep = "/"), header = F, comment.char = "#",quote = "", fill = T)


gff <- cmscanToGff(rfamRes = rfamRes)


gffMain <- readLines(paste(opt$file_path, "/", opt$gcf, ".gff", sep = ""))
gffMain <- data.frame(text = gffMain)
genomeInfo <- as.character(gffMain[8,1])
genomeBuild <- as.character(gffMain[4,1])
genomeSpecies <- as.character(gffMain[9,1])
accession <- strsplit(genomeInfo, " ")[[1]][2]

fileConn<-file(paste(opt$file_path, "/",opt$output, "_ncRNA.gff", sep = ""))
writeLines(c("##gff-version 3",
             "#!gff-spec-version 1.21",
             "#!processor R script (local)",
             genomeBuild,
             paste("#!genome-build-accession NCBI_Assembly:", opt$gcf, sep = ""),
             paste("#!annotation-date ", Sys.Date(), sep = ""),
             "#!annotation-source cmscan (rFam) (local version)",
             genomeInfo,
             genomeSpecies), fileConn)
close(fileConn)


write.table(x = gff, file = paste(opt$file_path, "/",opt$output, "_ncRNA.gff", sep = ""), row.names = F, col.names = F, quote = F, sep = "\t", append = T)

```

###combine_gff_files.R

For each genome all of the individual annotation files are combined into a single file with the description column incuding details of the origin of each annotation.

```{r combine_gff_files.R, eval=F, echo=F}
#!/usr/bin/env Rscript
suppressMessages(library('getopt'))


# getopts -----------------------------------------------------------------


spec = matrix(c(
  'sra', 'f', 1, "character",
  'gff', 'g', 1, 'character',
  'help' , 'h', 0, "logical",
  'stranded' , 's', 0, "logical",
  'quiet' , 'q', 0, "logical",
  'file_path', 'p', 2, "character",
  'out_name', 'o', 2, "character",
  'random_data', 'r', 1, "character"
), byrow=TRUE, ncol=4)


opt = getopt(spec)

if ( !is.null(opt$help) ) {
  cat("combine_gff_files.R version 1.0\n")
  cat(" \n")
  cat("Use combine_gff_files.R <options> -f <files>\n")
  cat(" \n")
  cat("Options:\n")
  cat("  -f <files> The gff files\n")
  cat("  -s <stranded data> The data is stranded\n")
  cat("  -r <random data> The file to remove CDS regions from\n")
  cat("  -q <quiet> Do not print any updates\n")
  cat("  -p <file path> The location of the other files and the output file\n")
  cat("  -o <output file name> The name of the output file. Do not inclue the gff file extension. The default is the same as the sra input\n")
  q(status=1)
}

if ( is.null(opt$sra) ) {
  cat("Error: -f <files> is required.\n")
  q(status=1)
}

if ( is.null(opt$out_name) ) {
  cat("Error: -o <output file name> is required.\n")
  q(status=1)
}


# packages ----------------------------------------------------------------


suppressMessages(library(tidyverse))
suppressMessages(library(comparativeSRA))

# defining variables ------------------------------------------------------


if ( is.null(opt$file_path ) ) { opt$file_path = "." }
if ( is.null(opt$out_name ) ) { opt$out_name = opt$sra }
if(is.null(opt$stranded)){
  stranded <- F
}else{
  stranded <- T
}

if(is.null(opt$quiet)){
  quiet <- F
}else{
  quiet <- T
}


#####

file_path <- opt$file_path
files <- list.files(paste(file_path, opt$sra, sep = "/"), pattern = ".gff$")
# import data -------------------------------------------------------------


#print(files)
dat <- data.frame(sequence = as.character("0"), source = as.character("0"), feature = as.character("0"),
                  start = as.integer("0"), end = as.integer("0"), score = as.character("0"),
                  strand = as.character("0"), phase = as.character("0"), Atrribute = as.character("0"), file_name = as.character("start_row"), stringsAsFactors = F)
i <- 2
for(i in 1:length(files)){
  tmp  <- tryCatch({
    suppressWarnings(tmp <- read.table(paste(file_path, opt$sra, files[i], sep = "/"), comment.char = "#", quote = "", sep = "\t", as.is = T))
  }, error =  function(e) {
    cat(paste("Error: ", "row ", i, ", ", file_path, "/", opt$sra, "/", files[i], " cannot be opened.\n", sep = ""))
    cat(paste(e, "\n"))
  })

  if(class(tmp) == "NULL"){
    next
  }

  if(ncol(tmp) != 9){
    cat(paste("Error: ", "row ", i, ", ", file_path, "/", opt$sra, "/", files[i], " contains ", ncol(tmp), " columns.\n", sep = ""))
    next
  }

  colnames(tmp) <- c("sequence", "source", "feature", "start", "end", "score", "strand", "phase", "Atrribute")

  tmp <- tmp%>%mutate(file_name = files[i])%>%mutate(score = as.character(score))

  if(files[i] == opt$random_data){
    tmp <- tmp%>%
  filter(feature != "CDS", feature != "gene", feature != "pseudogene", feature != "exon", feature != "region")
  }else{
  
  dat <- dat%>%bind_rows(tmp)
}
}
if(!is.null(opt$random_data)){
   ncRNAgff <- dat%>%
     filter(feature != "gene", feature != "pseudogene", feature != "exon", feature != "region")
}else{
ncRNAgff <- dat%>%
  filter(feature != "CDS", feature != "gene", feature != "pseudogene", feature != "exon", feature != "region")
}

# main section  -------------------------------------------------------------------


ncRNAgff <- ncRNAgff%>%arrange(start) %>% filter((end - start) > 0)# %>% arrange(strand)


mergedDat <- data.frame(sequence = as.character("0"), feature = as.character("0"),
                        start = as.integer("0"), end = as.integer("0"),
                        strand = as.character("0"), file_names = as.character("start_row"),
                        row_numbers = as.character("0"), prop_overlap = as.numeric(0), new_feature = F,
                        number_of_rnaseq_files = as.integer("0"),
                        score = as.character("0"),
                        stringsAsFactors = F)

##loop through the combined gff files and combine features that overlap
i <- 3
current_feature <- F #is there a current feature being written?
new_feature <- T

for(i in 1:(nrow(ncRNAgff))){
  ##check if the feature is already known
  if(ncRNAgff$source[i] != "sraAlignedncRNAExpression"){
    new_feature <- F
  }

  ##if there is no current feature then set a new start value
  if(current_feature == F){
  start_val <- ncRNAgff$start[i]
  start_i <- i
  end_val <- ncRNAgff$end[i]
  }



  ##set the new end value
  if(ncRNAgff$end[i] > end_val){
  end_val <- ncRNAgff$end[i]
  }

  if(i == nrow(ncRNAgff)){
    
    ##check if the subsequent feature was contained within the first feature
    if(ncRNAgff$end[start_i] < end_val){
      prop_val <- (ncRNAgff$end[start_i] - ncRNAgff$start[i])/(end_val - start_val)
    }else{
      prop_val <- 1
    }
    
    tmp <- data.frame(sequence = ncRNAgff$sequence[i],
                      feature = ncRNAgff$feature[i],
                      start = start_val, end = end_val,
                      strand = ncRNAgff$strand[i],
                      file_names = paste(ncRNAgff$file_name[start_i:i], collapse = ","),
                      row_numbers = paste(c(start_i:i), collapse = ","),
                      prop_overlap = prop_val,
                      new_feature = new_feature,
                      number_of_rnaseq_files = length(start_i:i),
                      score = as.character(ncRNAgff$score[i]),
                      stringsAsFactors = F)
    mergedDat <- mergedDat%>%bind_rows(tmp)
    current_feature <- F
    new_feature <- T
  }else{
    
    
  ##check if the cuurent end value overlaps with the next starting value and update the end value if it does
  if(end_val > ncRNAgff$start[i + 1]){
    end_val <- ncRNAgff$end[i + 1]
    current_feature <- T
  }else{

    ##check if the subsequent feature was contained within the first feature
    if(ncRNAgff$end[start_i] < end_val){
    prop_val <- (ncRNAgff$end[start_i] - ncRNAgff$start[i])/(end_val - start_val)
    }else{
      prop_val <- 1
    }

    tmp <- data.frame(sequence = ncRNAgff$sequence[i],
                      feature = ncRNAgff$feature[i],
                      start = start_val, end = end_val,
                      strand = ncRNAgff$strand[i],
                      file_names = paste(ncRNAgff$file_name[start_i:i], collapse = ","),
                      row_numbers = paste(c(start_i:i), collapse = ","),
                      prop_overlap = prop_val,
                      new_feature = new_feature,
                      number_of_rnaseq_files = length(start_i:i),
                      score = as.character(ncRNAgff$score[i]),
                      stringsAsFactors = F)
    mergedDat <- mergedDat%>%bind_rows(tmp)
    current_feature <- F
    new_feature <- T
  }
  }
}





mergedDat <- mergedDat%>%filter(number_of_rnaseq_files > 0, file_names != "start_row")

# if(!is.null(opt$random_data)){
#   mergedDat <- mergedDat %>% filter(file_names != opt$gff)
# }

mergedDat <- mergedDat %>% mutate(id =  paste(opt$out_name, row_number(), sep = "_"))

cat(paste("Writing the output to ", file_path, "/", opt$out_name, "_new_calls.txt\n", sep = ""))
write.table(x = mergedDat, file = paste(file_path, "/", opt$out_name, "_new_calls.txt", sep = ""), row.names = F, col.names = T, quote = F, sep = "\t")




```


###Summary of Output Data


-   From >21 strains and 11 genera, there were >292 RNA-Seq files.

    -   *Escherichia* and *Shigella* are separated in the pyhlogenetic tree for this data

-   This resulted in ??? expressed regions being predicted.

-   There were ??? known ncRNAs included in the analysis.

------------------------------------------------------------------------

###Combining GFF file

At this stage each individual RNA-Seq file has a corresponding gff file of SRA calls. There is also the original GFF file containing ncRNAs (along with CDS). Predictions of ncRNAs are made using rfam models and the output is made into a GFF file. There are 2 GFF files containing *known* ncRNAs and a number of GFF files containing predicted SRAs.

-   feature files (.gff) files were all combined into a single *ACCESSION*_new_calls.txt file.

    -   [*combine_gff_files.r*](#section-combine_gff_files.r) *(done in gff_files folder)*

-   After combining all the individual calls for each genome there were a total of 8906 putative sRNAs.

-   For each sRNA that was predicted, a random intergenic region was selected.

    -   [*get_random_srna_sequences.py*](#section-get_random_srna_sequences.py) *-a GCA_002208745.1*
    -   the file containing new calls for a given genome was used.
    -   this was done by randomly selecting a start site and taking the sequence from that location (for the same length as the orignial predicted sRNA).
    -   coding regions were removed

-   There were 15,072 random regions chosen

###get_random_srna_sequences.py

A set of 'RNAs' were predicted based on selecting random regions of genomes of the equavilent size to the predicted set in order to give a baseline of what is expected from different sRNA prediction approaches. 

```{bash get_random_srna_sequences_loop, eval = F, echo=F}
for file in *.txt; do accession=`basename $file _new_calls.txt`; echo $accession; get_random_srna_sequences.py -a $accession; done
```

```{python get_random_srna_sequences.py, eval = F, python.reticulate = FALSE, echo=F}
#!/usr/bin/python

'''
file paths are hard coded
'''


import sys
from Bio import SeqIO
import getopt
import os
from BCBio import GFF
from Bio.Seq import Seq
from Bio.Alphabet import generic_dna
import random
import comparativeSRNA as srna


help = '''

'''

def usage():
    print help

def rungetopts():
    try:
        opts, args = getopt.getopt(sys.argv[1:], "a:sqh", ["accession", "shuffle", "quiet", "help"])
    except getopt.GetoptError as err:
        # print help information and exit:
        print(err) # will print something like "option -a not recognized"
        usage()
        sys.exit(2)
    accession = ""
    shuffled = False
    for o, a in opts:
            if o in ("-h", "--help"):
                usage()
                sys.exit()
            elif o in ("-a", "--accession"):
                accession = a
            elif o in ("-s", "--shuffle"):
                shuffled = True
            else:
                assert False, "unhandled option"
    if accession == "":
        print "-a <accession> missing. For more help use -h"
        sys.exit(2)
    return(accession, shuffled)


def main():

    accession, shuffled = rungetopts()
    print "Reading files"
    try:
        inFile = open("/Users/thomasnicholson/phd/RNASeq/new_calls/%s_new_calls.txt" % accession, 'r')

        fileLength = file_len("/Users/thomasnicholson/phd/RNASeq/new_calls/%s_new_calls.txt" % accession)
    except IOError:
        print "/Users/thomasnicholson/phd/RNASeq/new_calls/%s_new_calls.txt not found" % accession
        sys.exit(2)
    try:
        fastaFile = list(SeqIO.parse("/Users/thomasnicholson/phd/RNASeq/sequences/%s.fna" % accession, "fasta"))
    except IOError:
        print "/Users/thomasnicholson/phd/RNASeq/sequences/%s.fna not found" % accession
        sys.exit(2)

    print "Combining contigs"
    my_seq = srna.concatenateSequence(fastaFile)



    print "Getting intergenic sequence"
    random_seq = srna.intergenicSequence(accession, my_seq, shuffled)


    print "Getting intergenic positions"
    positions = srna.intergenicPositions(accession)

    print "Selecting random sRNAs"
    srna.selectRandomLocation(inFile, positions,fileLength, random_seq, accession)





if __name__ == "__main__":
    main()






```

For each genome there is now a single file containing all the SRA calls and whether they were previously found/predicted.

## Search for known ncRNAs and get phylogenetic distance matrix

###Run over subset of genomes for all genera

```{r get_genomes_for_analysis, eval=F}
assembly_summary <- read.table("/Volumes/scratch/brownlab/chrisbr/DB/REFSEQ_REPREF/bacteria/assembly_summary_repref.txt", sep = "\t", fill = T, quote = "", comment.char = "")
assembly_summary <- assembly_summary %>% select(V1, V5, V8, , V18, V20, V12, V6)
colnames(assembly_summary) <- c("accession.1", "type", "species", "accession.2", "genome_link", "assembly.type", "some_number")

assembly_summary <- assembly_summary %>% separate(col = species, into = "genus", sep = " ", extra = 'drop', remove = F)

all_genera <- assembly_summary %>% group_by(genus) %>% summarise(count_all = n())
dat <- assembly_summary %>% filter(assembly.type != "Scaffold")
genera <- dat %>% group_by(genus) %>% summarise(count = n())

genera <- genera %>% full_join(all_genera, by = 'genus')


complete_genomes <- assembly_summary %>% filter(assembly.type == "Complete Genome")
contigs <- assembly_summary %>% filter(assembly.type == "Contig")

complete_genomes <- complete_genomes %>% 
  group_by(genus) %>% 
  mutate(counter = row_number()) %>% 
  filter(counter < 3) %>% 
  mutate(group = "complete")

contigs <- contigs %>% 
  group_by(genus) %>% 
  mutate(counter = row_number() + 2) %>% 
  filter(counter < 5) %>% 
  mutate(group = "contig")

complete_genomes <- complete_genomes %>% 
  bind_rows(contigs) %>% 
  group_by(genus) %>% 
  arrange(counter) %>% 
  mutate(counter.2 = row_number()) %>% 
  filter(counter.2 < 3)

files <- complete_genomes %>% mutate(species.2 = str_replace_all(string = species, pattern = " ", "_")) %>% mutate(file_path = paste(substr(genus, 1, 1), "/", species.2, "-", some_number, "\\#", accession.1, "/", sep = "")) %>% ungroup() %>% select(file_path)

write.table(x = files, file = "~/bin/r_git/R/r_files/server_genomes_file_paths.txt", quote = F, row.names = F, col.names = F)

write.table(x = complete_genomes$accession.2, file = "~/phd/RNASeq/all_taxa_accession.txt", quote = F, row.names = F, col.names = F)
write.table(x = complete_genomes$species, file = "~/phd/RNASeq/all_taxa_names.txt", quote = F, row.names = F, col.names = F)
```

```{r tree_viewer, echo=T, include=F, eval=F}
  tree <- read.tree("~/bin/r_git/R/r_files/genera_11.guide_tree")
  p <-ggtree(tree) + 
  geom_tiplab() +
  xlim(0,0.8)
  p
```

-   cmscan run with commands
    
    - *rfamscan()* is the command called.
    - cmscan -Z $counts --cut_ga --rfam --nohmmonly --tblout $1.tblout --fmt 2 --clanin ~/phd/RNASeq/Rfam.clanin.txt ~/phd/RNASeq/Rfam.cm $1
  
###run_csmscan_across_multiple_files

```{bash run_csmscan_across_multiple_files, eval=F, include=T}
for file in *.fna; 
do 

  runname=`basename $file .fna`;  

  if [ -f "check_files/${runname}.tmp.out" ]; then 
    echo "Already exists: $runname"; 
    continue;
  else 
    echo "$runname";  
  fi;  
  
  rfamscan $file;  
  > check_files/$runname.tmp.out;  

done

```

-   output combined with 'cat *.tblout >> ../representative_genomes.tblout'

-   reformatted for R with 'cat representative_genomes.tblout | sed 's/  /\t/g' | tr -s '\t' | sed 's/\t /\t/g' | sed 's/ \t/\t/g' | sed 's/ /\t/3' | sed 's/ /\t/' | sed 's/ /\t/' | sed 's/ /_/g' | sed 's/_!/\t!/g' | tr -s '\t' | sed 's/Pseudomonas\t/Pseudomonas_/g' > representative_genomes.tab'

-   get a list of contigs and the corresponding genomes

###genome_contig_pairs
```{bash genome_contig_pairs, eval=F}
#done from ~/phd/RNASeq/representative_genomes/
> ../genome_contig_pairs.txt
for file in GC*.fna;  
do   

  ID=`echo $file | cut -d '.' -f1,2 | cut -d "_" -f1,2`;   
  grep ^">" $file | cut -d ' ' -f1 | sort | uniq | sed 's/>//g' | sed -e "s/$/   $ID/" >> ../genome_contig_pairs.txt;   
done
```

###cmsearch_res_pc
```{r cmsearch_res_pc, eval=F}

##file made with cat RF00177.tbl | sed 's/  /\t/g' | tr -s '\t' | sed 's/\t /\t/g' | sed 's/ \t/\t/g' | sed 's/ /\t/3' | sed 's/ /\t/' | sed 's/ /\t/' | sed 's/ /_/g' | sed 's/_!/\t!/g' | tr -s '\t' | sed 's/Pseudomonas\t/Pseudomonas_/g' > RF00177.tab along with manually replacing some incorrect _ and \t 
dat <- read.table("~/phd/RNASeq/representative_genomes.tab", sep = "", quote = "", comment.char = "#", fill = T)

contig_labels <- read.table("~/phd/RNASeq/genome_contig_pairs.txt")
colnames(contig_labels) <- c("query.name", "genome")

dat <- dat[,2:18]

colnames(dat) <- c("description.of.target", "target.name", "query.name", "accession", "accession.2", "mdl", "mdl.from", "mdl.to", "seq.from", "seq.to", "strand", "trunc", "pass", "gc", "bias", "score", "e.value")

dat <- dat %>% filter(!is.na(e.value))

dat <- dat %>% group_by(target.name, query.name) %>% 
  arrange(as.numeric(e.value)) %>% 
  mutate(order.num = row_number()) %>% 
  filter(order.num == 1) %>% 
  ungroup()





smalldat <- dat %>% 
  select(target.name, query.name, seq.from, seq.to, strand, e.value, mdl.from, mdl.to)

smalldat <- smalldat %>% left_join(contig_labels, by = 'query.name') %>% 
  group_by(genome, target.name) %>% 
  arrange(as.numeric(e.value)) %>%
  mutate(order.num = row_number()) %>% 
  filter(order.num == 1) %>% 
  ungroup()

RF00177 <- smalldat %>% filter(target.name == "RF00177") 


for(item in unique(smalldat$target.name)){
  print(item)
  modelDat <- smalldat %>% filter(target.name == item)
  if(nrow(modelDat) == 0){
    continue
  }
  modelDat <- modelDat %>% select(query.name, seq.from, seq.to, strand)
  
write.table(x = modelDat, file = paste("~/phd/RNASeq/rfam_files/locations/", item,"_locations.txt", sep = ""), row.names = F, col.names = F, quote = F, sep = "\t")
  

}

  write.table(x = RF00177 %>% select(query.name, seq.from, seq.to, strand), file = "~/phd/RNASeq/rfam_files/RF00177_locations.txt", row.names = F, col.names = F, quote = F, sep = "\t")


```

-   RF00177 (Ribosome SSU) saved as above.

-   Other models also saved

-   'esl-sfetch --index representative_genomes.fna' used to index the fasta file


###get_nucelotide_sequences

```{bash get_nucelotide_sequences, eval = F}   

##from ~/phd/RNASeq/rfam_files/

# > RF00177_rep_seqs.fna

i=0
file_count=1
> RF00177_files/RF00177_rep_seqs_${file_count}.fna
while read line; 
do 
  i=`expr $i + 1`
  if (( $i > 50 )); then
  i=0
  file_count=`expr $file_count + 1`
  > RF00177_files/RF00177_rep_seqs_${file_count}.fna
  fi

  
  contig=`echo $line | cut -d ' ' -f1`; 
  contig_start=`echo $line | cut -d ' ' -f2`; 
  contig_end=`echo $line | cut -d ' ' -f3`; 
  contig_strand=`echo $line | cut -d ' ' -f4`;  
  
  length=`expr $contig_end - $contig_start`
  
  length=`echo $length | tr -d '-'`
  
  if (( $length < 1400 )); then
  echo "$contig too short" 
  continue
  fi

    esl-sfetch -c ${contig_start}..${contig_end} ../representative_genomes/representative_genomes.fna $contig        >> RF00177_files/RF00177_rep_seqs_${file_count}.fna;

done < RF00177_locations.txt


##from ~/phd/RNASeq/rfam_files/locations
for file in *_locations.txt;
do
outname=`basename $file _locations.txt`

echo $outname

i=0
file_count=1
> ../${outname}_files/${outname}_rep_seqs_${file_count}.fna
while read line; 
do 
  i=`expr $i + 1`
  if (( $i > 50 )); then
  i=0
  file_count=`expr $file_count + 1`
  > ../${outname}_files/${outname}_rep_seqs_${file_count}.fna
  fi

  
  contig=`echo $line | cut -d ' ' -f1`; 
  contig_start=`echo $line | cut -d ' ' -f2`; 
  contig_end=`echo $line | cut -d ' ' -f3`; 
  contig_strand=`echo $line | cut -d ' ' -f4`;  
  
  length=`expr $contig_end - $contig_start`
  
  length=`echo $length | tr -d '-'`
  


    esl-sfetch -c ${contig_start}..${contig_end} ../../representative_genomes/representative_genomes.fna $contig        >> ../${outname}_files/${outname}_rep_seqs_${file_count}.fna;

done < ${outname}_locations.txt



done < $file
done


```


-   Build covariance models (on server)

###make cm files
```{bash make_cm_files, eval=F}
##from ~/phd/RNASeq/rfam_files/

for folder in *_files; 
do 

  
  cmmodel=`basename $folder _files`;  

  
  cmfetch  ~/phd/RNASeq/Rfam.cm $cmmodel > current.cm;
  > $folder/ali_files.txt; 
  
  
  for file in $folder/*.fna; 
  do
  
    shortname=`basename $file`;
    outname=`basename $shortname .fna`;  
    cmalign -g --dnaout -o $folder/$outname.cm current.cm $file;  
    echo "$outname.cm" >> $folder/ali_files.txt;  
    
  done;  
done

```


###remove_empty_files
```{bash remove_empty_files, eval=F}
for folder in *_files; 
do
  cd $folder
  
  > ali_files_2.txt
  
  while read line; 
  do
  
    line_length=`wc -l $line | cut -d ' ' -f1`
    
    if (( $line_length > 0 )); then
      echo $line >> ali_files_2.txt
    fi
    
  done < ali_files.txt
  mv ali_files_2.txt ali_files.txt
  cd ..

done
```

-   Mask to reference and combine the alignments

###combine_alignments
```{bash combine_alignments, eval=F}
for folder in *_files;
do
  cd $folder
  outname=`basename $folder _files`
  echo $outname
  esl-alimerge --list ali_files.txt | esl-alimask --rf-is-mask - > $outname.stk
  cd ..
  
done
```


-   These files are downloaded from the server


-   phylip files shorten IDs to 10 characters. This means there needs to be a lookup table to reverse this in later steps.

###rename_alignment_ids
```{r rename_alignment_ids, eval=F}
dat <- read.table("~/phd/RNASeq/RF00177.stk", sep = "\t", fill = T, comment.char = "", quote = "", header = F)

dat <- dat %>% separate(V1, into = c("a", "b", "c"), sep = " ", extra = 'merge', remove = F)

dat <- dat %>% mutate(id_test = ifelse(grepl(pattern = "/",x = b), T, F))


current_ids <- dat %>% filter(id_test) %>% select(b) %>% unique()

current_ids <- current_ids %>% separate(col = b, into = "id", extra = "drop", remove=F, sep = "/") %>% mutate(phylip_id = substr(x = b, start = 1, stop = 10))

write.csv(x = current_ids, file = "~/phd/RNASeq/uids_RF00177_alignment.txt", quote = F, row.names = F)
save(current_ids, file = "~/bin/r_git/R/r_files/current_ids.Rda")

```

-   RF00177.stk was the name of the file containing the RF00177 alignments for the ~1500 genomes
    
-   esl-reformat phylip RF00177.stk > RF00177_rep_seqs_all.phylip

-   the .phylip file is used with dnadist to create the RF00177_rep_seqs_all.dists file



###reformat_matrix

-   output from dnadist changed into useable matrix

    -   cat  RF00177_rep_seqs_all.dists | tr '\n' ' ' | sed 's/ N/\nN/g' > RF00177_rep_MATRIX_all.dists

-   get the complete list of all query-target so that all contigs in each sRNA are listed.

###query_target_pairs
```{bash query_target_pairs, eval=F}
#done in the alignments file (such as ~/phd/RNASeq/srnas/predicted/combined_alignments_ids/alignments)
#saved on MacBook to .../predicted/
> ../query_target_pairs.txt
for file in *.stk; 
do 
  
  echo $file; 
  ID=`echo $file | cut -d '.' -f1,2 | cut -d "_" -f1,2`; 
  ID_2=`echo $file | cut -d '.' -f1,2 `;  
  grep ^"#=GS" $file | sort | uniq | cut -d "/" -f1 | cut -d ' ' -f2 | cut -d '|' -f2 | sed -e "s/$/   $ID   $ID_2/" >> ../query_target_pairs.txt;  
  
done
```

###dna_dists
```{r dna_dists_setup, eval=F, include=F}
run_all <- F
if(run_all){
dat <- read.table("~/phd/RNASeq/RF00177_rep_MATRIX_all.dists", sep = "", header = F, fill = T, stringsAsFactors = F, as.is = T)

dat <- dat %>% filter(!is.na(V2))


colnames(dat)[1] <- "phylip_id"

"NC_009791." %in% colnames(dat)

colnames(dat) <- c("names", dat$phylip_id)

dat[1:10,1:10]




# rownames(dat) <- colnames(dat)

for(i in 1:nrow(dat)){
  for(j in 2:ncol(dat)){
    # if(dat[i,1] == colnames(dat)[j]){
    #   if(dat[i,j] != 0){
    #     print(paste(i, j))
    #   }
    # }
    if(i + 1 == j){
      print(dat[i,j])
    }
  }
}






meltDat <- melt(dat)

colnames(meltDat) <- c("phylip_id", "query.name", "distance")

load(file = "~/bin/r_git/R/r_files/current_ids.Rda")
current_ids <- current_ids %>% unique()

current_ids <- current_ids %>% separate(col = id, into = c("t1", "t2"), sep = "\\|", remove = F, extra = 'warn') 

current_ids <- current_ids %>% mutate(id = ifelse(is.na(t2), t1, t2)) %>% 
  select(-t1, -t2)


contig_labels <- read.table("~/phd/RNASeq/genome_contig_pairs.txt")
colnames(contig_labels) <- c("id", "target.genome")

contig_labels <- contig_labels %>% left_join(current_ids, by = "id") %>% select(-b)


colnames(contig_labels) <- c("target.id", "target.genome", "phylip_id")


# colnames(contig_labels) <- c("target.name", "target.genome")
# contig_labels <- contig_labels %>% 
  # mutate(target.name = substr(x = target.name, start = 1, stop = 10)) %>% 
  # unique()


meltDat <- meltDat %>% left_join(contig_labels, by = 'phylip_id')

colnames(meltDat)[1:2] <- c("target.name", "phylip_id")

colnames(contig_labels) <- c("query.id", "query.genome", "phylip_id")

meltDat <- meltDat %>% left_join(contig_labels, by = 'phylip_id')

ggplot() +
  geom_freqpoly(data = meltDat, aes(x = distance, y = ..count..), binwidth = 0.05)

tmp <- meltDat %>% filter(distance > 0)


ggplot() +
  geom_freqpoly(data = tmp, aes(x = distance, y = ..count..), binwidth = 0.05)

colnames(meltDat)[2] <- c("query.name")


meltDat <- meltDat %>% filter(!is.na(query.genome), !is.na(target.genome))%>% group_by(target.genome, query.genome) %>% arrange(-as.numeric(distance)) %>% mutate(row_num = row_number()) %>% filter(row_num == 1) %>% select(-row_num)

mat <- reshape2::acast(data = meltDat %>% select(target.genome, query.genome, distance), formula = target.genome ~ query.genome)

distanceMat <- as.data.frame(mat)

save(distanceMat, file = "~/phd/RNASeq/distanceMat.Rda")

load("~/phd/RNASeq/distanceMat.Rda")

pairs <- read.table("~/phd/RNASeq/srna_seqs/version_1/predicted/query_target_pairs.txt")
colnames(pairs) <- c("target.name", "query.genome", "ID")
contig_labels <- read.table("~/phd/RNASeq/genome_contig_pairs.txt")
colnames(contig_labels) <- c("target.name", "target.genome")
pairs <- pairs %>% left_join(contig_labels, by = 'target.name')

pairs <- pairs %>% select(target.genome, ID) %>% unique()

pairs <- pairs %>% mutate_all(as.character)

srnas <- unique(pairs$ID)
max_val <- 0
max_dists <- data.frame(id = srnas, distance = NA)
counter <- 0


max_dists <- max_dists %>% mutate(complete = ifelse(is.na(distance), F, T))
length(unique(pairs$target.genome))


item <- 1

for(item in 1:nrow(max_dists)){
  printRemaining(i = item, length = nrow(max_dists), increment = 1)
  # counter <- counter + 1
  # if(counter > 5){
  #   break
  # }
  if(max_dists$complete[item] == T){
    print(paste(max_dists$id[item], "already done."))
    next
  }
  max_val <- 0
  # print(as.character(max_dists$id[item]))
  df <- pairs %>% filter(ID == as.character(max_dists$id[item])) %>% unique()
  

  if(nrow(df) == 1){
    max_val <- 0
    max_dists$distance[item] <- max_val
    max_dists$complete[item] <- T
    next
  }
genomes <- df$target.genome
rows <- match(x = genomes, table = rownames(distanceMat))
cols <- match(x = genomes, table = colnames(distanceMat))
rows <- rows[!is.na(rows)]
cols <- cols[!is.na(cols)]

max_val <- max(c(max(distanceMat[rows, cols]),max_val))

  max_dists$distance[item] <- max_val
  max_dists$complete[item] <- T
}

max_dists_pred <- max_dists
save(max_dists_pred, file = "~/bin/r_git/R/r_files/max_dists_pred.Rda")



pairs <- read.table("~/phd/RNASeq/query_target_pairs_pc.txt")

colnames(pairs) <- c("target.name", "ID")

pairs <- pairs %>% left_join(contig_labels, by = "target.name")

pairs <- pairs %>% mutate_all(as.character)

srnas <- unique(pairs$ID)
max_val <- 0
max_dists <- data.frame(id = srnas, distance = NA)
counter <- 0


max_dists <- max_dists %>% mutate(complete = ifelse(is.na(distance), F, T))
length(unique(dat$target.genome))


item <- 1

for(item in 1:nrow(max_dists)){
  printRemaining(i = item, length = nrow(max_dists), increment = 1)
  # counter <- counter + 1
  # if(counter > 5){
  #   break
  # }
  if(max_dists$complete[item] == T){
    print(paste(max_dists$id[item], "already done."))
    next
  }
  max_val <- 0
  # print(as.character(max_dists$id[item]))
  df <- pairs %>% filter(ID == as.character(max_dists$id[item])) %>% unique()
  

  if(nrow(df) == 1){
    max_val <- 0
    max_dists$distance[item] <- max_val
    max_dists$complete[item] <- T
    next
  }
genomes <- df$target.genome
rows <- match(x = genomes, table = rownames(distanceMat))
cols <- match(x = genomes, table = colnames(distanceMat))
rows <- rows[!is.na(rows)]
cols <- cols[!is.na(cols)]

max_val <- max(c(max(distanceMat[rows, cols]),max_val))

  max_dists$distance[item] <- max_val
  max_dists$complete[item] <- T
}

max_dists_pc <- max_dists
save(max_dists_pc, file = "~/bin/r_git/R/r_files/max_dists_pc.Rda")




pairs <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/query_target_pairs.txt")
colnames(pairs) <- c("target.name", "query.genome", "ID")
contig_labels <- read.table("~/phd/RNASeq/genome_contig_pairs.txt")
colnames(contig_labels) <- c("target.name", "target.genome")
pairs <- pairs %>% left_join(contig_labels, by = 'target.name')

pairs <- pairs %>% select(target.genome, ID) %>% unique()

pairs <- pairs %>% mutate_all(as.character)

srnas <- unique(pairs$ID)
max_val <- 0
max_dists <- data.frame(id = srnas, distance = NA)
counter <- 0


max_dists <- max_dists %>% mutate(complete = ifelse(is.na(distance), F, T))
length(unique(pairs$target.genome))


item <- 1

for(item in 1:nrow(max_dists)){
  printRemaining(i = item, length = nrow(max_dists), increment = 1)
  # counter <- counter + 1
  # if(counter > 5){
  #   break
  # }
  if(max_dists$complete[item] == T){
    print(paste(max_dists$id[item], "already done."))
    next
  }
  max_val <- 0
  # print(as.character(max_dists$id[item]))
  df <- pairs %>% filter(ID == as.character(max_dists$id[item])) %>% unique()
  

  if(nrow(df) == 1){
    max_val <- 0
    max_dists$distance[item] <- max_val
    max_dists$complete[item] <- T
    next
  }
genomes <- df$target.genome
rows <- match(x = genomes, table = rownames(distanceMat))
cols <- match(x = genomes, table = colnames(distanceMat))
rows <- rows[!is.na(rows)]
cols <- cols[!is.na(cols)]

max_val <- max(c(max(distanceMat[rows, cols]),max_val))

  max_dists$distance[item] <- max_val
  max_dists$complete[item] <- T
}

max_dists_nc <- max_dists
save(max_dists_nc, file = "~/bin/r_git/R/r_files/max_dists_nc.Rda")




pairs <- read.table("~/phd/RNASeq/srna_seqs/version_1/predicted/old/query_target_pairs_nr.txt")
colnames(pairs) <- c("target.name", "query.genome", "ID")
contig_labels <- read.table("~/phd/RNASeq/genome_contig_pairs.txt")
colnames(contig_labels) <- c("target.name", "target.genome")
pairs <- pairs %>% left_join(contig_labels, by = 'target.name')

pairs <- pairs %>% select(target.genome, ID) %>% unique()

pairs <- pairs %>% mutate_all(as.character)

srnas <- unique(pairs$ID)
max_val <- 0
max_dists <- data.frame(id = srnas, distance = NA)
counter <- 0


max_dists <- max_dists %>% mutate(complete = ifelse(is.na(distance), F, T))
length(unique(pairs$target.genome))


item <- 1

for(item in 1:nrow(max_dists)){
  printRemaining(i = item, length = nrow(max_dists), increment = 1)
  # counter <- counter + 1
  # if(counter > 5){
  #   break
  # }
  if(max_dists$complete[item] == T){
    print(paste(max_dists$id[item], "already done."))
    next
  }
  max_val <- 0
  # print(as.character(max_dists$id[item]))
  df <- pairs %>% filter(ID == as.character(max_dists$id[item])) %>% unique()
  

  if(nrow(df) == 1){
    max_val <- 0
    max_dists$distance[item] <- max_val
    max_dists$complete[item] <- T
    next
  }
genomes <- df$target.genome
rows <- match(x = genomes, table = rownames(distanceMat))
cols <- match(x = genomes, table = colnames(distanceMat))
rows <- rows[!is.na(rows)]
cols <- cols[!is.na(cols)]

max_val <- max(c(max(distanceMat[rows, cols]),max_val))

  max_dists$distance[item] <- max_val
  max_dists$complete[item] <- T
}

max_dists_pred_nr <- max_dists
save(max_dists_pred_nr, file = "~/bin/r_git/R/r_files/max_dists_pred_nr.Rda")

}
```

```{r dna_dists, eval=T}
run_all <- F
load("~/bin/r_git/R/r_files/max_dists_pred.Rda")
# load("~/bin/r_git/R/r_files/max_dists_pred_nr.Rda")
load("~/bin/r_git/R/r_files/max_dists_pc.Rda")
load("~/bin/r_git/R/r_files/max_dists_nc.Rda")



max_dists_pred <- max_dists_pred %>% mutate(group = "Predicted")
# max_dists_pred_nr <- max_dists_pred_nr %>% mutate(group = "Predicted NR")
max_dists_pc <- max_dists_pc %>% mutate(group = "Positive Control")
max_dists_nc <- max_dists_nc %>% mutate(group = "Negative Control")


dists <- max_dists_pred %>% bind_rows(max_dists_pc, max_dists_nc) %>% dplyr::rename(max_dist = distance) %>% filter(max_dist != 0)


distsCumulativeCount <- cumulativeCounts(dists = dists, smooth = F)

p <- ggplot() +
  geom_line(data = distsCumulativeCount, aes(x= max_dist, y = cumulative_prop, group = group, colour = group))
p
if(run_all){
ggsave(filename = "~/phd/RNASeq/figures/max_conservation_distance_4.svg", plot = p)
}
```


###large_tree
```{r large_tree, eval=F, include=F}
  # tree <- read.tree("~/bin/r_git/R/r_files/large_labelled_tree.tree")
  tree <- read.tree("~/bin/r_git/R/r_files/all_taxa.tree")
  p <-ggtree(tree) + 
  geom_tiplab() +
  xlim(0,0.8)
  p
  #ggsave(filename = "~/phd/RNASeq/figures/large_tree.svg", device = 'svg', width = 50, height = 50, limitsize = FALSE)
```




##Build families of sRNAs

Each individual sRNA was searched against the complete list of sRNAs in order to cluster the related sRNAs into families. These families were then used to search through all of the genomes in the clade to improve on the number of sequences per family. 

![Figure a. show the clade]()

##Remove redundancy

As there are many sRNAs each comntributing to each model, it is important to enusre that each sequence only shows up in one model rather than several. This means combining the duplicated models to remove redundancy. 

```{r redundancy_check, eval = F, include=F}


load("~/bin/r_git/R/r_files/overlapping_models_ids.Rda") #made from ~/phd/RNASeq/srna_seqs/version_1/positive_control/overlapping_models/overlapping_models_ids.txt

colnames(overlapping_models_ids) <- c("target.id", "query.id")

tbl <- table(overlapping_models_ids[,c('target.id','query.id')])
idsDat <- as.data.frame(as.matrix(tbl))


idsDat$target.id <- as.character(idsDat$target.id)
idsDat$query.id <- as.character(idsDat$query.id)
idsDat <- idsDat %>% filter(Freq > 0)

queryCounts <- idsDat %>% group_by(query.id) %>% summarise(query.count = n()) %>% dplyr::rename(target = query.id)

df <- data.frame(query.name = targets)

df <- df %>% mutate(group = 1)


mat <- reshape2::acast(idsDat, formula = target.id ~ query.id)
mat[is.na(mat)] <- 0
g <- graph.incidence(mat, weighted = T)
g

# svg(filename="~/phd/RNASeq/figures/pc_models.svg", 
#      width=100, 
#      height=100, 
#      pointsize=20)
V(g)$color <- V(g)$type
V(g)$color=gsub("FALSE","red",V(g)$color)
V(g)$color=gsub("TRUE","blue",V(g)$color)
plot(g, edge.color="gray30", vertex.size = 5)
# dev.off()
# 
# p <- ggplot(data = df, aes(target.id, query.id, fill = Freq))+
#  geom_tile(color = "white")+
#  scale_fill_gradient2(low = "white", high = "red", mid = "white", space = "Lab") +
#   theme_minimal()+ 
#  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
#     size = 12, hjust = 1))
# p
# 

```

Checking that the overlapping sRNAs will be combined correctly.

```{python redundacy_test_example}
test_contigs = ['N1', 'N2', 'N3', 'N4']
test_data = {'query_id':['G1', 'G2', 'G3', 'G1', 'G2', 'G3', 'G1', 'G1', 'G3', 'G3', 'G2', 'G3'], 
             'target_contig':['N1', 'N1', 'N1', 'N2', 'N2', 'N2', 'N3', 'N3', 'N3', 'N3', 'N4', 'N4'],
            'target_start':[1, 1, 2, 100, 100, 100, 940, 855, 940, 855, 1010, 1015],
            'target_end':[100, 100, 95, 180, 180, 180, 860, 935, 860, 935, 1110, 1120]}

test_dat = pd.DataFrame(test_data)
print(test_dat)

test_d = {}
for contig in test_contigs:
    print(contig)
    subsetDat =  test_dat.loc[test_dat['target_contig'] == contig]
    print(subsetDat)
    overlap_list = get_overlap_list(subsetDat = subsetDat)
    print(overlap_list)
    test_d = get_overlap_count(overlap_list = overlap_list, d = test_d)

test_d
```

Checking the distribution of overlap %.

-   each of the predicted sRNAs have been used in a searh of ~1500 genomes.
    
    - this was done on the server
    
    - files will need to be transfered to the MacBook for python analysis
    
-   A check for redundancy of sRNAs is needed
    
    -   this will be done by getting the coordinates of each match for each contig and checking for overlapping regions
    
    -   overlapping regions will be merged.

###contigs_and_cordinates_of_matches
```{bash contigs_and_cordinates_of_matches, eval=F}
> ../../predicted_genomic_sequence_matches.txt
for file in *.stk;
do 

  ID=`echo $file | cut -d '.' -f1,2`
  grep ^"#=GS" $file | sort | uniq | cut -d "[" -f1 | sed -e "s/$/   $ID/" | cut -d ' ' -f2- | cut -d '|' -f2 >> ../../predicted_genomic_sequence_matches.txt

done
 
```

-   get the number of sequences in each model for analysis of the distributions in later steps

###get_stats_on_alignments
```{bash get_stats_on_alignments, eval=F}
> ../../original_stats_all.txt

for file in *;
do 

echo $file
esl-alistat $file | sed 's/%//g' | sed 's/Alignment /Alignment_/g' | sed 's/Average /Average_/g' | sed 's/Format: /Format:_/g' | sed 's/Number of sequences/Number_of_sequences/g' | sed -e "s/$/ $file/" >> ../../original_stats_all.txt

done


```

-   there is a faster way of doing these steps with GRanges, however there are thresholds and variables that cannot be controlled so it is nopt being used. It might be possible, however the current method is good enough. 
    
    - I have used this for the negative control group as it is so much faster. Any repeats will use this method

###redundancy_1_R 
```{r redundancy_1_R, eval=F}

dat <- read.table("/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/negative_control/nc_genomic_sequence_matches.txt")

dat <- dat %>% separate(col = V1, into = c("contig", "coordinates"), sep = "\\/", remove = F)

dat <- dat %>% separate(col = coordinates, into = c("start", "stop"), sep = "-", remove = F)

dat <- dat %>% dplyr::rename(srna = V3) %>% select(contig, srna, start, stop) %>% mutate(strand = "+")

dat <- dat %>% mutate(start = as.numeric(start), stop = as.numeric(stop))

dat <- dat %>% mutate(tmpstart = ifelse(start < stop, start, stop),
                      tmpend = ifelse(start > stop, start, stop))

query <- GRanges(seqnames = dat$contig,
                 ranges = IRanges(start = dat$tmpstart, end = dat$tmpend),
                  strand = dat$strand, query_name = dat$srna)


lookup1 <- data.frame(id1 = dat$srna, queryHits = c(1:length(dat$srna)))
lookup2 <- data.frame(id2 = dat$srna, subjectHits = c(1:length(dat$srna)))


tmp <- findOverlaps(query, query, type = 'start')

tmp <- as.data.frame(tmp)

tmp <- tmp %>% left_join(lookup1) %>% left_join(lookup2)

tmp <- tmp %>% filter(id1 != id2)

smallDat <- tmp %>% select(id1, id2) %>% unique()
smallDat <- smallDat %>% mutate_all(as.character)

s2 <- smallDat
s2$id1 <- smallDat$id2
s2$id2 <- smallDat$id1

smallDat <- smallDat %>% bind_rows(s2) %>% unique()

ids <- as.character(unique(dat$srna))
item <- ids[68]
item2 <- "alignments_GCA_000017765.1_689"

groupOverlapItems <- function(smallDat, item, current_ids){
  # print(length(current_ids))
  # print(item)
  if(length(current_ids) == 0){
    current_ids <- item
  }
  df <- smallDat %>% filter(id1 == item)

  if(nrow(df) == 0){
    return(current_ids)
  }
  df$seen <- df$id2 %in% current_ids
  df <- df %>% filter(seen == F)

  if(nrow(df) == 0){
    return(current_ids)
  }
  for(item2 in df$id2){
    current_ids <- unique(c(current_ids, item2))
    current_ids <- groupOverlapItems(smallDat, item2, current_ids)
  }
  return(current_ids)
}

item <- ids[ids == "alignments_GCA_000006945.2_2627"]
tmp <- groupOverlapItems(smallDat, item, current_ids = c())

checked_ids <- c()
for(item in ids){
  if(item %in% checked_ids){
    next
  }
  print(item)
  current_ids <- groupOverlapItems(smallDat, item, current_ids = c())
 
  checked_ids <- c(checked_ids, current_ids)
  
    write.table(x = current_ids, file = paste("~/phd/RNASeq/srna_seqs/version_1/negative_control/combined_alignments_ids/", current_ids[1], "_combined_list.txt", sep = ""), append = T, quote = F, row.names = F, col.names = F)

  # mat <- as.data.frame(t(as.matrix(current_ids)))
  # write.table(mat, file = "~/phd/RNASeq/tmp/nc_overlaps", append = T, quote = F, col.names = F, row.names = F, sep = "\t")
}

```

###redundancy_1 in python

This takes a long time to run.
Not sure that this is needed for anything more than a figure.

```{python redundancy_1, eval=F}
alignment_file_counts = pd.read_csv("/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/predicted/original_stats_all.txt", 
                                    header=None, delim_whitespace=True, names=list('abcdef'))
alignment_file_counts = alignment_file_counts.loc[alignment_file_counts['a'] == 'Number_of_sequences:']
alignment_file_counts = alignment_file_counts[['b', 'c']]
alignment_file_counts.columns = ['count', 'id']
alignment_file_counts['id'] = alignment_file_counts['id'].str.replace('.stk', '')
alignment_file_counts.set_index('id', inplace=True)
target_counts = alignment_file_counts.to_dict()

alignDat = pd.read_csv("/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/predicted/predicted_genomic_sequence_matches.txt", header=None, delim_whitespace=True)
alignDat = alignDat.iloc[:,[0,2]]
alignDat.columns = ["details", "query_id"]
alignDat[["target_contig", "coord"]] = alignDat.details.str.split("/", expand = True)
alignDat[["target_start", "target_end"]] = alignDat.coord.str.split("-", expand = True)
alignDat = alignDat[["query_id", "target_contig", "target_start", "target_end"]]
alignDat["target_start"] = alignDat["target_start"].astype(str).astype(int)
alignDat["target_end"] = alignDat["target_end"].astype(str).astype(int)
alignDat = alignDat.sort_values(by=['target_start'])
alignDat[:10]

target_contigs = alignDat.target_contig.unique()
query_ids = alignDat.query_id.unique()

if run_all == True:
    overlapping_ids = []
    lengths = []
    start_val = 0
    end_val = 0
    overlaps = []
    for contig in target_contigs:
        subsetDat =  alignDat.loc[alignDat['target_contig'] == contig]
        overlaps = get_overlap_vals(subsetDat, overlaps)
    df = pd.DataFrame(data = overlaps)
    df.to_csv('/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/predicted/overlaps_data.csv', index=False)
else:
  overlaps = pd.read_csv("/Users/thomasnicholson/bin/python_git/python_files/overlaps_data.csv",
  header=None, delim_whitespace=True) #might be too big for github

overlaps[:10]

fig = sns.displot(overlaps, kde=True)
figure(figsize = (20,20))
fig.savefig("/Users/thomasnicholson/phd/RNASeq/figures/displot.svg", dpi=100)

```

```{r, echo=FALSE, fig.width=8, fig.height=8}
knitr::include_graphics("/Users/thomasnicholson/phd/RNASeq/figures/displot.svg")
```

Group sRNAs if there is enough of an overlap and write out files. 

###redundancy_2
```{python redundancy_2, eval=F}
run_all = False
if run_all == True:
    d = {}
    for contig in target_contigs:
        print(contig)
        subsetDat =  alignDat.loc[alignDat['target_contig'] == contig]
        overlap_list = srna.get_overlap_list(subsetDat = subsetDat)
        d = srna.get_overlap_count(overlap_list = overlap_list, d = d)
    json_data = json.dumps(d)
    file = open('/Users/thomasnicholson/bin/python_git/python_files/dict.json', 'w')
    file.write(json_data)
    file.close()
    query_matches = {}
    query_counts = {}
    overlap_percentages = []
    threshold = 0
    for i in range(0, len(query_ids) -1):
        for j in range(i + 1, len(query_ids)):
            ids =[query_ids[i], query_ids[j]]
            ids.sort()
            current_id = "_".join(ids)
            count = min([target_counts['count'][query_ids[i]], target_counts['count'][query_ids[j]]])
            count = int(count)
            if current_id in d:
                if d[current_id]/count < 1 and d[current_id]/count > threshold:
                    overlap_percentages.append(d[current_id]/count)
                else:
                    overlap_percentages.append(1)
                if d[current_id]/count > threshold:
                    query_matches[current_id] = d[current_id]/count
                    query_counts[current_id] = [d[current_id]/count, count, d[current_id]]
    json_query_matches = json.dumps(query_matches)
    file = open('/Users/thomasnicholson/bin/python_git/python_files/query_matches.json', 'w')
    file.write(json_query_matches)
    file.close()
    json_query_counts = json.dumps(query_counts)
    file = open('/Users/thomasnicholson/bin/python_git/python_files/query_counts.json', 'w')
    file.write(json_query_counts)
    file.close()
    
    all_overlaps = {}
    ids_checked = []
    for key, value in d.items():
        ids = key.split("_")
        id1 = "_".join(ids[:3])
        id2 = "_".join(ids[3:])
        all_overlaps, ids_checked, make_new, counter = srna.unique_set_of_overlaps(all_overlaps, ids_checked, id1 =
        id1,
        id2 = id2)
        all_overlaps, ids_checked, make_new, counter = srna.unique_set_of_overlaps(all_overlaps, ids_checked, id1 =
        id2, id2 = id1)
        if make_new == True:
            all_overlaps[id1] = [id2]
    json_all_overlaps = json.dumps(all_overlaps)
    file = open('/Users/thomasnicholson/bin/python_git/python_files/all_overlaps.json', 'w')
    file.write(json_all_overlaps)
    file.close()
      
    number_of_ids_overlapping = {}
    for key, value in all_overlaps.items():
        number_of_ids_overlapping[key] = [len(value)]
    
    representative_ids = pd.DataFrame(number_of_ids_overlapping)
    representative_ids = representative_ids.T
    representative_ids.columns = ['id_count']
    representative_ids.index.name = 'id1'
    representative_ids.reset_index(inplace=True)
    representative_ids.to_csv('/Users/thomasnicholson/bin/python_git/python_files/representative_ids.csv', index=False)
    
    df = pd.DataFrame.from_dict(query_counts, orient='index', columns = ['percentage', 'total', 'count'])
    df.index.name = 'id'
    df.reset_index(inplace=True)    
    df.to_csv('/Users/thomasnicholson/bin/python_git/python_files/overlap_values.csv', index=False)
    
    combined_d = {}
    ids_checked = []
    for query in query_ids:
        if query not in ids_checked:
            combined_d, ids_checked = combined_alignments(query = query, combined_d = combined_d, ids_checked = ids_checked, query_matches = query_matches)

    json_combined_d = json.dumps(combined_d)
    file = open('/Users/thomasnicholson/bin/python_git/python_files/combined_d.json', 'w')
    file.write(json_combined_d)
    file.close()

else:
    with open('/Users/thomasnicholson/bin/python_git/python_files/dict.json', 'r') as read_file:
        d = json.load(read_file)
    with open('/Users/thomasnicholson/bin/python_git/python_files/query_counts.json', 'r') as read_file:
        query_counts = json.load(read_file)
    with open('/Users/thomasnicholson/bin/python_git/python_files/all_overlaps.json', 'r') as read_file:
        all_overlaps = json.load(read_file)    
    representative_ids = pd.read_csv('/Users/thomasnicholson/bin/python_git/python_files/representative_ids.csv')
    overlap_values_3 = pd.read_csv('/Users/thomasnicholson/bin/python_git/python_files/overlap_values.csv')    
    
    with open('/Users/thomasnicholson/bin/python_git/python_files/combined_d.json', 'r') as read_file:
        combined_d = json.load(read_file)      
```

Not sure if there is a purpose to this section.

###redundancy_2
```{python overlapping_scores, eval=F}
outfile = open('/Users/thomasnicholson/bin/python_git/python_files/ids_and_overlaps.csv', 'a')
for key, value in query_matches.items():
    names = key.split("_")
    id1 = names[:3]
    id1 = '_'.join(id1)
    id2 = names[3:]
    id2 = '_'.join(id2)
    outfile.write('%s,%s,%s\n' % (id1, id2, value))
```

-   List all the overlapping sRNAs in files

###output_of_list_of_sRNAs_to_combine
```{r output_of_list_of_sRNAs_to_combine, eval = F}
json_file <- "~/bin/python_git/python_files/combined_d.json"
json_data <- fromJSON(file=json_file)

values <- json_data["GCA_002848605.1_280"]


for(i in values[[1]]){
  print(i)
}
  
for(key in json_data){
  values <- json_data[key]
  print(paste("Key: ", key[1], " of length ", length(values[[1]])))
  for(value in values[[1]]){
    write.table(x = value, file = paste("~/phd/RNASeq/srna_seqs/version_1/predicted/combined_alignments_ids/", key[1], "_combined_list.txt", sep = ""), append = T, quote = F, row.names = F, col.names = F)
  }
}

```

-   Take the overlapping sRNAs, extract the fasta sequences and align the sequences.

###combine_sRNAs_bash
```{bash combine_sRNAs_bash, eval=F}
mkdir -p fasta
mkdir -p hmm
mkdir -p alignments

for file in *.txt;
do
max_num="0"
outname=`basename $file _combined_list.txt`
echo $outname
> fasta/$outname.fa
while read line; 
do 

esl-reformat fasta ../large_alignments/alignments/$line.fna.stk.stk.stk >> fasta/$outname.fa

current_num=`esl-alistat ../large_alignments/alignments/$line.fna.stk.stk.stk | grep "Number of sequences" | cut -d ' ' -f 4`

if(( $current_num > $max_num ));
then

max_seq="$line.fna.stk.stk.stk"
max_num="$current_num"
fi

done < $file

hmmbuild hmm/$outname.hmm ../large_alignments/alignments/$max_seq

hmmalign --informat fasta hmm/$outname.hmm fasta/$outname.fa | esl-alimask -g --gapthresh 0.8 -p --pfract 0.5 --pthresh 0.5 - | esl-alimanip   --lnfract 0.6 --lxfract 1.4 --lmin 50 --lmax 500 --detrunc 50 - > alignments/$outname.stk

done


```

-   Get the fasta sequences as done for the known sRNAs

    -   [*get_fasta_sequence*](#get-fasta-sequence)



##Check negative controls

-   I want to remove negative control models that match either positive controls or predicted data as these are not true negative controls

-   manually saved a list of IDs (saved from the ncCovRNA file above) for the negative control set where the mean score >= 100 to a file called high_scoring_rnas.txt

###check_high_scoring_negative_control_sequences
```{bash check_high_scoring_negative_control_sequences, eval=F}

> high_scoring_rnas.fna
while read line;
do
echo $line

sequence=`grep "GC RF" alignments_rnaalifold/alignments_${line}.stk | cut -d ' ' -f3- | tr -d '_'`

echo ">$line" >> high_scoring_rnas.fna
echo $sequence >> high_scoring_rnas.fna

done < high_scoring_rnas.txt
```

-   build an hmm database for positive control and predicted

###build_hmm
```{bash build_hmm, eval=F}

##done in ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/alignments_rnaalifold

group='predicted'

for file in *.stk;
do
outname=`basename $file .stk | cut -d '_' -f2-`

hmmbuild ../hmm/${outname}.hmm $file

done

cd ../hmm/

> ../${group}.hmm

cat *.hmm >> ../${group}.hmm

cd ../

hmmpress ${group}.hmm
```

-   Get all of the fasta sequences

###fetch_all_negative_control_seqs
```{bash fetch_all_negative_control_seqs, eval=F}
##done in ~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/alignments_rnaalifold
for file in *.stk;
do

outname=`basename $file .stk | cut -d '_' -f2-`

esl-reformat fasta $file > ../fasta/${outname}.fna

done
```

-   Compare the hmm database to the fasta files of negative controls

###run_hmmscan
```{bash run_hmmscan, eval=F}

##done in ~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/fasta

group='predicted'

mkdir -p ${group}_output

for file in *.fna;
do
outname=`basename $file .fna`
echo $outname
hmmscan  --tblout ${group}_output/$outname.tbl --noali -E 1e-5 ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/${group}.hmm $file

done

```

###hmmscan_summary
```{bash hmmscan_summary, eval=F}
##done in ~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/fasta/${group}_output/
group='predicted'

> ../${group}_hmmscan.tbl
for file in *.tbl;
do

ID=`basename $file .tbl`; 

grep -v ^"#" $file |  sed -e "s/$/   $ID/" >> ../${group}_hmmscan.tbl
done


```

###hmmscan_analysis
```{r hmmscan_analysis}
pcdat <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/fasta/positive_control_hmmscan.tbl")

pcCounts <- pcdat %>% group_by(V20) %>% summarise(count = n())
pcMeans <- pcdat %>% group_by(V20) %>% summarise(mean.val = mean(V5))

pcSummary <- pcCounts %>% full_join(pcMeans)

# pcSummary <- pcSummary %>% filter(count > 3 | mean.val < 1e-10)

write.table(x = pcSummary %>% select(V20), file = "~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/remove_PC.txt", quote = F, row.names = F, col.names = F)


preddat <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/fasta/positive_control_hmmscan.tbl")

predCounts <- preddat %>% group_by(V20) %>% summarise(count = n())
predMeans <- preddat %>% group_by(V20) %>% summarise(mean.val = mean(V5))

predSummary <- predCounts %>% full_join(predMeans)

# pcSummary <- pcSummary %>% filter(count > 3 | mean.val < 1e-10)

write.table(x = predSummary %>% select(V20), file = "~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/remove_PRED.txt", quote = F, row.names = F, col.names = F)

```



###run_RNAcode.sh
```{bash run_RNAcode.sh, eval=F, include=F}
#!/bin/bash

##makes alignments and running alifoldz and r-scape
##GCA accession number.

usage(){
    echo "sraAlignAndFold.sh is a script for making a multiple sequence alignment and
    getting secondary structure information.  
Usage:
 fetchGenomeGCA.sh [opts] [input]

Options:
	-h	Display this help

Input	       
	-r	Folder location

"
}

while getopts "i:o:h" arg; do
case $arg in
	i) 
	FOLDER=${OPTARG};;
	o) 
	OUTPUT=${OPTARG};;
    h)
		usage
		exit
      ;;    
	\?) 
	echo "Unknown option: -${OPTARG}" >&2; exit 1;;
    esac
done

if [ -z ${FOLDER} ]; then
	FOLDER="./"
fi




mkdir -p "$FOLDER/rnacode_out"



let "fileNum = 0"
for file in alignments/*.stk; #change to _R for positive control
do

checkname=`basename $file .stk`
if [ -f "./rnacode_out/${checkname}.rnacode" ]; then
echo "Already exists: $file"
continue
else

	
nseqs=`esl-alistat $file | grep "Number of sequences" | cut -d ":" -f2`

length=`esl-alistat $file | grep "Alignment length:" | cut -d ":" -f2`
largest_length=`esl-alistat $file | grep "Largest" | cut -d ":" -f2`


if (( $length < 500 )); then

diffLength=`expr $largest_length - $length`

if (( $diffLength > $length ));then
echo "Alignment is poor: $file"
continue
fi

if (( $nseqs > 5000 )); then
echo "Skipping $file (length: $length, nseqs: $nseqs)"
echo "$file (length: $length, nseqs: $nseqs)" >> skipped_alignments.txt
continue
fi

if (( $nseqs < 3 )); then
echo "Skipping $file (length: $length, nseqs: $nseqs)"
#echo "$file (length: $length, nseqs: $nseqs)" >> skipped_alignments.txt
continue
fi

echo "Running RNAcode on $file (length: $length, nseqs: $nseqs)"
	
esl-reformat clustal $file | RNAcode --outfile ./rnacode_out/$checkname.rnacode

fi
fi

done


```

####rnacode_summary
```{bash rnacode_summary, eval=F}
#done on server from ~/phd/RNASeq/srna_seqs/version_1/${group}/combined_alignments_ids/rnacode_out/

group="positive_control"
> ../${group}.rnacode;
for file in *.rnacode;
do  
  ID=`basename $file .rnacode`; 
  cat $file | sed -e "s/$/\t$ID/"  >> ../${group}.rnacode;  
done

```

-   formatting for R

    -   cat negative_control.rnacode | sed 's/N/\tN/g' | grep -v "HSS" | grep -v "====" | grep -v "alignment(s) scored in" | grep -v "Delta" > tmp.rnacode

    -   cat predicted.rnacode | sed 's/N/\tN/g' | grep -v "HSS" | grep -v "====" | grep -v "alignment(s) scored in" | grep -v "Delta" > tmp.rnacode

    -   cat positive_control.rnacode | sed 's/N/\tN/g' | grep -v "HSS" | grep -v "====" | grep -v "alignment(s) scored in" | grep -v "Delta" > tmp.rnacode

####protein_coding_filter
```{r protein_coding_filter, eval=F}
ncDat <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/tmp.rnacode",
                    col.names = c("hss.id", "frame", "length", "from", "to", "seq.name", "start", "end", "score", "p.value", "srna"), fill = T)
ncDat <- ncDat %>% mutate(p.value = as.numeric(as.character(p.value)),
                          length = as.numeric(as.character(length)))
ncDat <- ncDat %>% filter(grepl(pattern = "alignments", hss.id) == F) %>% 
  filter(p.value < 0.05, length > 16)
ncRNAcode <- ncDat
save(ncRNAcode, file = "~/bin/r_git/R/r_files/ncRNAcode.Rda")

write.table(x = ncRNAcode %>% select(srna) %>% unique(), file = "~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/remove_RNAcode.txt", quote = F, row.names = F, col.names = F)

predDat <- read.table("~/phd/RNASeq/srna_seqs/version_1/predicted/large_alignments/tmp.rnacode",
                    col.names = c("hss.id", "frame", "length", "from", "to", "seq.name", "start", "end", "score", "p.value", "srna"), fill = T)
predDat <- predDat %>% mutate(p.value = as.numeric(as.character(p.value)),
                          length = as.numeric(as.character(length)))
predDat <- predDat %>% filter(grepl(pattern = "alignments", hss.id) == F) %>% 
  filter(p.value < 0.05, length > 16)
predRNAcode <- predDat
save(predRNAcode, file = "~/bin/r_git/R/r_files/predRNAcode.Rda")



pcDat <- read.table("~/phd/RNASeq/srna_seqs/version_1/positive_control/large_alignments/tmp.rnacode",
                    col.names = c("hss.id", "frame", "length", "from", "to", "seq.name", "start", "end", "score", "p.value", "srna"), fill = T)
pcDat <- pcDat %>% mutate(p.value = as.numeric(as.character(p.value)),
                          length = as.numeric(as.character(length)))
pcDat <- pcDat %>% filter(grepl(pattern = "alignments", hss.id) == F) %>% 
  filter(p.value < 0.05, length > 16)
pcRNAcode <- pcDat


save(pcRNAcode, file = "~/bin/r_git/R/r_files/pcRNAcode.Rda")
```

-   manual made by adding accessions that I found to definity be matching to something.

-   cat remove_* >> foobar

-   cat foobar | sed 's/alignments_//g' | sort | uniq > remove_ALL.txt

###remove_negative_controls_matching_features
```{bash remove_negative_controls_matching_features, eval=F}
##done in ~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/
mkdir -p rscape_out/ignore
mkdir -p alifold/ignore
mkdir -p RNAAlifold/ignore
mkdir -p alignments_rnaalifold/ignore

file="remove_MANUAL.txt"
while read line;
do
echo $line

mv rscape_out/*${line}*  rscape_out/ignore/
mv alifold/*${line}*  alifold/ignore/
mv RNAAlifold/*${line}*  RNAAlifold/ignore/
mv alignments_rnaalifold/*${line}*  alignments_rnaalifold/ignore/

grep -v $line query_target_pairs.txt > foobar
mv foobar query_target_pairs.txt

done < $file



file="remove_ALL.txt"
while read line;
do
echo $line

mv alifold/alignments_${line}.stk.alifold  alifold/ignore/


done < $file


```

##Score sRNAs


**Scripts involved for scoring the sRNAs**

-   [*run_RNAAlifold.sh*](#section-run_rnaalifold.sh)

    -   Produces the alignment file with predicted secondary structure included (useful for later steps) and a visualisation of the predicted secondary structure.
    
-   [*run_Alifold.sh*](#section-run_alifold.sh) 

    -   Compares the predicted secondary structure to a series of alignments from randomly shuffled sequence to give an idea of the how likley it is that the given secondary structure  could occur by chance (in the form of a z-score of the MFE).

-   [*run_R-scape.sh*](#section-run_r-scape.sh) 

    - Looks for coovaritation in the alignments.

-   [*run_rmfamscan.sh*](#section-run_rmfamscan.sh) *-e* *\<file extentsion\>* *-a*
    
    - Looks for motifs in the sRNAs

------------------------------------------------------------------------

-   Runs RNAAlifold on all *.stk files in an alignments/ folder
    
    -   moves the alignments into a folder
    
    -   moves secondary structure images into a folder
    
    -   can be stopped and restarted
    

###run_RNAAlifold.sh
```{bash run_RNAAlifold.sh, eval=F, include=F}
#!/bin/bash

##makes alignments and running alifoldz and r-scape
##GCA accession number.

usage(){
    echo "sraAlignAndFold.sh is a script for making a multiple sequence alignment and
    getting secondary structure information.  
Usage:
 fetchGenomeGCA.sh [opts] [input]

Options:
	-h	Display this help

Input	       
	-r	Folder location

"
}

while getopts "i:o:h" arg; do
case $arg in
	i) 
	FOLDER=${OPTARG};;
	o) 
	OUTPUT=${OPTARG};;
    h)
		usage
		exit
      ;;    
	\?) 
	echo "Unknown option: -${OPTARG}" >&2; exit 1;;
    esac
done

if [ -z ${FOLDER} ]; then
	FOLDER="./"
fi




mkdir -p "$FOLDER/alifold/post_script"
mkdir -p "$FOLDER/RNAAlifold"
mkdir -p alignments_rnaalifold


let "fileNum = 0"
for file in alignments/*.stk

do
lines=`wc -l < $file`
if (( $lines < 1));then
continue
fi

outname=`basename $file`


if [ -f "$FOLDER/RNAAlifold/$outname.rnaalifold" ]; then
	echo "Already exists: $file"
	continue
fi




echo "Running on: $file"


start=`grep "GCA" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f1`
end=`grep "GCA" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f2`

if [[ $start == "" ]]; then
	start=`grep "NC_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f1`
	end=`grep "NC_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f2`

fi

if [[ $start == "" ]]; then
	start=`grep "NZ_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f1`
	end=`grep "NZ_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f2`

fi

if [[ $start == "" ]]; then
	head $file
fi




length=`expr $end - $start`

if (( $length < 0 )); then
	length=$(( -1 * $length ))
fi

if (( $length < 500 )); then
esl-reformat  clustal $file  | RNAalifold --aln-stk=${file} >> ./RNAAlifold/$outname.rnaalifold
cat alirna.ps > ./alifold/post_script/$outname.ps      
else
	echo "Skipping: $file"
fi

done


for file in alignments_G*;
do
outname=`basename $file .stk.stk`

mv $file ./alignments_rnaalifold/$outname.stk

done
```

-   Combine the output from RNAAlifold into single files for further analysis

####rnaalifold_summary
```{bash rnaalifold_summary, eval=F}
#done from ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/RNAALifold
group="negative_control"
> ../${group}.rnaalifold; 
for file in *.rnaalifold;
do   
  
  if [ $file == *"\.stk\.stk\.rnaalifold" ]; then 
    ID=`basename $file .stk.stk.rnaalifold`; 
  else 
    ID=`basename $file .stk.rnaalifold`; 
  fi; 
  
  MFE=`grep "=" $file | rev | cut -d "(" -f1 | rev | cut -d "=" -f1`; echo "$ID $MFE" >> ../${group}.rnaalifold; 

done
```

-   Positive control set has different naming and needs the files moved with another step

####positive_control_alignments
```{bash move_positive_control_alignments, eval=F}
for file in alignments_R*;
do
  outname=`basename $file .stk.stk`
  mv $file alignments_rnaalifold/$outname.stk
done
```

-   Negative control set has different naming and needs the files moved with another step

####negative_control_alignments
```{bash move_negative_control_alignments, eval=F}
for file in alignments_a*;
do
tmpname=`echo $file | cut -d '_' -f2,3,4,5`
  outname=`basename $tmpname .stk.stk`
  mv $file alignments_rnaalifold/$outname.stk
done
```

###run_R-scape.sh
```{bash run_R-scape.sh, eval=F, include=F}
#!/bin/bash

##makes alignments and running alifoldz and r-scape
##GCA accession number.

usage(){
    echo "sraAlignAndFold.sh is a script for making a multiple sequence alignment and
    getting secondary structure information.  
Usage:
 fetchGenomeGCA.sh [opts] [input]

Options:
	-h	Display this help

Input	       
	-r	Folder location

"
}

while getopts "i:o:h" arg; do
case $arg in
	i) 
	FOLDER=${OPTARG};;
	o) 
	OUTPUT=${OPTARG};;
    h)
		usage
		exit
      ;;    
	\?) 
	echo "Unknown option: -${OPTARG}" >&2; exit 1;;
    esac
done

if [ -z ${FOLDER} ]; then
	FOLDER="./"
fi




mkdir -p "$FOLDER/rscape_out"



let "fileNum = 0"
for file in alignments_G*;
do

checkname=`basename $file .stk`
if [ -f "../rscape_out/${checkname}_1.R2R.sto" ]; then
echo "Already exists: $file"
continue
else

echo "Running R-scape on: $file"
	
fi

time R-scape --r2rall --outdir ../rscape_out/ $file > rsacpe.out

done
```

-   Combine the output from Rscape into single files for further analysis

####rscape_summary
```{bash rscape_summary,eval=F}
#done from ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/rscape_out/

group="negative_control"
> ../${group}.rscape.cov;
for file in *.sorted.cov;
do  
  tmpname=`echo $file | cut -d '_' -f2,3,4`; 
  ID=`basename $tmpname .stk.stk`; 
  cat $file | sed -e "s/$/	$ID/"  >> ../${group}.rscape.cov;  
done

```


###run_Alifold.sh
```{bash run_Alifold.sh, eval=F, include=F}
#!/bin/bash

##makes alignments and running alifoldz and r-scape
##GCA accession number.

usage(){
    echo "sraAlignAndFold.sh is a script for making a multiple sequence alignment and
    getting secondary structure information.  
Usage:
 fetchGenomeGCA.sh [opts] [input]

Options:
	-h	Display this help

Input	       
	-r	Folder location

"
}

while getopts "i:o:h" arg; do
case $arg in
	i) 
	FOLDER=${OPTARG};;
	o) 
	OUTPUT=${OPTARG};;
    h)
		usage
		exit
      ;;    
	\?) 
	echo "Unknown option: -${OPTARG}" >&2; exit 1;;
    esac
done

if [ -z ${FOLDER} ]; then
	FOLDER="./"
fi




mkdir -p "$FOLDER/alifold/post_script"



let "fileNum = 0"
for file in alignments_rnaalifold/*.stk


do

outname=`basename $file`
if [ -f "$FOLDER/alifold/$outname.alifold" ]; then
	#echo "$FOLDER/alifold/$file.alifold"
	echo "Already exists: $file"
	continue
else
	echo "Checking size: $file"
fi


lines=`wc -l < $file`
if (( $lines < 1));then
continue
fi


nseqs=`grep "#=" $file | cut -d ' ' -f2 | sort | uniq | wc -l`


start=`grep "GCA" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f1`
end=`grep "GCA" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f2`

if [[ $start == "" ]]; then
	start=`grep "NC_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f1`
	end=`grep "NC_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f2`

fi

if [[ $start == "" ]]; then
	start=`grep "NZ_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f1`
	end=`grep "NZ_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f2`

fi

if [[ $start == "" ]]; then
	head $file
fi




length=`expr $end - $start`

if (( $length < 0 )); then
	length=$(( -1 * $length ))
fi

if (( $length < 500 )); then

ID=`grep "NC_" $file | head -n 1 | cut -d " " -f2`

if [[ $ID == "" ]]; then
	ID=`grep "NZ_" $file | head -n 1 | cut -d " " -f2`
fi

if [[ $ID == "" ]]; then
	ID=`grep GCA_" $file | head -n 1 | cut -d " " -f2`
fi

if [[ $ID == "" ]]; then
	head $file
else
alignmentLength=`grep $ID $file | grep -v "#" | tr -s ' ' | cut -d ' ' -f2 | wc -c`

diffLength=`expr $alignmentLength - $length`

if (( $diffLength > $length ));then
echo "Alignment is poor: $file"
continue
fi
fi




echo "Running alifoldz.pl on $file (length: $length, nseqs: $nseqs)"

time esl-reformat  clustal $file  | alifoldz.pl > ./alifold/$outname.alifold         
 

else

	echo "Skipping: $file"


fi

done
```


####alifold_summary
```{bash alifold_summary, eval=F}

#done in ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/alifold 

group="negative_control"
> ../${group}.alifold
for file in *.alifold;  
do 

  ID=`echo $file | cut -d '.' -f1,2`; 
  grep -v "#" $file | grep -v "From" | grep -v "\-\-\-" | tr -s ' '  | sed -e "s/$/   $ID/" >> ../${group}.alifold
  
done

```

### run_rmfamscan.sh
```{bash run_rmfamscan.sh, eval=F, include=F}
#!/bin/bash

##Run rmfam over all fasta files

usage(){
    echo "run_rmfam_scan.sh is a script for running rmfam_scan over a set of fasta
    files.  
Usage:
 run_rmfam_scan.sh [opts] [extension]

Options:
	-h	Display this help

Input
	-e extension	       
	-a	align
	-o output
	-k keep tmp files

"
}

align="F"
keep="F"
while getopts "e:ao:hk" arg; do
case $arg in
	e)
		extension=${OPTARG}
		;;
	a) 
		align="T"
		;;
    h)
		usage
		exit
      ;;    
    k)
		keep="T"
      	;;   
	\?) 
	echo "Unknown option: -${OPTARG}" >&2; exit 1;;
    esac
done

COUNTER=0
mkdir -p "rmfam_cmscan"
mkdir -p "rmfam_gff_files"
mkdir -p "rmfam_tblout"


let "fileNum = 0"
if [[ $extension == "fna" ]]; then

	for file in *.$extension
	do
		if [ -f "rmfam_tblout/$file.out.tblout" ]; then
			echo "Already exists: $file"
 			continue
		fi
		length=`grep -v ">" $file | wc -c`
		if (( $length < 500 )); then
			echo "Running rmfam_scan on $file (length: $length)"
			time rmfam_scan.pl -g -f ~/phd/RNASeq/RMfam/scripts/RMfam.cm $file -o $file.out 
			mv *.tblout rmfam_tblout
			mv *.cmscan rmfam_cmscan
			mv *.gff rmfam_gff_files
		else
			echo "Skipping: $file"
		fi
	done
else


for file in *.$extension

do


if [ -f "rmfam_tblout/$file.out.tblout" ]; then
	echo "Already exists: $file"
 	continue
else
echo "Checking size: $file"
fi


lines=`wc -l < $file`
if (( $lines < 1));then
continue
fi

# COUNTER=$((COUNTER+1))
# 
# if (( $COUNTER > 100 )); then
# echo "waiting"
# COUNTER=1
# time wait
# 
# 
# 
# fi


# if [[ $align == "T" ]]; then

# echo "Aligning $file"
# esl-reformat  clustal $file > $file.clustal

nseqs=`grep "#=" $file | cut -d ' ' -f2 | sort | uniq | wc -l`


start=`grep "GCA" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f1`
end=`grep "GCA" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f2`

if [[ $start == "" ]]; then
	start=`grep "NC_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f1`
	end=`grep "NC_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f2`

fi

if [[ $start == "" ]]; then
	start=`grep "NZ_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f1`
	end=`grep "NZ_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f2`

fi

if [[ $start == "" ]]; then
	head $file
fi




length=`expr $end - $start`

if (( $length < 0 )); then
	length=$(( -1 * $length ))
fi

if (( $length < 500 )); then

ID=`grep "NC_" $file | head -n 1 | cut -d " " -f2`

if [[ $ID == "" ]]; then
	ID=`grep "NZ_" $file | head -n 1 | cut -d " " -f2`
fi

if [[ $ID == "" ]]; then
	ID=`grep GCA_" $file | head -n 1 | cut -d " " -f2`
fi

if [[ $ID == "" ]]; then
	head $file
else
alignmentLength=`grep $ID $file | grep -v "#" | tr -s ' ' | cut -d ' ' -f2 | wc -c`

diffLength=`expr $alignmentLength - $length`

if (( $diffLength > $length ));then
echo "Alignment is poor: $file"
continue
fi
fi




echo "Running rmfam_scan on $file (length: $length, nseqs: $nseqs)"

 time rmfam_scan.pl -g -f ~/phd/RNASeq/RMfam/scripts/RMfam.cm $file -o $file.out 
 
 
 mv *.tblout rmfam_tblout
mv *.cmscan rmfam_cmscan
mv *.gff rmfam_gff_files
 
else

	echo "Skipping: $file"


fi

done

fi

cd rmfam_tblout

let "fileNum = 0"

for file in *.tblout

do

sed 's/  /__/g' $file | sed 's/ /--/g' | sed 's/__/ /g' | tr -s ' ' | sed 's/ --/ /g' | sed 's/-- / /g' | sed 's/--!/ !/g' | tr ' ' '\t' | sed 's/--/_/g' > $file.formatted.tblout

done

```


###gc_content

-   In order to get gc content info a fasta file is created for each alignment

-   Along with this file, the reference sequence is written to another main file.

####get_fasta_sequence
```{bash get_fasta_sequence, eval=F}
#done from ~/phd/RNASeq/srna_seqs/version_1/positive_control/large_alignments/alignments 
for file in *.stk;
do
outname=`basename $file .stk`
esl-reformat fasta $file > ../fasta/$outname.fna
done
```


####get_reference_fasta
```{bash get_reference_fasta, eval=F}
#done from ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/alignments 
group='nc'
> ../${group}_rf.fna
for file in *.stk;
do
outname=`basename $file .stk`
echo ">$outname" >> ../${group}_rf.fna
cat $file | grep "#=GC RF" | cut -d ' ' -f3-  | tr -d ' ' >> ../${group}_rf.fna
done
```

-   GC percentage is calculated from the _rf.fna file using:

    -   sRNAGCPercentage.py -i ${group}_rf.fna -o {group}_rf.gc

####sRNAGCPercentage.py
```{python sRNAGCPercentage.py, eval=F, include=F}
#!/usr/bin/python


##import packages
import sys
from Bio import SeqIO
from Bio.SeqUtils import GC
import getopt


help = '''
    sRNAGCPercentage.py v 0.1 (August 2020) is a script for {}.
    Usage:
         sRNAGCPercentage.py [options] <input> <output>
    
    Options:
        -h	Display this help
        -q  Supress messages
    Input
        -i	<input> the input
        -o	<output> the output

    
'''

def usage():
    print help

def rungetopts():
    try:
        opts, args = getopt.getopt(sys.argv[1:], "i:o:qh", ["input", "output", "quiet", "help"])
    except getopt.GetoptError as err:
        print(err)
        usage()
        sys.exit(2)
    input = ""
    output = ""
    for o, a in opts:
            if o in ("-h", "--help"):
                usage()
                sys.exit()
            elif o in ("-i", "--input"):
                input = a
            elif o in ("-o", "--output"):
                output = a
            else:
                assert False, "unhandled option"
    if output == "":
        print "-o <output> missing. For more help use -h"
        sys.exit(2)
    if input == "":
        print "-i <input> missing. For more help use -h"
        sys.exit(2)
    return(input, output)


def main():

    inFile, outFile = rungetopts()
    record = list(SeqIO.parse(inFile, "fasta"))
    output = open(outFile, "a")
    for my_seq in record:
        id = my_seq.id
        gc_value = GC(my_seq.seq)
        output.write("%s\t%s\n" % (id, gc_value))



if __name__ == "__main__":
    main()

```




###get RNA labels from Rfam
```{bash get_rna_labels, eval=F}
> rfam_descriptions.txt
for folder in *_files;
do
outname=`basename $folder _files`
echo $outname
description=`cmfetch  ~/phd/RNASeq/Rfam.cm $outname | grep ^"NAME" | head -n 1 | tr -s ' ' | cut -d ' ' -f2-`

echo "${outname} ${description}" >> rfam_descriptions.txt

done
```

####view_rfam_descriptions
```{r view_rfam_descriptions}
rfam <- read.table("~/phd/RNASeq/srna_seqs/version_1/positive_control/rfam_descriptions.txt", sep = " ")

```

##Results 

-   Analysis of the evolutionary distance of all the sequences in a given sRNA

    -   the maximum distance between sequences in an sRNA was selected 
    
    -   this is then plotted below in a cumulative proportion plot for each of PC, NC and Predicted datasets.

###conservation_distance 
```{r conservation_distance, eval=T}
load("~/bin/r_git/R/r_files/max_dists_pred.Rda")
# load("~/bin/r_git/R/r_files/max_dists_pred_nr.Rda")
load("~/bin/r_git/R/r_files/max_dists_pc.Rda")
load("~/bin/r_git/R/r_files/max_dists_nc.Rda")



max_dists_pred <- max_dists_pred %>% mutate(group = "Predicted")
# max_dists_pred_nr <- max_dists_pred_nr %>% mutate(group = "Predicted NR")
max_dists_pc <- max_dists_pc %>% mutate(group = "Positive Control")
max_dists_nc <- max_dists_nc %>% mutate(group = "Negative Control")


dists <- max_dists_pred %>% bind_rows(max_dists_pc, max_dists_nc) %>% dplyr::rename(max_dist = distance) %>% filter(max_dist != 0)


distsCumulativeCount <- cumulativeCounts(dists = dists, smooth = F)

p <- ggplot() +
  geom_line(data = distsCumulativeCount, aes(x= max_dist, y = cumulative_prop, group = group, colour = group))
p
run_all <- F
if(run_all){
ggsave(filename = "~/phd/RNASeq/figures/max_conservation_distance_5.svg", plot = p)
}

```

-   The ROC curve using conservation distance as a predictor

###conservation_distance_roc_curve
```{r conservation_distance_roc_curve, eval = T}
load( file = "~/bin/r_git/R/r_files/max_dists_pred.Rda")
load(file = "~/bin/r_git/R/r_files/max_dists_pc.Rda")
load(file = "~/bin/r_git/R/r_files/max_dists_nc.Rda")

max_dists_pred <- max_dists_pred %>% mutate(group = "Predicted")
max_dists_pc <- max_dists_pc %>% mutate(group = "Positive Control")
max_dists_nc <- max_dists_nc %>% mutate(group = "Negative Control")


dists <- max_dists_pred %>% bind_rows(max_dists_pc, max_dists_nc) %>% dplyr::rename(max_dist = distance) %>% filter(max_dist > 0)

head(dists)

rocData <- dists %>% filter(group != "Predicted") %>% mutate(response = ifelse(group == "Positive Control", 1, 0))
roc.curve(response = rocData$response, predicted = rocData$max_dist,
          main="ROC curve for Maximum Phylogenetic Distance")

```


-   Tree generated by taking all_taxa_names.txt (made from an earlier section) and using the commontree section of Taxonomy on ncbi and downloading the phylip tree.

-   mv ~/Downloads/phyliptree.phy all_taxa_family.tree to rename and move out of the downloads folder.

-   subset_taxa.tree made by copy/pasting a subset (of the range of taxa I already have).

-   this is converted into genera_subset.txt with: 

    -   cat subset_taxa.tree | sed 's/(//g' | sed 's/)//g' | cut -d ':' -f1 > genera_subset.txt 
    
    -   further \n\n was removed in bbedit


###predicted_data_upsetr
```{r predicted_data_upsetr}

pairs <- read.table("~/phd/RNASeq/srna_seqs/version_1/predicted/query_target_pairs.txt")
colnames(pairs) <- c("target.name", "query.genome", "ID")
contig_labels <- read.table("~/phd/RNASeq/genome_contig_pairs.txt")
colnames(contig_labels) <- c("target.name", "target.genome")
pairs <- pairs %>% left_join(contig_labels, by = 'target.name')

genus_labels <- read.table("~/phd/RNASeq/contig_genus_lables.txt")

colnames(genus_labels) <- c("target.name", "genus")

pairs <- pairs %>% left_join(genus_labels)
repDat <- pairs %>% select(ID, genus) %>% mutate(count = 1)
mat <- reshape2::acast(repDat, formula = ID ~ genus)

upsetDat <- as.data.frame(mat)

upsetDat$names <- row.names(upsetDat)
upsetDat[upsetDat != 0] <- 1

genus_selection <- read.table("~/bin/python_git/python_files/genera_list.txt")

colVals<- match(x = genus_selection$V1, table = colnames(upsetDat))

colVals <- colVals[!is.na(colVals)]

upsetSubset <- upsetDat[,colVals]

UpSetR::upset(upsetSubset, sets = colnames(upsetSubset), mb.ratio = c(0.55, 0.45), order.by = "freq", keep.order = T)

match(x = "GCA_900243355.1_585", row.names(upsetSubset))


upsetSubset[4550,]

write_data <- F
if(write_data){
svg(filename="~/phd/RNASeq/figures/upsetr_plot_pred_2.svg",
     width=15,
     height=10,
     pointsize=12)
UpSetR::upset(upsetSubset, sets = colnames(upsetSubset), mb.ratio = c(0.55, 0.45), order.by = "freq", keep.order = T)

dev.off()
}

```

###pc_data_upsetr
```{r pc_data_upsetr}

pairs <- read.table("~/phd/RNASeq/query_target_pairs_pc.txt")
colnames(pairs) <- c("target.name", "ID")
contig_labels <- read.table("~/phd/RNASeq/genome_contig_pairs.txt")
colnames(contig_labels) <- c("target.name", "target.genome")
pairs <- pairs %>% left_join(contig_labels, by = 'target.name')

genus_labels <- read.table("~/phd/RNASeq/contig_genus_lables.txt")

colnames(genus_labels) <- c("target.name", "genus")

pairs <- pairs %>% left_join(genus_labels)
repDat <- pairs %>% select(ID, genus) %>% mutate(count = 1)
mat <- reshape2::acast(repDat, formula = ID ~ genus)


upsetDat <- as.data.frame(mat)

upsetDat$names <- row.names(upsetDat)
upsetDat[upsetDat != 0] <- 1

genus_selection <- read.table("~/bin/python_git/python_files/genera_list.txt")

colVals<- match(x = genus_selection$V1, table = colnames(upsetDat))

colVals <- colVals[!is.na(colVals)]

upsetSubset <- upsetDat[,colVals]

UpSetR::upset(upsetSubset, sets = colnames(upsetSubset), mb.ratio = c(0.55, 0.45), order.by = "freq", nintersects = 15, keep.order = T)

write_data <- F
if(write_data){
svg(filename="~/phd/RNASeq/figures/upsetr_plot_pc_2.svg",
     width=15,
     height=10,
     pointsize=12)
UpSetR::upset(upsetSubset, sets = colnames(upsetSubset), mb.ratio = c(0.55, 0.45), order.by = "freq", nintersects = 15, keep.order = T)

dev.off()
}

```


###Covariation

-   The files need the ID column to be separated out so these lines need running.

    -   cat predicted.rscape.cov | sed 's/GC/\tGC/g' > tmp.cov

    -   cat negative_control.rscape.cov | sed 's/GC/\tGC/g' > tmp.cov

    -   cat positive_control.rscape.cov | sed 's/RF/\tRF/g' > tmp.cov


####rscape_setup
```{r rscape_setup, eval = F, include=F}
pcCov <- read.table("~/phd/RNASeq/srna_seqs/version_1/positive_control/large_alignments/tmp.cov", sep = "\t", comment.char = "#", as.is = T, header = F, fill = T, col.names = c("V1", "left_pos", "right_pos", "score", "e.value", "substitutions", "V2", "power", "ID"))
ncCov <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/tmp.cov", sep = "\t", comment.char = "#", as.is = T, header = F, fill = T, col.names = c("V1", "left_pos", "right_pos", "score", "e.value", "substitutions", "V2", "power", "ID"))

predCov <- read.table("~/phd/RNASeq/srna_seqs/version_1/predicted/large_alignments/tmp.cov", sep = "\t", comment.char = "#", as.is = T, header = F, fill = T, col.names = c("V1", "left_pos", "right_pos", "score", "e.value", "substitutions", "V2", "power", "ID"))

#colnames(pcCov) <- c("V1", "left_pos", "right_pos", "score", "e.value", "substitutions", "power")
#colnames(ncCov) <- c("V1", "left_pos", "right_pos", "score", "e.value", "substitutions", "power")

pcCov <- pcCov %>% mutate(ID = ifelse(V1 == "no significant pairs", left_pos, ID))


pcCov$score[pcCov$V1 == "no significant pairs"] <- 0
pcCov$e.value[pcCov$V1 == "no significant pairs"] <- 10
pcCov$power[pcCov$V1 == "no significant pairs"] <- 0
pcCov$substitutions[pcCov$V1 == "no significant pairs"] <- 0

pcCov$left_pos[pcCov$V1 == "no significant pairs"] <- "-"
pcCov$right_pos[pcCov$V1 == "no significant pairs"] <- "-"
pcCov$V1[pcCov$V1 == "no significant pairs"] <- "-"

ncCov <- ncCov %>% mutate(ID = ifelse(V1 == "no significant pairs", left_pos, ID))

ncCov$score[ncCov$V1 == "no significant pairs"] <- 0
ncCov$e.value[ncCov$V1 == "no significant pairs"] <- 10
ncCov$power[ncCov$V1 == "no significant pairs"] <- 0
ncCov$substitutions[ncCov$V1 == "no significant pairs"] <- 0

ncCov$left_pos[ncCov$V1 == "no significant pairs"] <- "-"
ncCov$right_pos[ncCov$V1 == "no significant pairs"] <- "-"
ncCov$V1[ncCov$V1 == "no significant pairs"] <- "-"

predCov <- predCov %>% mutate(ID = ifelse(V1 == "no significant pairs", left_pos, ID))


predCov$score[predCov$V1 == "no significant pairs"] <- 0
predCov$e.value[predCov$V1 == "no significant pairs"] <- 10
predCov$power[predCov$V1 == "no significant pairs"] <- 0
predCov$substitutions[predCov$V1 == "no significant pairs"] <- 0

predCov$left_pos[predCov$V1 == "no significant pairs"] <- "-"
predCov$right_pos[predCov$V1 == "no significant pairs"] <- "-"
predCov$V1[predCov$V1 == "no significant pairs"] <- "-"


load("~/bin/r_git/R/r_files/ncRNAcode.Rda")
load("~/bin/r_git/R/r_files/pcRNAcode.Rda")
load("~/bin/r_git/R/r_files/predRNAcode.Rda")

ncRNAcode <- ncRNAcode %>% separate(col = srna, into = c("t1", "t2", "t3"), sep = "_", remove = F, extra = 'merge') %>% mutate(ID = paste(t2, t3, sep = "_")) %>% select(-t1, -t2, -t3) %>%  group_by(ID) %>% mutate(counter = row_number()) %>% filter(counter == 1) %>% select(-counter) %>% ungroup()

pcRNAcode <- pcRNAcode %>% mutate(ID = srna) %>%  group_by(ID) %>% mutate(counter = row_number()) %>% filter(counter == 1) %>% select(-counter) %>% ungroup()
pcCov <- pcCov %>% separate(col = ID, into = c("t1"), sep = "_", remove = F, extra = 'drop') %>% mutate(ID = t1) %>% select(-t1)


predRNAcode <- predRNAcode %>% mutate(ID = srna) %>%  group_by(ID) %>% mutate(counter = row_number()) %>% filter(counter == 1) %>% select(-counter) %>% ungroup()

ncCov <- ncCov %>% left_join(ncRNAcode, by = "ID") 
pcCov <- pcCov %>% left_join(pcRNAcode, by = "ID") 
predCov <- predCov %>% left_join(predRNAcode, by = "ID") 

ncCovRNA <- ncCov %>% filter(is.na(p.value))
ncCovProtein <- ncCov %>% filter(!is.na(p.value))

predCovRNA <- predCov %>% filter(is.na(p.value))
predCovProtein <- predCov %>% filter(!is.na(p.value))

pcCovRNA <- pcCov %>% filter(is.na(p.value))
pcCovProtein <- pcCov %>% filter(!is.na(p.value))

pcIDLen <- length(unique(pcCov$ID))
predIDLen <- length(unique(predCov$ID))
ncIDLen <- length(unique(ncCov$ID))

pcCovMean <- pcCov %>% group_by(ID) %>% summarise(mean_score = mean(score.x))
pcCovCount <- pcCov %>% group_by(ID) %>% summarise(count = n())
pcCovMax <- pcCov %>% group_by(ID) %>% summarise(min_eval = min(e.value))
pcCov <- pcCovMean %>% full_join(pcCovMax, by = "ID") %>% 
  full_join(pcCovCount, by = "ID")

ncCovMean <- ncCovRNA %>% group_by(ID) %>% summarise(mean_score = mean(score.x))
ncCovCount <- ncCovRNA %>% group_by(ID) %>% summarise(count = n())
ncCovMax <- ncCovRNA %>% group_by(ID) %>% summarise(min_eval = min(e.value))
ncCovRNA <- ncCovMean %>% full_join(ncCovMax, by = "ID") %>% 
  full_join(ncCovCount, by = "ID") 

predCovMean <- predCovRNA %>% group_by(ID) %>% summarise(mean_score = mean(score.x))
predCovCount <- predCovRNA %>% group_by(ID) %>% summarise(count = n())
predCovMax <- predCovRNA %>% group_by(ID) %>% summarise(min_eval = min(e.value))
predCovRNA <- predCovMean %>% full_join(predCovMax, by = "ID") %>% 
  full_join(predCovCount, by = "ID")

save(pcCov, file = "pcCovariation.Rda")
save(ncCovRNA, file = "ncCovariation.Rda")
save(predCovRNA, file = "predCovariation.Rda")


```


####rscape
```{r rscape, eval = T}
load("~/bin/r_git/R/pcCovariation.Rda")
load("~/bin/r_git/R/ncCovariation.Rda")
load("~/bin/r_git/R/predCovariation.Rda")

ggplot() +
  geom_freqpoly(data = pcCov, aes(x = mean_score, y = log(..density..)), binwidth = 100) +
  geom_freqpoly(data = ncCovRNA, aes(x = mean_score, y = log(..density..)), binwidth = 100, colour = "blue") +
  geom_freqpoly(data = predCovRNA, aes(x = mean_score, y = log(..density..)), binwidth = 100, colour = "red")

pcCov <- pcCov %>% mutate(response = 1)
ncCovRNA <- ncCovRNA %>% mutate(response = 0)
rocData <- pcCov %>% bind_rows(ncCovRNA) %>% mutate(combined_score = count * mean_score)
roc.curve(response = rocData$response, predicted = rocData$min_eval, 
          main="ROC curve for Covariation Scores")
roc.curve(response = rocData$response, predicted = rocData$mean_score, 
          main="ROC curve for Covariation Scores", add.roc = T)
roc.curve(response = rocData$response, predicted = rocData$count, 
          main="ROC curve for Covariation Scores", add.roc = T)
roc.curve(response = rocData$response, predicted = rocData$combined_score, 
          main="ROC curve for Covariation Scores", add.roc = T)
```





-   made using sRNAGCPercentage.py

    - input is the fasta file

###GC Content
```{r gc_content, eval = T}
pcGC <- read.table("~/phd/RNASeq/srna_seqs/version_1/positive_control/large_alignments/pc_rf.gc", sep = "\t", comment.char = "#", as.is = T, header = F, fill = T)
ncGC <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control_no_shuffle.gc", sep = "\t", comment.char = "#", as.is = T, header = F, fill = T)
predGC <- read.table("~/phd/RNASeq/srna_seqs/version_1/predicted.gc", sep = "\t", comment.char = "#", as.is = T, header = F, fill = T)

pcGC <- pcGC %>% separate(col = V1, into = "ID", extra = "drop", sep = "\\[")
ncGC <- ncGC %>% separate(col = V1, into = "ID", extra = "drop", sep = "\\[")

pcGC <- pcGC %>% mutate(response = 1)
ncGC <- ncGC %>% mutate(response = 0)

rocData <- pcGC %>% bind_rows(ncGC)

roc.curve(response = rocData$response, predicted = rocData$V2,
          main="ROC curve for GC%")


save(pcGC, file= "~/bin/r_git/R/r_files/pcGC.Rda")
save(ncGC, file= "~/bin/r_git/R/r_files/ncGC.Rda")
save(predGC, file= "~/bin/r_git/R/r_files/predGC.Rda")

```

###Secondary Structure

####alifold_setup
```{r alifold_setup, eval = F}
pcAlifold<- read.table("~/phd/RNASeq/srna_seqs/version_1/positive_control/large_alignments/positive_control.alifold", header = F, comment.char = "#", quote = "", sep = "", fill = T, as.is = T, col.names = c( "From",      "To",    "Strand",    "Native.MFE",    "Mean.MFE",     "STDV",      "Z", "ID"))
ncAlifold<- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/negative_control.alifold", header = F, comment.char = "#", quote = "", sep = "", fill = T, as.is = T)

colnames(pcAlifold) <- c( "From",      "To",    "Strand",    "Native.MFE",    "Mean.MFE",     "STDV",      "Z", "ID")
colnames(ncAlifold) <- c( "From",      "To",    "Strand",    "Native.MFE",    "Mean.MFE",     "STDV",      "Z", "ID")

ncAlifold <- ncAlifold %>% filter(grepl(pattern = "GCA_", ID), STDV > 0) 
pcAlifold <- pcAlifold %>% filter(grepl(pattern = "RF", ID), STDV > 0)


pcAlifoldMean <- pcAlifold %>% group_by(ID) %>% summarise(z_mean = mean(as.numeric(Z), na.rm = T))
pcAlifoldMax <- pcAlifold %>% group_by(ID) %>% summarise(z_max = max(as.numeric(Z), na.rm = T))

ncAlifoldMean <- ncAlifold %>% group_by(ID) %>% summarise(z_mean = mean(as.numeric(Z), na.rm = T))
ncAlifoldMax <- ncAlifold %>% group_by(ID) %>% summarise(z_max = max(as.numeric(Z), na.rm = T))

pcAlifold <- pcAlifoldMean %>% full_join(pcAlifoldMax, by = "ID")
ncAlifold <- ncAlifoldMean %>% full_join(ncAlifoldMax, by = "ID")


save(pcAlifold, file = "~/bin/r_git/R/pcAlifold.Rda")
save(ncAlifold, file = "~/bin/r_git/R/ncAlifold.Rda")
```

-   The original ROC plot was showing a flat spot near the start. 

    -   The code below was used to check what this was. 
    -   When the standard deviation is zero then Z scores are meaningless and need removing.
    -   This was added to the above code and fixed the problem.

```{r alifold_check}
load("~/bin/r_git/R/pcAlifold.Rda")
load("~/bin/r_git/R/ncAlifold.Rda")
pcAlifold <- pcAlifold %>% mutate(response = 1)
ncAlifold <- ncAlifold %>% mutate(response = 0)

rocData <- pcAlifold %>% bind_rows(ncAlifold)
rocData <- rocData[!is.na(rocData$z_mean),] 
rocData <- rocData[!is.na(rocData$z_max),] 

library(ROCR)
data(ROCR.simple)
pred <- prediction( rocData$z_mean, rocData$response)
perf <- performance(pred,"tpr","fpr")
plot(perf)
str(perf)

cutoffs <- data.frame(cut=perf@alpha.values[[1]], fpr=perf@x.values[[1]], 
                      tpr=perf@y.values[[1]])

tmp <- rocData %>% filter(z_mean > -0.35, z_mean < 0.06)

```


####alifold

```{r alifold, eval = T}
load("~/bin/r_git/R/pcAlifold.Rda")
load("~/bin/r_git/R/ncAlifold.Rda")

pcAlifold <- pcAlifold %>% mutate(response = 1)
ncAlifold <- ncAlifold %>% mutate(response = 0)



rocData <- pcAlifold %>% bind_rows(ncAlifold)
rocData <- rocData[!is.na(rocData$z_mean),] 
rocData <- rocData[!is.na(rocData$z_max),] 


ggplot() +
  geom_freqpoly(data = rocData, aes(x = z_mean, y = ..count.., group = as.character(response), color = as.character(response)), binwidth = 1)

roc.curve(response = rocData$response, predicted = rocData$z_mean,
          main="ROC curve for Z-score Alifoldz")

rocData %>% group_by(response) %>% summarise(count = n())
rocData %>% group_by(response) %>% filter(z_mean <= -1) %>% summarise(count = n())


```

####MFE
```{r MFE, eval = T, echo=T}
pcMFE <- read.table("~/phd/RNASeq/srna_seqs/version_1/positive_control/large_alignments/positive_control.rnaalifold", sep = "", comment.char = "#", as.is = T, header = F, fill = T)
ncMFE <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/negative_control.rnaalifold", sep = "", comment.char = "#", as.is = T, header = F, fill = T)
predMFE <- read.table("~/phd/RNASeq/srna_seqs/version_1/predicted/large_alignments/predicted.rnaalifold", sep = "", comment.char = "#", as.is = T, header = F, fill = T)

pcMFE <- pcMFE %>% filter(V1 != "From", grepl(pattern = "-", x = V1) ==F, V1 != "ERROR")
ncMFE <- ncMFE %>% filter(V1 != "From", grepl(pattern = "-", x = V1) ==F, V1 != "ERROR")
predMFE <- predMFE %>% filter(V1 != "From", grepl(pattern = "-", x = V1) ==F, V1 != "ERROR")

pcMFE <- pcMFE %>% mutate(group = "Positive Control")
ncMFE <- ncMFE %>% mutate(group = "Negative Control")
predMFE <- predMFE %>% mutate(group = "Predicted")

mfe <- pcMFE %>% bind_rows(ncMFE, predMFE)

ggplot(data = mfe) +
  geom_freqpoly(aes(x = V2, y = ..density.., group = group, colour = group), binwidth = 2)

pcMFE <- pcMFE %>% mutate(response = 1) %>%  filter(!is.na(V2))
ncMFE <- ncMFE %>% mutate(response = 0) %>%  filter(!is.na(V2))

rocData <- pcMFE %>% bind_rows(ncMFE) 

roc.curve(response = rocData$response, predicted = rocData$V2,
          main="ROC curve for MFE")

save(pcMFE, file= "~/bin/r_git/R/r_files/pcMFE.Rda")
save(ncMFE, file= "~/bin/r_git/R/r_files/ncMFE.Rda")
save(predMFE, file= "~/bin/r_git/R/r_files/predMFE.Rda")



```



###ncRNA motifs

```{r motifs, eval = T}

load("~/bin/r_git/R/pcMotif.Rda")
load("~/bin/r_git/R/ncMotif.Rda")
load("~/bin/r_git/R/predMotif.Rda")

load("~/bin/r_git/R/pcDuplicates.Rda")
load("~/bin/r_git/R/ncDuplicates.Rda")

pcDuplicates <- pcDuplicates %>% mutate(keep.row = F)
ncDuplicates <- ncDuplicates %>% mutate(keep.row = F)

pcDuplicates <- pcDuplicates  %>% dplyr::rename(ID = V1)
ncDuplicates <- ncDuplicates  %>% dplyr::rename(ID = V1)


pcMotif <- pcMotif %>% left_join(pcDuplicates, by = "ID")
ncMotif <- ncMotif %>% left_join(ncDuplicates, by = "ID")

pcMotif <- pcMotif %>% mutate(keep.row = ifelse(is.na(keep.row), T, F)) 
ncMotif <- ncMotif %>% mutate(keep.row = ifelse(is.na(keep.row), T, F)) 

pcMotif <- pcMotif %>% filter(keep.row)
ncMotif <- ncMotif %>% filter(keep.row)

pcMotif <- pcMotif %>% select(-keep.row)
ncMotif <- ncMotif %>% select(-keep.row)

ncMotif <- ncMotif %>% mutate(response = 0)
pcMotif <- pcMotif %>% mutate(response = 1)

rocData <- pcMotif %>% bind_rows(ncMotif)

roc.curve(response = rocData$response, predicted = rocData$max_score,
          main="ROC curve for MFE")

```

```{r motifs_setup, eval=F}
pcMotif <- read.table("~/phd/RNASeq/srna_seqs/version_1/positive_control/positive_control.rmfam", sep = "", comment.char = "#", as.is = T, header = F, fill = T)
ncMotif <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/negative_control.rmfam", sep = "", comment.char = "#", as.is = T, header = F, fill = T)

predMotif <- read.table("~/phd/RNASeq/srna_seqs/version_1/predicted/predicted.rmfam", sep = "", comment.char = "#", as.is = T, header = F, fill = T)

colnames(pcMotif) <- c("seqname", "source", "feature", "start", "end", "score", "strand", "frame", "attribute", "ID")
colnames(ncMotif) <- c("seqname", "source", "feature", "start", "end", "score", "strand", "frame", "attribute", "ID")
colnames(predMotif) <- c("seqname", "source", "feature", "start", "end", "score", "strand", "frame", "attribute", "ID")

pcMotifMean <- pcMotif %>% group_by(ID) %>% summarise(mean_score = mean(score))
pcMotifMax <- pcMotif %>% group_by(ID) %>% summarise(max_score = max(score))

pcMotif <- pcMotifMean %>% full_join(pcMotifMax, by = "ID")


ncMotifMean <- ncMotif %>% group_by(ID) %>% summarise(mean_score = mean(score))
ncMotifMax <- ncMotif %>% group_by(ID) %>% summarise(max_score = max(score))
ncMotif <- ncMotifMean %>% full_join(ncMotifMax, by = "ID")

predMotifMean <- predMotif %>% group_by(ID) %>% summarise(mean_score = mean(score))
predMotiffMax <- predMotif %>% group_by(ID) %>% summarise(max_score = max(score))

predMotif <- predMotifMean %>% full_join(predMotiffMax, by = "ID")


save(pcMotif, file = "~/bin/r_git/R/pcMotif.Rda")
save(ncMotif, file = "~/bin/r_git/R/ncMotif.Rda")
save(predMotif, file = "~/bin/r_git/R/predMotif.Rda")

```

###RandomForest

```{r random_forest, eval=F}
load("~/bin/r_git/R/r_files/pcMFE.Rda")
load("~/bin/r_git/R/r_files/ncMFE.Rda")

pcMFE <- pcMFE %>%  %>% mutate(ID = V1) %>% select(ID, V2) %>% dplyr::rename(mfe_score = V2)
ncMFE <- ncMFE %>% separate(V1, into = c("t1", "ID_1", "ID_2", "ID_3"), remove = T, extra = "drop", sep = "_") %>% mutate(ID = paste(ID_1, ID_2, ID_3, sep = "_")) %>% select(ID, V2) %>% dplyr::rename(mfe_score = V2)

load("~/bin/r_git/R/r_files/pcGC.Rda")
load("~/bin/r_git/R/r_files/ncGC.Rda")

pcGC <- pcGC %>% group_by(V1) %>% summarise(gc_score = mean(V2))%>% dplyr::rename(ID = V1)
ncGC <- ncGC %>% group_by(V1) %>% summarise(gc_score = mean(V2)) %>% dplyr::rename(ID = V1)

load("maxDistsPC.Rda") #variablename: distsPositive
load("maxDistsNC.Rda") #variablename: distsNegative

distsPositive <- distsPositive %>% dplyr::rename(ID = query.name)
distsNegative <- distsNegative %>% dplyr::rename(ID = query.name)

ncReadDepths <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_read_depths.txt", header = T, sep = "\t")
pcReadDepths <- read.table("~/phd/RNASeq/srna_seqs/version_1/positive_control_read_depths.txt", header = T, sep = "\t")

load("pcCovariation.Rda") #variablename: pcCov
load("ncCovariation.Rda") #variablename: ncCov

pcCov <- pcCov %>% dplyr::rename(mean_cov = mean_score, min_eval_cov = min_eval)
ncCov <- ncCov %>% dplyr::rename(mean_cov = mean_score, min_eval_cov = min_eval)

load("pcMotif.Rda") #variablename: pcMotif
load("ncMotif.Rda") #variablename: ncMotif

pcMotif <- pcMotif %>% dplyr::rename(mean_motif = mean_score, max_motif = max_score)
ncMotif <- ncMotif %>% dplyr::rename(mean_motif = mean_score, max_motif = max_score)

load("pcAlifold.Rda") #variablename: pcAlifold
load("ncAlifold.Rda") #variablename: ncAlifold

pcDat <- pcMFE %>% 
  full_join(pcGC, by = "ID") %>% 
  full_join(distsPositive, by = "ID") %>% 
  full_join(pcReadDepths, by = "ID") %>% 
  full_join(pcCov, by = "ID") %>% 
  full_join(pcMotif, by = "ID")%>% 
  full_join(pcAlifold, by = "ID") %>% 
  mutate(group = "Positive Control")


ncDat <- ncMFE %>% 
  full_join(ncGC, by = "ID") %>% 
  full_join(distsNegative, by = "ID") %>% 
  full_join(ncReadDepths, by = "ID") %>% 
  full_join(ncCov, by = "ID") %>% 
  full_join(ncMotif, by = "ID")%>% 
  full_join(ncAlifold, by = "ID") %>% 
  mutate(group = "Negative Control")


dat <- pcDat %>% bind_rows(ncDat)%>% 
  select(-mean_median, -mean_max, -median_mean, -median_median, -median_max, -max_mean, -max_median, -ID_2)

dat <- dat[,c(5, 1:4, 6:13)]

dat$mfe_score[is.na(dat$mfe_score)] <- 0
dat$gc_score[is.na(dat$gc_score)] <- 50
dat$max_dist[is.na(dat$max_dist)] <- 0
dat$mean_mean[is.na(dat$mean_mean)] <- 0
dat$max_max[is.na(dat$max_max)] <- 0
dat$mean_cov[is.na(dat$mean_cov)] <- 0
dat$min_eval_cov[is.na(dat$min_eval_cov)] <- 10
dat$mean_motif[is.na(dat$mean_motif)] <- 0
dat$max_motif[is.na(dat$max_motif)] <- 0
dat$z_mean[is.na(dat$z_mean)] <- 10
dat$z_max[is.na(dat$z_max)] <- 10




load("~/bin/r_git/R/pcDuplicates.Rda")
load("~/bin/r_git/R/ncDuplicates.Rda")

pcDuplicates <- pcDuplicates %>% mutate(keep.row = F)
ncDuplicates <- ncDuplicates %>% mutate(keep.row = F)

pcDuplicates <- pcDuplicates  %>% dplyr::rename(ID = V1)
ncDuplicates <- ncDuplicates  %>% dplyr::rename(ID = V1)

duplicates <- pcDuplicates %>% bind_rows(ncDuplicates)

dat <- dat %>% left_join(duplicates, by = "ID")

dat <- dat %>% mutate(keep.row = ifelse(is.na(keep.row), T, F)) 

dat <- dat %>% filter(keep.row)

dat <- dat %>% select(-keep.row)

dat <- dat %>% select(-ID)
set.seed(101)
randomNum <- runif(n = nrow(dat), min = 0, max = 1)

dat$random <- randomNum
dat2 <- dat %>% mutate(group = ifelse(group == "Positive Control", 1, 0)) #%>% select(-na_count)

dat2$group <- as.factor(dat2$group) 

data_set_size <- floor(nrow(dat2)/2)
indexes <- sample(1:nrow(dat2), size = data_set_size)

training <- dat2[indexes,]
validation1 <- dat2[-indexes,]

rf_classifier = randomForest(group ~ ., data=training, ntree=100, importance=TRUE)
rf_classifier
varImpPlot(rf_classifier)

# Make predictions
prediction_for_table <- predict(rf_classifier,validation1[,-1])
table(observed=validation1[,1],predicted=prediction_for_table)
prediction_for_roc_curve <- predict(rf_classifier,validation1[,-1],type="prob")
dat3 <- dat %>% select(-group) 
corMat <- cor(dat3, method = "spearman")
round(corMat, 2)
  get_lower_tri<-function(cormat){
    cormat[upper.tri(cormat)] <- NA
    return(cormat)
  }
  get_upper_tri <- function(cormat){
    cormat[lower.tri(cormat)]<- NA
    return(cormat)
  }
upper_tri <- get_upper_tri(corMat)

melted_cormat <- melt(upper_tri, na.rm = TRUE)
p <- ggplot(data = melted_cormat, aes(Var2, Var1, fill = value))+
 geom_tile(color = "white")+
 scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
   midpoint = 0, limit = c(-1,1), space = "Lab", 
   name="Pearson\nCorrelation") +
  theme_minimal()+ 
 theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 12, hjust = 1))+
 coord_fixed()
p
ggsave(filename = "~/phd/RNASeq/figures/corrmat.svg", plot = p)


write_data <- F
if(write_data){
svg(filename="~/phd/RNASeq/figures/random_forest.svg",
     width=20,
     height=20,
     pointsize=12)
varImpPlot(rf_classifier)


dev.off()
}
```
