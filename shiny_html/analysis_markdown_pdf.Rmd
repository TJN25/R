---
title: "Comparative RNA-Seq Analysis"
author: "Thomas Nicholson"
date: "14/09/2020"
output: 
  html_document:
    toc: true
    toc_depth: 4
    toc_float: true
    number_sections: true
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(warn = -1) 
# suppressMessages(library(comparativeSRA))
library(tidyverse)
library(VennDiagram)
library(shiny)
library(ggplot2)
library(gplots)
library(viridis)
library(RColorBrewer)
#library(stringr)
#library(plyr)
library(devtools)
#library(tidyr)
library(shinyjs)
library(shinyWidgets)
library(DT)
library(lubridate)
library(dplyr)
library(svglite)
library(genoPlotR)
library(drake)
library(ape)
library(Biostrings)
library(ggtree)
# library(treeio)
library(geiger)
library(ROSE)
library(reshape2)
library(igraph)
library("viridis") 
library(randomForest)
library(ROCR)
library(corrplot)
library(kableExtra)
library(reticulate)
library(rjson)
filePath <- "~/phd/RNASeq/r_files/"
# use_python("/Users/thomasnicholson/anaconda3/bin/python")
# use_condaenv("comparativesrna")
source('~/bin/r_git/R/render_toc.R')
```
```{r functions, include=F}
plotKnownvsConserved <- function(dat, columns, not_zero = F){
  dat <- dat%>%mutate(conserved = F)
if(not_zero){
  for(i in 1:nrow(dat)){
    dat[i, ncol(dat)] <- ("1" %in% dat[i, columns])
    if(dat[i, ncol(dat)] == F){
    dat[i, ncol(dat)] <- ("0-1" %in% dat[i, columns])
    }

  }
}else{
  for(i in 1:nrow(dat)){
    dat[i, ncol(dat)] <- ("1" %in% dat[i, columns])
  }
}


  conservedSet <- dat%>%filter(conserved)
  knownSet <- dat%>%filter(new_feature == F)

  vennSet <- conservedSet%>%bind_rows(knownSet)%>%unique()



  area1 <- nrow(subset(vennSet, conserved == T))
  area2 <- nrow(subset(vennSet, new_feature == F))
  cross.area <- nrow(subset(vennSet, new_feature == F & conserved == T))

  grid.newpage()
  draw.pairwise.venn(area1 = area1, area2 = area2, cross.area = cross.area, fill = c("blue", "red"),
                     scaled = T,
                     #cat.default.pos= "text",
                     #cat.pos = c(-50, 50),
                     #category = c("Conserved and Expressed", "Known")
                     category = c("", "")
  )
}

assignConservationLevel <- function(ids_lookup, main_col = 7, genera_col, species_col, any_col = c(7:ncol(ids_lookup))){
  ids_lookup <- ids_lookup%>%mutate(type = "")
  for(i in 1:nrow(ids_lookup)){
    if("1" %in% ids_lookup[i, main_col]){
      ids_lookup[i, ncol(ids_lookup)] <- "Family_1"
    }else if("0-1" %in% ids_lookup[i, main_col]){
      ids_lookup[i, ncol(ids_lookup)] <- "Family_0-1"
    }else if("1" %in% ids_lookup[i, genera_col]){
      ids_lookup[i, ncol(ids_lookup)] <- "Genera_1"
    }else if("0-1" %in% ids_lookup[i, genera_col]){
      ids_lookup[i, ncol(ids_lookup)] <- "Genera_0-1"
    }else if("1" %in% ids_lookup[i, species_col]){
      ids_lookup[i, ncol(ids_lookup)] <- "Species_1"
    }else if("0-1" %in% ids_lookup[i, species_col]){
      ids_lookup[i, ncol(ids_lookup)] <- "Species_0-1"
    }else if("1" %in% ids_lookup[i, any_col]){
      ids_lookup[i, ncol(ids_lookup)] <- "Species_1"
    }else if("0-1" %in% ids_lookup[i, any_col]){
      ids_lookup[i, ncol(ids_lookup)] <- "Species_0-1"
    }

  }
  return(ids_lookup)
}
firstup <- function(x) {
  substr(x, 1, 1) <- toupper(substr(x, 1, 1))
  x
}

cumulativeCounts <- function(dists, smooth = T){

  groups <- unique(dists$group)
  for(i in groups){
    dat <- dists %>% filter(group == i)
    dat <- dat %>% mutate(count = 1) %>% 
    arrange(-max_dist) %>% group_by(group) %>% 
    mutate(cumulativeCount = cumsum(count)) %>% ungroup() %>% 
    group_by(group, max_dist) %>% summarise(cumulative_prop = max(cumulativeCount)/ nrow(dat))
    
    if(smooth){
      dat <- as.data.frame(spline(x = dat$max_dist,y =  dat$cumulative_prop))
    }
    dat <- dat %>% ungroup() %>% mutate(group = i)
    if(exists('combinedDat')){
      combinedDat <- combinedDat %>% bind_rows(dat)
    }else{
      combinedDat <- dat 
    }
  }
  return(combinedDat)  

}

```
```{python pysetup, include=F}
import sys
from Bio import SeqIO
import Bio
import pandas as pd
import seaborn as sns
import os
import random
#from BCBio import GFF
from Bio.Seq import Seq
import matplotlib.pyplot as plt
import numpy as np
from pylab import savefig
from matplotlib.pyplot import figure
import json
run_all = False
```
```{python py_functions, include=F}
def package_test():
	print("comparativesrna.py loaded")

def file_len(fname):
    with open(fname) as f:
        for i, l in enumerate(f):
            pass
    return i


def intergenicSequence(accession, my_seq, shuffled):
    start = 0
    end = 0
    random_seq = Seq("AG", generic_dna)
    try:

        in_handle = open("/Users/thomasnicholson/phd/RNASeq/sequences/%s.gff" % accession)
        for rec in GFF.parse(in_handle):
            for feature in rec.features:
                qualifiers = feature.qualifiers
                try:
                    location = feature.location
                    end = location.start
                    intergeneicSeq = my_seq[start:end]
                    if shuffled == True:
                        shuffledSeq = ''.join(random.sample(str(intergeneicSeq), len(intergeneicSeq)))
                        random_seq = random_seq + shuffledSeq
                    else:
                        random_seq = random_seq + intergeneicSeq
                    start = location.end
                    #print(len(random_seq))
                except KeyError:
                    pass

        in_handle.close()

    except IOError:
        print("/Users/thomasnicholson/phd/RNASeq/sequences/%s.gff not found" % accession)
        sys.exit(2)
    return random_seq


def intergenicPositions(accession):
    start = 0
    end = 0
    positions = [0]
    try:

        in_handle = open("/Users/thomasnicholson/phd/RNASeq/sequences/%s.gff" % accession)
        for rec in GFF.parse(in_handle):
            i = 0
            for feature in rec.features:
                qualifiers = feature.qualifiers
                try:
                    qualifiers['gene_biotype']
                except KeyError:
                    continue
                try:
                    i += 1
                    location = feature.location
                    end = location.start - 49
                    if end < start:
                        continue
                    tmpPos = range(start,end)
                    positions = positions + tmpPos
                    start = location.end + 50
                except KeyError:
                    pass

        in_handle.close()

    except IOError:
        print("/Users/thomasnicholson/phd/RNASeq/sequences/%s.gff not found" % accession)
        sys.exit(2)
    return positions


def makeoutputdirectory(write_path):
    if os.path.isdir(write_path) == False:
        try:
            os.mkdir(write_path)
        except OSError:
            print("Creation of the directory %s failed" % write_path)
            sys.exit(2)
    directory = os.listdir(write_path)
    if len(directory) != 0:
        print("Examples of files in %s" % write_path)
        print(directory[0:4])
        query_user = input("%s is not an empty directory. Continue anyway y/n (this may write over existing files): " % write_path)
        if query_user == "y":
            print("Using %s as directory" % write_path)
        else:
            print("Exiting script")
            sys.exit(2)


def concatenateSequence(fastaFile):
    my_seq = fastaFile[0].seq
    i = 0
    for seq in fastaFile:
        if i == 0:
            i += 1
            continue
        i += 1
        my_seq = my_seq + seq.seq
    return my_seq


def selectRandomLocation(inFile, positions,fileLength, random_seq, accession):

    randomFile = open("/Users/thomasnicholson/phd/RNASeq/new_calls/random/python_version_1/%s_random_no_shuffle_new_calls.txt" % accession, "w")
    randomFile.write("start\tend\tstrand\tsequence\n")

    shuffledIndexes = random.sample(positions, fileLength)
    seqLength = len(random_seq)
    seqIndexes = random.sample(range(0,seqLength), fileLength)

    srnaLengths = []
    srnaStrands = []
    srnaIDs = []
    i = 0
    for line in inFile:
        i += 1
        words = line.rstrip()
        words = words.split("\t")
        start = words[2]
        try:
            start = int(start)
        except ValueError:
            continue
        end = words[3]
        end = int(end)
        srna = words[-1]
        srna_length = end - start
        srnaLengths.append(srna_length)
        strand = words[4]
        srnaStrands.append(strand)
        srnaIDs.append(srna)
    for i in range(0,len(shuffledIndexes)):
        index = shuffledIndexes[i]
        length = srnaLengths[i]
        strand = srnaStrands[i]
        seqIndex = seqIndexes[i]
        srna = srnaIDs[i]
        if strand == "+":
            start = index
            end = start + length
            seqStart = seqIndex
            seqEnd  = seqStart + length
        else:
            end = index
            start = end - length
            seqEnd = seqIndex
            seqStart  = seqEnd - length
        if start < 1:
            continue
        if end < 1:
            continue
        if length < 50:
            continue
        if length > 500:
            continue
        if seqStart < 1:
            continue
        if seqEnd < 1:
            continue
        if seqEnd > seqLength:
            continue
        if seqStart > seqLength:
            continue
        sequence  = random_seq[seqStart:seqEnd]
        randomFile = open("/Users/thomasnicholson/phd/RNASeq/new_calls/random/python_version_1/%s_random_no_shuffle_new_calls.txt" % accession, "a")
        randomFile.write("%s\t%s\t%s\t%s\n" % (start, end, strand, sequence))

        srna_type = "random"

        write_path = "/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/negative_control_no_shuffle"
        srnaFile = open("%s/%s.fna" % (write_path, accession), "a")
        srnaFile.write(">%s[%s-%s,%s,%s]\n%s\n" % (srna, seqStart, seqEnd, strand, srna_type, sequence))


def getreaddepths(accession):
    try:
        df = None
        for filename in os.listdir("/Users/thomasnicholson/phd/RNASeq/plot_files/%s/" % accession):
            filesize = os.path.getsize(
                "/Users/thomasnicholson/phd/RNASeq/plot_files/%s/%s" % (accession, filename))
            if filesize == 0:
                print("No data in %s" % filename)
                continue
            plotFile = pd.read_csv(
                os.path.join("/Users/thomasnicholson/phd/RNASeq/plot_files/%s/" % accession, filename),
                sep='\t', header=None)
            print(filename)
            plotFile['selected'] = plotFile.iloc[:].max(axis=1)
            tmpDf = plotFile.iloc[:, 2]
            if df is not None:
                df = pd.concat([df.reset_index(drop=True), tmpDf], axis=1)
            else:
                df = tmpDf
        dfOut = df
        dfOut['mean'] = df.iloc[:].mean(axis=1)
        dfOut['median'] = df.median(axis=1)
        dfOut['max'] = df.max(axis=1)
        return dfOut

    except IOError:
        print("Cannot open a file in /Users/thomasnicholson/phd/RNASeq/plot_files/%s/" % accession)


def sRNA_read_depths(inFile, read_depths_df,accession, random):
    if random == False:
        outFile  = open("/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/read_depths/%s_read_depths.txt" % accession, 'w')
        outFile.write("ID\tstart\tend\tgroup\tfeature\tmean_mean\tmean_median\tmean_max\tmedian_mean\tmedian_median\tmedian_max\tmax_mean\tmax_median\tmax_max\n")
        outFile.close()
        outFile  = open("/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/read_depths/%s_read_depths.txt" % accession, 'a')
    else:
        outFile  = open("/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/read_depths_negative_control/%s_read_depths.txt" % accession, 'w')
        outFile.write("ID\tstart\tend\tgroup\tfeature\tmean_mean\tmean_median\tmean_max\tmedian_mean\tmedian_median\tmedian_max\tmax_mean\tmax_median\tmax_max\n")
        outFile.close()
        outFile  = open("/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/read_depths_negative_control/%s_read_depths.txt" % accession, 'a')

    if random == False:
        for line in inFile:
            words = line.rstrip()
            words = words.split("\t")
            srna = words[-1]
            start = words[2]
            try:
                start = int(start)
            except ValueError:
                continue
            end = words[3]
            end = int(end)
            new_feature = words[8]
            feature = words[1]
            if new_feature == "FALSE":
                srna_type = "known"
            else:
                srna_type = "novel"

            subsetDF = read_depths_df[start:end]

            mean_mean = subsetDF['mean'].mean()
            mean_median = subsetDF['mean'].median()
            mean_max = subsetDF['mean'].max()
            median_mean = subsetDF['median'].mean()
            median_median = subsetDF['median'].median()
            median_max = subsetDF['median'].mean()
            max_mean = subsetDF['max'].mean()
            max_median = subsetDF['max'].median()
            max_max = subsetDF['max'].max()

            outFile.write("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n" % (srna, start, end, srna_type, feature, mean_mean, mean_median, mean_max, median_mean, median_median, median_max, max_mean, max_median, max_max))
    else:
        i = 0
        for line in inFile:
            i += 1
            words = line.rstrip()
            words = words.split("\t")
            srna = "%s_%s" % (accession, i)
            start = words[0]
            try:
                start = int(start)
            except ValueError:
                continue
            end = words[1]
            end = int(end)
            feature = "intergenic"
            srna_type = "negative_control"

            subsetDF = read_depths_df[start:end]

            mean_mean = subsetDF['mean'].mean()
            mean_median = subsetDF['mean'].median()
            mean_max = subsetDF['mean'].max()
            median_mean = subsetDF['median'].mean()
            median_median = subsetDF['median'].median()
            median_max = subsetDF['median'].mean()
            max_mean = subsetDF['max'].mean()
            max_median = subsetDF['max'].median()
            max_max = subsetDF['max'].max()

            outFile.write("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n" % (
            srna, start, end, srna_type, feature, mean_mean, mean_median, mean_max, median_mean, median_median,
            median_max, max_mean, max_median, max_max))


def single_fasta(fastaFile, folder):
    for seq in fastaFile:
        id = seq.id
        outname = id.split("[")
        outname = outname[0]
        my_seq = seq.seq
        outFile = open("/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/%s/%s.fna" % (folder, outname), "w")
        outFile.write(">%s\n%s\n" % (id, my_seq))


def openNHMMER(nhmmername):
    nhmmerDF = pd.read_csv(nhmmername, delim_whitespace=True, header=None, comment='#')
    nhmmerDF.columns = ["target_name", "accession", "query_name", "accession_2", "hmmfrom", "hmmto", "alifrom", "alito", "envfrom", "envto", "sq_len", "strand", "E_value", "score", "bias", "description_of_target"]
    nhmmerDF[["ID", "descriptors"]] = nhmmerDF.target_name.str.split("[", expand = True)
    nhmmerDF[["ID_2", "descriptors_2"]] = nhmmerDF.query_name.str.split("[", expand = True)
    d = nhmmerDF.groupby('ID')['ID_2'].apply(list).to_dict()
    return(d)


def openReadDepths(readdepthsname, d):
    readdepthsDF = pd.read_csv(readdepthsname, sep = "\t", comment='#')
    readdepthsDF = readdepthsDF[readdepthsDF['ID'] != "ID"]

    ##when being done in jupyter the columns were all read in as string and the lines below were necessary...
    ##it seems to work fine now

    # print(readdepthsDF.dtypes)
    # readdepthsDF[["mean_value", "mean_decimal"]] = readdepthsDF.max_mean.str.split(".", expand = True)
    # print(1)
    # readdepthsDF[["median_value", "median_decimal"]] = readdepthsDF.max_median.str.split(".", expand = True)
    # readdepthsDF[["max_value", "max_decimal"]] = readdepthsDF.max_max.str.split(".", expand = True)
    # readdepthsDF[['mean_value', 'median_value', 'max_value']] = readdepthsDF.loc[:,['mean_value', 'median_value', 'max_value']].apply(pd.to_numeric)


    readdepthsDF["mean_value"] = readdepthsDF['max_mean']
    readdepthsDF["median_value"] = readdepthsDF['max_median']
    readdepthsDF["max_value"] = readdepthsDF['max_max']
    readdepthsDF[['mean_value', 'median_value', 'max_value']] = readdepthsDF.loc[:,['mean_value', 'median_value', 'max_value']].apply(pd.to_numeric)


    idList = list(d.keys())
    readdepthsKept = readdepthsDF[readdepthsDF['ID'].isin(idList)]
    return(readdepthsKept)


def writeReadDepths(outname, readDepths, d):
    seen = []
    d2 = {}
    i = 0

    outFile = open(outname, "w")
    outFile.write(
        "ID\tmean_mean\tmean_median\tmean_max\tmedian_mean\tmedian_median\tmedian_max\tmax_mean\tmax_median\tmax_max\tID_2\n")
    outFile.close()
    outFile = open(outname, "a")
    values = []
    for key in d:
        #     print(i)
        #     i += 1
        #     if i > 100:
        #         break
        #     if key in seen:
        #         continue
        #     print(key)
        #     print(seen)
        values = d[key]
        seen.append(values)
        df = readDepths[readDepths['ID'].isin(values)]
        #     print(df['mean_value'].dtypes)

        #     print(df['mean_value'].dtypes)
        mean_mean = df['mean_value'].mean()
        mean_median = df['mean_value'].median()
        mean_max = df['mean_value'].max()
        median_mean = df['median_value'].mean()
        median_median = df['median_value'].median()
        median_max = df['median_value'].max()
        max_mean = df['max_value'].mean()
        max_median = df['max_value'].median()
        max_max = df['max_value'].max()
        #     print(key)
        #     print("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n" % (key,mean_mean,mean_median,mean_max,median_mean,median_median,median_max,max_mean,max_median,max_max,values))
        outFile.write("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n" % (
        key, mean_mean, mean_median, mean_max, median_mean, median_median, median_max, max_mean, max_median, max_max,
        values))
    outFile.close()


def writeSequences(inFile,my_seq,accession,write_path):
    i = 0
    for line in inFile:
        i += 1
        words = line.rstrip()
        words = words.split("\t")
        srna = words[-1]
        start = words[2]
        try:
            start = int(start)
        except ValueError:
            continue
        end = words[3]
        end = int(end)
        if end - start > 50:
            strand = words[4]
            new_feature = words[8]
            feature = words[1]
            overlap = words[7]
            if new_feature == "FALSE":
                srna_type = "known"
            else:
                srna_type = "novel"
            srnaSeq = my_seq[start:end]
            srnaSeqRev = srnaSeq.reverse_complement()
            if strand == "-":
                srnaSeq = srnaSeqRev
            if srna_type == "known":
                srnaPCFile = open("%s/positive_control/%s.fna" % (write_path, accession), "a")
                srnaPCFile.write(">%s[%s-%s,%s,%s,%s,%s]\n%s\n" % (srna, start, end, strand, srna_type, feature, overlap, srnaSeq))
            else:
                srnaPredictedFile = open("%s/predicted/%s.fna" % (write_path, accession), "a")
                srnaPredictedFile.write(">%s[%s-%s,%s,%s,%s,%s]\n%s\n" % (srna, start, end, strand, srna_type, feature, overlap, srnaSeq))
                
def get_overlap_vals(subsetDat, overlaps):
    dat_len = len(subsetDat.index)
    overlapping_ids = []
    lengths = []
    start_val = 0
    end_val = 0
    for i in range(0,dat_len):
        query_val = subsetDat.iloc[i]['query_id']    
        new_start_val = min([subsetDat.iloc[i]['target_start'], subsetDat.iloc[i]['target_end']])
        new_end_val = max([subsetDat.iloc[i]['target_start'], subsetDat.iloc[i]['target_end']]) 
        if end_val > new_start_val:
            overlapping_ids.append(query_val)
            len_1 = end_val - start_val
            len_2 = new_end_val - new_start_val
            shortest_seq = min([len_1, len_2])
            overlap_start = max([start_val, new_start_val])
            overlap_end = min([end_val, new_end_val])
            overlap = (overlap_end - overlap_start)/shortest_seq
            overlaps.append(overlap)
        else:
            end_val = new_end_val
            start_val = new_start_val
            overlapping_ids = [query_val]
    return(overlaps)

def get_overlap_list(subsetDat):
    overlapping_ids = []
    overlap_list = []
    lengths = []
    start_val = 0
    end_val = 0
    shortest_seq = max(subsetDat['target_end'])
    dat_len = len(subsetDat.index)
    for i in range(0,dat_len):
        query_val = subsetDat.iloc[i]['query_id']    
        new_start_val = min([subsetDat.iloc[i]['target_start'], subsetDat.iloc[i]['target_end']])
        new_end_val = max([subsetDat.iloc[i]['target_start'], subsetDat.iloc[i]['target_end']])  
        if end_val > new_start_val:
            len_2 = new_end_val - new_start_val
            shortest_seq = min([shortest_seq, len_2])
            overlap_start = max([start_val, new_start_val])
            overlap_end = min([end_val, new_end_val])
            overlap = (overlap_end - overlap_start)/shortest_seq
            
            if overlap >= 0.5 and overlap_end - overlap_start >= 50:
                if query_val not in overlapping_ids:
                    overlapping_ids.append(query_val)
                end_val = max([end_val, new_end_val])
            else:
                overlap_list.append(overlapping_ids)
                shortest_seq = max(subsetDat['target_end'])
                end_val = new_end_val
                start_val = new_start_val
                overlapping_ids = [query_val]
        else:
            overlap_list.append(overlapping_ids)
            end_val = new_end_val
            start_val = new_start_val
            overlapping_ids = [query_val]
        if i == dat_len - 1:
            overlap_list.append(overlapping_ids)
    return(overlap_list)

def get_overlap_count(overlap_list, d):
    for l in overlap_list:
        list_len = len(l)
        if list_len == 0:
            continue
        for i in range(0,list_len - 1):
            for j in range(i+1, list_len):
                ids =[l[i], l[j]]
                ids.sort()
                current_id = "_".join(ids)
                if current_id in d:
                    d[current_id] += 1
                else:
                    d[current_id] = 1
    return(d)

def unique_set_of_overlaps(all_overlaps, ids_checked, id1, id2):
    make_new = True
    counter = 0
    if id1 in ids_checked:
        if id1 in all_overlaps:
            if id2 not in all_overlaps[id1]:
                all_overlaps[id1].append(id2)    
        else:
            counter = 0
            item_list = []
            for item in all_overlaps:
                if id1 in all_overlaps[item]:
                    item_list.append(item)
                    if id2 not in all_overlaps[item]:
                        all_overlaps[item].append(id2)
                    make_new = False
                    counter += 1
            if counter > 1:
                print(item_list[1:])
                for item in item_list[1:]:
                    for value in all_overlaps[item]:
                        if value not in all_overlaps[item_list[0]]:
                            all_overlaps[item_list[0]].append(value)
                    all_overlaps.pop(item, None)
                     
    else:
        ids_checked.append(id1)
    return(all_overlaps, ids_checked, make_new, counter)                
                
def combined_alignments(query, combined_d, ids_checked, query_matches):
    combined_ids = [query]
    ids_checked.append(query)
    max_query = query
    for i in range(0, len(query_ids)):
        ids =[query, query_ids[i]]
        ids.sort()
        current_id = "_".join(ids)
        if current_id in query_matches:
            if query_ids[i] in ids_checked:
                for key, value in combined_d.items():
                    if query_ids[i] in value:
                        max_query = key
            else:
                combined_ids.append(query_ids[i])
                ids_checked.append(query_ids[i])
                
                
    if max_query in combined_d:
        for item in combined_ids:
            if item not in combined_d[max_query]:
                combined_d[max_query].append(item)
    else:
        combined_d[max_query] = combined_ids
    return(combined_d, ids_checked)



```
```{r toc, echo=FALSE, include=F} 
render_toc("~/bin/r_git/R/shiny_html/analysis_markdown_pdf.Rmd")
```


#Overview {#overview}

***

##Overview of sRNA {#srna_overview} 

Prokaryotes are the most numerous organisms on Earth, making a vast impact on every aspect of biology. A key component of the function of prokaryotes is how small non-coding RNAs (sRNA) contribute to cell functions (Gorski et al. 2017; Wagner and Romby 2015). RNAs play a critical role in a wide range of biological functions such as:

-   Transcription/Translation

    -   rRNA, tRNA, 6sRNA etc.

-   Immune response

    -   CRISPR-cas

-   Gene regulation

    -   Riboswitches, sRNAs binding to mRNA etc.

-   Virulence

![Figure 1. Examples of ncRNAs in bacteria](sRNA_examples.png)

Identifying sRNAs has been a significant challenge (Freyhult et al. 2006). While a number of different approaches are available each have limitations. Annotations based on sequence can be done based on known RNA families (Kalvari et al. 2018) are possible but cannot find novel sRNAs and are more likely to find the most highly conserved sRNAs. As many sRNAs are not widely conserved (Lindgreen et al. 2014) this means use of comparative transcriptomics will be more limited for non-coding RNA analysis, and experiments more carefully designed to ensure that the evolutionary distance between analyzed genomes is considered, to make the analysis of the data meaningful.  Experimental approaches such as transposon insertion sequencing (Barquist et al. 2013) can find novel sRNAs, these experiments are time consuming and expensive. High-throughput RNA sequencing allowed for another way to look for sRNAs throughout genomes, using RNA-Seq experiments to look for signals of expression. This allows novel features to be identified, and conservation is not going to contribute. The challenge with using data from RNA-Seq experiments has been in identifying putative sRNAs from the expression data. Transcriptional noise, the expression of non-functional transcripts (Jose et al. 2019), has been shown to occur (Struhl 2007; Lybecker et al. 2014; Wade and Grainger 2014) with spurious promoters likely to be resulting in a lot of transcripts that have no function (Costa 2007; HÃ¼ttenhofer et al. 2005). Many tools that aim to predict putative sRNAs (Leonard et al. 2019; Yu et al. 2018; Mcclure et al. 2013) struggle to agree on predictions from the same dataset with the number of predicted transcripts and the exact start and end of the transcripts differing greatly. Experimental conditions are also very important with sRNAs often responding to environmental cues (Gottesman et al. 2006). These tools are likely struggling as the non-functional transcripts are not easily distinguished from functional sRNAs using expression data alone. A more comprehensive approach that carries out downstream analysis is necessary to better separate the transcriptional noise from the putative sRNAs. 

##Overview of Methods {#methods}

```{r data_counts, include=F}
genera_list <- list.files("~/phd/RNASeq/genera/")
genera_list <- genera_list[genera_list != "test"]
genera_count <- length(genera_list)
strain_count <- 0
experiment_count <- 0
for(genus in genera_list){
  strain_list <- list.files(paste("~/phd/RNASeq/genera/", genus, sep = ""), pattern = ".data")
  n.strains <- length(strain_list)
  if(n.strains == 0){
    next
  }
  for(strain in strain_list){
    experiment_list <- list.files(paste("~/phd/RNASeq/genera", genus, strain, "plot_files/", sep = "/"), pattern = "ncRNA.plot")
    n.experiments <- length(experiment_list)
    if(n.experiments == 0){
      next
    }
    experiment_count <- experiment_count + n.experiments
    strain_count <- strain_count + 1
  }
}

```

Here, we have looked at a number of different tools and tried two different approaches to attempt to better categorise the expressed regions into putative sRNAs, sRNAs matching known families and transcriptional noise. 

This was done by taking RNA-Seq data from a clade of Gammaproteobacteria was selected: 

-   \>6 families
-   `r genera_count` genera
-   `r strain_count` strain
-   `r experiment_count` experiments

These included a number of well studied species, with a number of RNA-seq experiments to analyse and less well studied species that had fewer RNA-seq experiments and less known about the sRNAs. 


From these experiments, sRNAs were predicted based on expressed regions in RNA-Seq data using multiple RNA-Seq datasets for each genome.

These predicted regions can be used to evaluate signal to noise in expression data by classifying the RUFs into two categories:

- Similar to known sRNAs
- Indistinguishable from randomly selected regions

Categorising the RUFs requires using metrics that can idenitfy sRNAs. A number of different measures were chosen:

-   Conservation of transcription
-   Conservation of sequence
-   GC content
-   Covariation observed in sequence alignments
-   Secondary structure
-   Presence of ncRNA motifs


These metrics were evaluated using two datasets:

-   Annotations from a search of Rfam models

-   Random intergenic sequences of the same lengths as the predicted sRNAs


A representative set of bacterial genomes were selected by taking two genomes from each genus available in the Refseq95 dataset. These genoem were used for the conservation of sequence step and the annotations using rFam models.

![Figure 4. Workflow of methods]()


##Summary of strains used {#strains_used}

```{r summary_of_strains, echo = F, eval = T, results='asis'}
load("~/bin/r_git/R/r_files/accession_info.Rda")
accession_info <- accession_info %>% 
  mutate(strain_short = substr(Strain, start = 1, stop = 30)) %>% 
  select(Accession, RNASeq.file.counts, strain_short)

set.seed(101)
rand.selection <- runif(10, min = 1, max = nrow(accession_info))

accession_info[rand.selection,] %>%  
  kable(caption = "Table 1. Number of experiments per strain") %>%
  kable_styling()

load("~/bin/r_git/R/r_files/assembly_summary.Rda") # made from ~/phd/RNASeq/SRA_bacteria_RNAseq.txt


assembly_summary <- assembly_summary %>% separate(col = SPECIES, into = c("Genus"), extra = "drop", remove = F, sep = " ")


genomes <- assembly_summary %>% filter(DESIGN == "PAIRED", grepl(pattern = "Illumina", x = INSTRUMENT)) %>% group_by(Genus) %>% select(Genus, GENOME_ACCESSION) %>% unique() %>% summarise(genome_count = n())
experiments <- assembly_summary %>% filter(DESIGN == "PAIRED", grepl(pattern = "Illumina", x = INSTRUMENT)) %>% group_by(Genus) %>% select(Genus, GENOME_ACCESSION, ACCESSION) %>% unique() %>% summarise(experiment_count = n())

counts <- genomes %>% full_join(experiments, by = "Genus")

load("~/bin/r_git/R/r_files/sraDatAll.Rda")

rand.selection <- runif(5, min = 1, max = nrow(assembly_summary))

assembly_summary[rand.selection,] %>%  
  kable(caption = "Table 2. List of experiments (1)") %>%
  kable_styling()

rand.selection <- runif(5)

sraDatAll[rand.selection,]%>%  
  kable(caption = "Table 3. List of experiments (2)") %>%
  kable_styling()

```

#Data Selection {#data_selection}

##Strains and experiments
How to get the summary table for the genera for the RNA-seq data:

-   Search the [SRA](https://www.ncbi.nlm.nih.gov/sra/) section of ncbi with the genus name and ['Organism'] tag.

-   Select "Send results to Run selector"

-   Select the "Metadata" button of the "Total" row and "Download" Column.

-   `cat SraRunTable* >> ~/phd/RNASeq/sra_run_tables.csv`

    -   This appears to have columns out of order so it is important to consider that there might be more data available and to search sraDatAll for genus names to check.

```{r selecting_more_data, echo=F, eval=F}
run_all <- F
if(run_all){
datAll <- read.csv("~/phd/RNASeq/sra_run_tables.csv")

assayTypes <- datAll %>% group_by(Assay.Type) %>% summarise(count = n())
sraDatAll <- datAll %>% filter(grepl(pattern = "RNA", x = Assay.Type))
                      
                      
dat <- sraDatAll %>% filter(grepl(pattern = "Illumina", Instrument), LibraryLayout == "PAIRED") %>% unique()

dat <- dat %>% select(Run, Experiment, Organism, Strain, ReleaseDate, Sample.Name, SRA.Study, LibraryLayout, LibrarySelection, LibrarySource, Instrument) %>% mutate_all(as.character)

# datAll <- datAll %>% select(Run, Experiment, Organism, Strain, ReleaseDate, Sample.Name, SRA.Study, LibraryLayout, LibrarySelection, LibrarySource, Instrument) %>% mutate_all(as.character)

SRA_bacteria_RNASeq_v2 <- dat
SRA_bacteria_RNASeq_v2_all <- sraDatAll
save(SRA_bacteria_RNASeq_v2, file ="~/bin/r_git/R/r_files/SRA_bacteria_RNASeq_v2.Rda")
save(SRA_bacteria_RNASeq_v2_all, file ="~/bin/r_git/R/r_files/SRA_bacteria_RNASeq_v2_all.Rda")


load("~/bin/r_git/R/r_files/SRA_bacteria_RNASeq_v2.Rda")
load("~/bin/r_git/R/r_files/SRA_bacteria_RNASeq_v2_all.Rda")

sraDat <- SRA_bacteria_RNASeq_v2
sraDatAll <- SRA_bacteria_RNASeq_v2_all

strainsCount <- sraDatAll %>% group_by(Organism, Strain) %>% summarise(count = n())

sraDatAll <- sraDatAll %>% separate(col = Organism, into = "genus", sep = " ", remove = F, extra = 'drop')
library.options <- c("PAIRED", "SINGLE")
sraDatAll1 <- sraDatAll %>% filter(LibraryLayout %in% library.options) 
sraDatAll2 <- sraDatAll %>% filter(SRA.Study %in% library.options) %>% select(-genus) %>% mutate(LibraryLayout = SRA.Study)
sraDatAll3 <- sraDatAll %>% filter(AvgSpotLen %in% library.options) %>% select(-genus) %>% mutate(LibraryLayout = AvgSpotLen)
sraDatAll4 <- sraDatAll %>% filter(Sample.Name %in% library.options) %>% select(-genus) %>% mutate(LibraryLayout = Sample.Name)
sraDatAll5 <- sraDatAll %>% filter(genus %in% library.options) %>% mutate(LibraryLayout = genus) %>% select(-genus) 
sraDatAll6 <- sraDatAll %>% filter(LibrarySelection %in% library.options) %>% select(-genus) %>% mutate(LibraryLayout = LibrarySelection)
sraDatAll7 <- sraDatAll %>% filter(Platform %in% library.options) %>% select(-genus) %>% mutate(LibraryLayout = Platform)



sraDatAll2 <- sraDatAll2  %>% 
  dplyr::mutate(Organism = Bytes)%>% separate(col = Organism, into = "genus", sep = " ", remove = F, extra = 'drop')
sraDatAll3 <- sraDatAll3 %>% 
  dplyr::mutate(Organism = DATASTORE.filetype)%>% separate(col = Organism, into = "genus", sep = " ", remove = F, extra = 'drop')
sraDatAll4 <- sraDatAll4 %>%  
  dplyr::mutate(Organism = Bases)%>% separate(col = Organism, into = "genus", sep = " ", remove = F, extra = 'drop')
sraDatAll5 <- sraDatAll5 %>% 
  dplyr::mutate(Organism = Sample.Name)%>% separate(col = Organism, into = "genus", sep = " ", remove = F, extra = 'drop')
sraDatAll6 <- sraDatAll6 %>% 
  dplyr::mutate(Organism = Platform)%>% separate(col = Organism, into = "genus", sep = " ", remove = F, extra = 'drop')
sraDatAll7 <- sraDatAll7 %>% 
  dplyr::mutate(Organism = SRA.Study)%>% separate(col = Organism, into = "genus", sep = " ", remove = F, extra = 'drop')




genusCount1 <- sraDatAll1 %>% group_by(genus) %>% summarise(count = n())
genusCount2 <- sraDatAll2 %>% group_by(genus) %>% summarise(count = n())
genusCount3 <- sraDatAll3 %>% group_by(genus) %>% summarise(count = n())
genusCount4 <- sraDatAll4 %>% group_by(genus) %>% summarise(count = n())
genusCount5 <- sraDatAll5 %>% group_by(genus) %>% summarise(count = n())
genusCount6 <- sraDatAll6 %>% group_by(genus) %>% summarise(count = n())
genusCount7 <- sraDatAll7 %>% group_by(genus) %>% summarise(count = n())

genusCount <- genusCount1 %>% bind_rows(genusCount2, genusCount3, genusCount4, genusCount5, genusCount6, genusCount7)


sraDatAll <- sraDatAll1 %>% bind_rows(sraDatAll2, sraDatAll3, sraDatAll4, sraDatAll5, sraDatAll6, sraDatAll7)

sraDatAll <- sraDatAll %>% select(Run, Experiment, Organism, Strain, genus, LibraryLayout, ReleaseDate, Sample.Name, SRA.Study, LibrarySelection, LibrarySource, Instrument) %>% mutate_all(as.character)

save(sraDatAll, file = "~/bin/r_git/R/r_files/sraDatAll.Rda")
}

```


The genome accession for each added genome was looked up on [NCBI](https://www.ncbi.nlm.nih.gov/) using the strain name in the file or by search for the given experiment in the [SRA](https://www.ncbi.nlm.nih.gov/sra/) section:

-   Take the experiment ID e.g SRR3742546

-   Search [SRA](https://www.ncbi.nlm.nih.gov/sra/) or [NCBI](https://www.ncbi.nlm.nih.gov/) and select the SRA result for this ID
    
-   Select the 'Organism:' link

-   Select the Genome option from the box of options currently on the upper right of the page. It will probably have a 1 which is a clickable link beside it. Click this link.
    
-   From the reference genome section select the Refseq ID of the Chr option. 

-   This will open a genbank file that should list Assembly accession. Select this.

-   From the full report copy the GenBank assembly accession: e.g GCA_002504285.1

-   Create a folder for the genus

-   Create a folder using the GenBank assembly accession e.g. `mkdir GCA_002504285.1.data/`

-   Create an experiments_list.txt file listing all of the SRA experiments for the given genome and save the file in the genus folder.
    
-   Run [*callPeaksforGenome.sh*](#section-callpeaksforgenome) *-g* *\<GCA Accession\>* *-s*

A taxonomy table was generated with the code below. This had to be supplemented by going through manually to correct mistakes, or fill in missing data.

-   *genera_list.txt* was made by hand by searching for RNASeq files for each genus as above and if found, the genus was added to the file. 

    -   this would not be practical for a bigger clade.

```{python get_taxonomy, eval=F}
genera = pd.read_csv('/Users/thomasnicholson/bin/python_git/python_files/genera_list.txt', header = None)
df_len = len(genera)

genera['Kingdom'] = 1
genera['Phylum'] = 1
genera['Class'] = 1
genera['Order'] = 1
genera['Family'] = 1
genera['Genus'] = genera.iloc[:,0]

i = -1
for item in genera.iloc[:,0]:
    i += 1
    html_link = 'https://en.wikipedia.org/wiki/%s' % item
    print(html_link)
    
    
    try:
        html_page = urllib.request.urlopen(html_link)
    except urllib.error.HTTPError as exception:
        next
    record_values = False
    pos_val = 0
    taxonomy_levels = []
    for line in html_page:
        mystr = line.decode("utf8")
        if record_values == False:
            if "<td>Kingdom" in mystr:
                record_values = True
            elif "<td>Domain" in mystr:
                record_values = True                
        else:

            if pos_val > 5:
                break
            if 'href="/wiki/' in mystr:
                pos_val += 1
#                 print(pos_val)
                level_name = mystr.split("/")[2]
                level_name = level_name.split('"')[0]
                print(level_name)
#                 print(genera.iloc[i,:])
                genera.iloc[i,pos_val]  = level_name


```

##Subset of genomes {#subest_of_all_genomes}

Two genomes from each genera (from REFSEQ95) were selected as a representative set of genomes

-   This is done on the server (biochemcompute.uod.otago.ac.nz) using [Rstudio](http://biochemcompute.uod.otago.ac.nz:8787/) from the browser

```{r get_genomes_for_analysis, eval=F}
assembly_summary <- read.table("/Volumes/scratch/brownlab/chrisbr/DB/REFSEQ_REPREF/bacteria/assembly_summary_repref.txt", sep = "\t", fill = T, quote = "", comment.char = "")
assembly_summary <- assembly_summary %>% select(V1, V5, V8, , V18, V20, V12, V6)
colnames(assembly_summary) <- c("accession.1", "type", "species", "accession.2", "genome_link", "assembly.type", "some_number")

assembly_summary <- assembly_summary %>% separate(col = species, into = "genus", sep = " ", extra = 'drop', remove = F)

all_genera <- assembly_summary %>% group_by(genus) %>% summarise(count_all = n())
dat <- assembly_summary %>% filter(assembly.type != "Scaffold")
genera <- dat %>% group_by(genus) %>% summarise(count = n())

genera <- genera %>% full_join(all_genera, by = 'genus')


complete_genomes <- assembly_summary %>% filter(assembly.type == "Complete Genome")
contigs <- assembly_summary %>% filter(assembly.type == "Contig")

complete_genomes <- complete_genomes %>% 
  group_by(genus) %>% 
  mutate(counter = row_number()) %>% 
  filter(counter < 3) %>% 
  mutate(group = "complete")

contigs <- contigs %>% 
  group_by(genus) %>% 
  mutate(counter = row_number() + 2) %>% 
  filter(counter < 5) %>% 
  mutate(group = "contig")

complete_genomes <- complete_genomes %>% 
  bind_rows(contigs) %>% 
  group_by(genus) %>% 
  arrange(counter) %>% 
  mutate(counter.2 = row_number()) %>% 
  filter(counter.2 < 3)

files <- complete_genomes %>% mutate(species.2 = str_replace_all(string = species, pattern = " ", "_")) %>% mutate(file_path = paste(substr(genus, 1, 1), "/", species.2, "-", some_number, "\\#", accession.1, "/", sep = "")) %>% ungroup() %>% select(file_path)

write.table(x = files, file = "~/bin/r_git/R/r_files/server_genomes_file_paths.txt", quote = F, row.names = F, col.names = F)

write.table(x = complete_genomes$accession.2, file = "~/phd/RNASeq/all_taxa_accession.txt", quote = F, row.names = F, col.names = F)
write.table(x = complete_genomes$species, file = "~/phd/RNASeq/all_taxa_names.txt", quote = F, row.names = F, col.names = F)
```

```{r tree_viewer, echo=T, include=F, eval=F}
  tree <- read.tree("~/bin/r_git/R/r_files/genera_11.guide_tree")
  p <-ggtree(tree) + 
  geom_tiplab() +
  xlim(0,0.8)
  p
```

#Predicting sRNAs {#predicting_srnas}

***

##Download data and map reads {#data_download}

**Scripts involved for each Accession**

-   [*callPeaksforGenome.sh*](#section-callpeaksforgenome) *-g* *\<GCA Accession\>* *-s*

    -   The *-s* flag is now used to indicate that a file named *experiments_list.txt* should be used for the list of RNASeq accessions. This is due to the new file containing accessions being less organised and requiring this new input.

    -   Only accessions with \>4 RNA-Seq files are analysed

    -   [*fetch_genomes_from_GCA.sh*](#section-fetch_genomes_from_gca.sh) *-r* *\<GCA Accession\>* *-g*

        -   The genome and gff files are downloaded from ncbi using the GCA acession
        -   *-g* flag is for downloading GFF file

    -   The RNA-Seq data is downloaded using *fasterq-dump* with a given accession

        -   these are selected from a file (shown below) containing a list of RNA-Seq experiment IDs for each strain. (Old)
        -   filtered for paired ends, Illumina HiSeq

    -   [*sra2plot.1.0.3.sh*](#section-sra2plot.1.0.3.sh) *-s* *\<SRA Accession\>* *-r* *\<GCA Accession\>* *-d* *-n* *\<Number of CPUs\>*

        -   Maps the reads
        -   *-d* turns off the downloading function of the script as this is being done separately

    -   [*removeProteinCodingRNA.R*](#section-removeproteincodingrna.r) *-f* *\<SRA Accession\>* *-g* *\<GCA Accession\>*

    -   [*run_rnaPeakCalling.R*](#section-run_rnapeakcalling.r) *-f* *\<SRA Accession\>* *-g* *\<GCA Accession\>*

    -   [*rfamscan*](#section-rfamscan) *\<GCA Accession\>*

        -   Searches the given genome for rFam models and reformats output into GFF format
        -   [*cmscanToGffWrapper.R*](#section-cmscantogffwrapper.r) *-f* *\<GCA Accession\>.tblout* *-g* *\<GCA Accession\>*

    -   [*combine_gff_files.R*](#section-combine_gff_files.r) -f *./gff_files/* *-o* *\<GCA Accession\>*


***


##Call peaks on individual RNA-Seq experiments {#call_peaks}


Description:

-   A plot file is produced. This contains a number for each nucleotide that indicates read depth.

-   The read depth is normalised and any region where the read depth is above a threshold for \>50 nt is called a peak.

    -   Threshold is set to the equivalent of \~15 nt read depth before normalisation

-   The protein coding regions are ignored



###RUF peak calling

The peak calling steps appeared to have something wrong so it was rewritten:

-   [*run_rnaPeakCalling.2.0.R*](#section-run_rnapeakcalling.2.0.r)

    -   This runs over all current plot files in the subfolders of *~/phd/RNASeq/genera/* and uses a slightly different approach to before

    -   It has everything hardcoded including file locations and no checks for overwriting existing files so before running this code
    
###Move old calls {#move_old_calls}

Moves existing `${experiment}_sra_calls.gff` files to an *old/* folder. This will prevent them from being included in the `${accession}_new_calls.txt` file from the [*combine_gff_files.R*](#section-combine_gff_files.r) script.

```{bash move_old_calls, eval=F}
##done in ~/phd/RNASeq/genera/

cd ~/phd/RNASeq/genera/
for genus in *;
do
#genus="Escherichia"


cd ~/phd/RNASeq/genera/${genus}


for folder in *.data;
do

cd ~/phd/RNASeq/genera/${genus}/${folder}/gff_files/

mkdir -p old

mv *_sra_calls.gff old


done
done
```


##Combining GFF file {#combining_gff_files}


At this stage each individual RNA-Seq file has a corresponding gff file of RUFs. There is also the original GFF file containing ncRNAs (along with CDS). Predictions of ncRNAs are made using rfam models and the output is made into a GFF file. There are 2 GFF files containing *known* sRNAs and a number of GFF files containing predicted RUFs.

-   feature files (.gff) files were all combined into a single `${accession}_new_calls.txt` file.

    -   [*combine_gff_files.r*](#section-combine_gff_files.r) *(done in gff_files folder)*

-   After combining all the individual calls for each genome there were a total of 8906 putative sRNAs.

-   For each sRNA that was predicted, a random intergenic region was selected.

    -   [*get_random_srna_sequences.py*](#section-get_random_srna_sequences.py) *-a* *\<GCA Accession\>*
    -   the file containing new calls for a given genome was used.
    -   this was done by randomly selecting a start site and taking the sequence from that location (for the same length as the orignial predicted sRNA).
    -   coding regions were removed

```{r, include=F}
files <- list.files("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/alignments/", pattern = ".stk")
file_count <- length(files)
```

-   There were `r file_count` random regions chosen


To simluate noise a set of regions were predicted based on selecting random regions of genomes of the equivalent size to the predicted RUFs in order to give a baseline of what is expected from different sRNA prediction approaches. 

-   All `${accession}_new_calls.txt` files are moved to *~/phd/RNASeq/new_calls/*


It is necessary to rerun the [*combine_gff_files.R*](#section-combine_gff_files.r) script for each strain due to the RUFs being predicted again after the intial run of the combine_gff_files.R

```{bash run_combine_gff_over_all_accessions, eval=F}
cd ~/phd/RNASeq/genera/
for genus in *;
do
  cd ~/phd/RNASeq/genera/${genus}
  for folder in *.data;
  do
    accession=`basename $folder .data`
    echo $genus $accession
    cd ~/phd/RNASeq/genera/${genus}/${folder}/
    combine_gff_files.R -f ./gff_files/ -o $accession
  done
done
```

##Get sRNA Sequences {#get_srnas}

Once the`${accessiion}_new_calls.txt` files have been made the predicted sequences are needed.


###Predicted RUFs

The fasta files and calls files for each individual strain are all moved to common folders.

```{bash move_files_to_common_folders, eval=F}
cd ~/phd/RNASeq/sequences
cp ~/phd/RNASeq/genera/*/*/*.fna ./
cd ~/phd/RNASeq/new_calls
mkdir -p old
mv *_new_calls.txt old/
cp ~/phd/RNASeq/genera/*/*/*_new_calls.txt ./
```      
      
Each of the calls files are then used to obtain the coordinates (contig, start and end locations) for each RUF. These are then extracted from the genome fasta files and written to a common fasta file. Writing to a common file is useful, although a later step of writing each RUF to a unique file is necessary as a result. Combining these steps would have been sensible.

-   [*get_sRNA_sequences.py*](#section-get_srna_sequences.py) is currently used

-   `esl-sfetch` with a while loop for each file would be better if this is ever redone

      
```{bash get_sRNA_sequences_loop, eval=F, include=T}
##done in ~/phd/RNASeq/new_calls/
cd ~/phd/RNASeq/srna_seqs/version_1/
mkdir -p seqs_predicted
cd ~/phd/RNASeq/new_calls/
for file in *.txt; 
do 
  accession=`basename $file _new_calls.txt`; 
  echo $accession; get_sRNA_sequences.py -a $accession; 
done
```

###Random regions

The random sequences are obtained in a similar way using [*get_random_srna_sequences.py*](#section-get_random_srna_sequences.py). 

-   `esl-sfetch` with a while loop for each file would be better if this is ever redone


```{bash get_random_srna_sequences_loop, eval = F}
##done in ~/phd/RNASeq/new_calls/
for file in *.txt; do accession=`basename $file _new_calls.txt`; echo $accession; get_random_srna_sequences.py -a $accession; done
```



###Fasta files for each RUF

This step creates a fasta file for each RUF. This is needed so that nhmmer can be used as the input for the query can only be a single sequence or alignment (from what I could figure out). The script [*single_fasta_files.py*](#section-single_fasta_files.py) is used although this could have been built into [*get_sRNA_sequences.py*](#section-get_srna_sequences.py).

```{bash single_fasta_files_loop, eval = F}
##done in ~/phd/RNASeq/srna_seqs/version_1/seqs_predicted/${group}
group="predicted"
cd ~/phd/RNASeq/srna_seqs/version_1/seqs_predicted/${group}

mkdir -p single_seqs

if [[ $group == "predicted" ]]; then

fasta_file="predicted.fna"

elif [[ $group == "positive_control" ]]; then
fasta_file="predicted_known.fna"

else;
echo "${group} not a valid option for group variable"
fasta_file=""


fi
single_fasta_files.py -i seqs_predicted/${group}/${fasta_file} -f seqs_predicted/${group}/single_seqs/


```


##Build models {#run_nhmmer}

Each of the measures used for evaluating RUFs are improved by alignments with more unique sequences. In order to build models for each RUF (and control group) a number of steps were done.

-  The following steps are described for the *predicted* data set but this also applys to the *negative* *control* dataset

-   The *positive* *control* dataset steps are described [later](#section-cmscan_rfam)

###Predicted nhmmer (first iteration)

```{r, include=F}
known_files <- list.files("~/phd/RNASeq/srna_seqs/version_1/seqs_predicted/positive_control/single_seqs/", pattern = ".fna")
known_count <- length(known_files)

novel_files <- list.files("~/phd/RNASeq/srna_seqs/version_1/seqs_predicted/predicted/single_seqs/", pattern = ".fna")
novel_count <- length(novel_files)

```

The predicted RUFs are built into model by searching the set of predicted RUFs in an all by all search. This first step is done in order to make later steps reducing redundanc easier.

-   The RUFs have been split into those that overlap with a known sRNA (`r known_count`) and those that are novel (`r novel_count`)

-   nhmmer needs to be run on both datasets.

```{bash run_srna_nhmmer_loop_initial, eval=F}
##done in ~/phd/RNASeq/srna_seqs/version_1/seqs_predicted/${group}
group="predicted"
cd ~/phd/RNASeq/srna_seqs/version_1/seqs_predicted/${group}
run_sRNA_nhmmer.sh -d ~/phd/RNASeq/srna_seqs/version_1/seqs_predicted/${group}/predicted*.fna -f single_seqs/ -e fna

```

-   the output extension uses *.fna* instead of *.stk* which needs to be changed

```{bash change_fna_stk, eval=F}
##done in ~/phd/RNASeq/srna_seqs/version_1/seqs_predicted/${group}/alignments
group="predicted"

cd ~/phd/RNASeq/srna_seqs/version_1/seqs_predicted/${group}/alignments

for file in *.fna;
do
outname=`basename $file .fna`

mv $file $outname.stk

done

```

The next step involves using the server and in order to do this all the files need to be copied into a folder.

Run on server (*biochemcompute.uod.otago.ac.nz*):

```{bash server_transfer_setup, eval=F}
##done in ~/phd/RNASeq/srnas/${group}
group="predicted"
cd ~/phd/RNASeq/srnas/${group}
mkdir -p initial_alignments
```

Run locally:

```{bash transfer_to_server,eval=F}
cd ~/phd/RNASeq/srna_seqs/version_1/seqs_predicted/predicted/alignments
scp *.stk bioc:./phd/RNASeq/srnas/predicted/initial_alignments
```

###Predicted nhmmer (second iteration)

Each of the alignments for predicted RUFs are used as queries to search against the set of representative genomes in order to expand the number of sequences used and to determine the evolutionary conservation of each RUF.

Run on server (*biochemcompute.uod.otago.ac.nz*):

-   `screen -list` to see screens

-   `screen -r $ID ` to reattach screen

```{bash run_srna_nhmmer_loop_large_alignments, eval=F}
##done in ~/phd/RNASeq/srnas/${group}
group="predicted"
cd ~/phd/RNASeq/srnas/${group}
run_sRNA_nhmmer.sh -d ~/phd/RNASeq/representative_genomes.fna -f initial_alignments/ -o large_alignments/ -e stk -E 1e-5
```


# Known sRNAs{#known_srna}

The known sRNAs are used for two purposes:

-   The ribosomal small subunit is used to calculate phylogenetic distances for each of the genomes used

-   All rFam models with sRNAs < 500 nt are used as a *positive* *control* dataset

##Find known sRNAs

###cmscan with RFam families {#cmscan_rfam}

The RFam families were downloaded from [Rfam](https://rfam.xfam.org/):

-   Click *FTP*

    -   Select Guest as user and connect
    
    -   open Current (14.4)
    
Two files were downloaded:

-   *Rfam.cm* contains all the models for the families

    -   The *RFam.cm* file needed to be unzipped `gunzip Rfam.cm.gz`.

-   *Rfam.clanin.txt* contains clan information


These files were used to search against the set of representative genomes and analysed genomes.

```{bash run_csmscan_across_multiple_files, eval=F, include=T}
#in ~/phd/RNASeq/representative_genomes
#in ~/phd/RNASeq/analysed_genomes
mkdir check_files
for file in *.fna; 
do 

  runname=`basename $file .fna`;  

  if [ -f "check_files/${runname}.tmp.out" ]; then 
    echo "Already exists: $runname"; 
    continue;
  else 
    echo "$runname";  
  fi;  
  
  rfamscan $file;  
  > check_files/$runname.tmp.out;  

done

```

This search gave an output for each genome containing coordinates (contig, start, end, strand) for the location of sequences matching Rfam families. These files needed to be combined and reformatted so that the nucelotide sequences of the matches could be obtained. This was done for each group:

`group="representative_genomes"`

`group="analysed_genomes"`

The outputs combined with `cat *.tblout >> ../${group}.tblout`. This output was reformatted so that it could be easily read into R `cat ${group}.tblout | sed 's/  /\t/g' | tr -s '\t' | sed 's/\t /\t/g' | sed 's/ \t/\t/g' | sed 's/ /\t/3' | sed 's/ /\t/' | sed 's/ /\t/' | sed 's/ /_/g' | sed 's/_!/\t!/g' | tr -s '\t' | sed 's/Pseudomonas\t/Pseudomonas_/g' > ${group}.tab`


All of the genomes for each group were combined into one file for easier coding of the step involving getting the sequences `cat *.fna >> ../${group}.fna`

The files were then marked as completed:

`mkdir done`

`mv *.fna done/`

`mv *.tblout done/`

###Lookup table (genomes and contigs)

The results from cmscan and nhmmer use contig accessions for the target accessions, while the genomes that were used have genome accessions. It was therefore necessary to create a lookup table of genome and contig accessions.

```{bash genome_contig_pairs, eval=F}
#done from ~/phd/RNASeq/representative_genomes/
#repeat from ~/phd/RNASeq/${group}
> ../genome_contig_pairs.txt
for file in GC*.fna;  
do   

  ID=`echo $file | cut -d '.' -f1,2 | cut -d "_" -f1,2`;   
  grep ^">" $file | cut -d ' ' -f1 | sort | uniq | sed 's/>//g' | sed -e "s/$/   $ID/" >> ../genome_contig_pairs.txt;   
done
```



###Coordinates from cmsearch

The reformatted cmscan output is used to create files `${family}_locations.txt` for each of the Rfam families of  the coordinates of all the matching regions from the representative and analysed genomes.
    
-   This was done on the server (biochemcompute.uod.otago.ac.nz) using [Rstudio](http://biochemcompute.uod.otago.ac.nz:8787/) from the browser

-   representative genomes

```{r cmsearch_res_pc, eval=F}

##file made with cat RF00177.tbl | sed 's/  /\t/g' | tr -s '\t' | sed 's/\t /\t/g' | sed 's/ \t/\t/g' | sed 's/ /\t/3' | sed 's/ /\t/' | sed 's/ /\t/' | sed 's/ /_/g' | sed 's/_!/\t!/g' | tr -s '\t' | sed 's/Pseudomonas\t/Pseudomonas_/g' > RF00177.tab along with manually replacing some incorrect _ and \t 

dat <- read.table("~/phd/RNASeq/representative_genomes.tab", sep = "", quote = "", comment.char = "#", fill = T)

contig_labels <- read.table("~/phd/RNASeq/genome_contig_pairs.txt")
colnames(contig_labels) <- c("query.name", "genome")

dat <- dat[,2:18]

colnames(dat) <- c("description.of.target", "target.name", "query.name", "accession", "accession.2", "mdl", "mdl.from", "mdl.to", "seq.from", "seq.to", "strand", "trunc", "pass", "gc", "bias", "score", "e.value")

dat <- dat %>% filter(!is.na(e.value))

dat <- dat %>% group_by(target.name, query.name) %>% 
  arrange(as.numeric(e.value)) %>% 
  mutate(order.num = row_number()) %>% 
  filter(order.num == 1) %>% 
  ungroup()





smalldat <- dat %>% 
  select(target.name, query.name, seq.from, seq.to, strand, e.value, mdl.from, mdl.to)

smalldat <- smalldat %>% left_join(contig_labels, by = 'query.name') %>% 
  group_by(genome, target.name) %>% 
  arrange(as.numeric(e.value)) %>%
  mutate(order.num = row_number()) %>% 
  filter(order.num == 1) %>% 
  ungroup()

RF00177 <- smalldat %>% filter(target.name == "RF00177") 


for(item in unique(smalldat$target.name)){
  print(item)
  modelDat <- smalldat %>% filter(target.name == item)
  if(nrow(modelDat) == 0){
    continue
  }
  modelDat <- modelDat %>% select(query.name, seq.from, seq.to, strand)
  
write.table(x = modelDat, file = paste("~/phd/RNASeq/rfam_files/locations/", item,"_locations.txt", sep = ""), row.names = F, col.names = F, quote = F, sep = "\t")
  

}

  write.table(x = RF00177 %>% select(query.name, seq.from, seq.to, strand), file = "~/phd/RNASeq/rfam_files/RF00177_locations.txt", row.names = F, col.names = F, quote = F, sep = "\t")


```

-   analysed genomes

```{r cmsearch_res_analysed_genomes, eval=F}

##file made with cat RF00177.tbl | sed 's/  /\t/g' | tr -s '\t' | sed 's/\t /\t/g' | sed 's/ \t/\t/g' | sed 's/ /\t/3' | sed 's/ /\t/' | sed 's/ /\t/' | sed 's/ /_/g' | sed 's/_!/\t!/g' | tr -s '\t' | sed 's/Pseudomonas\t/Pseudomonas_/g' > RF00177.tab along with manually replacing some incorrect _ and \t 

dat <- read.table("~/phd/RNASeq/analysed_genomes.tab", sep = "", quote = "", comment.char = "#", fill = T)

contig_labels <- read.table("~/phd/RNASeq/genome_contig_pairs.txt")
colnames(contig_labels) <- c("query.name", "genome")

dat <- dat[,2:18]

colnames(dat) <- c("description.of.target", "target.name", "query.name", "accession", "accession.2", "mdl", "mdl.from", "mdl.to", "seq.from", "seq.to", "strand", "trunc", "pass", "gc", "bias", "score", "e.value")

dat <- dat %>% filter(!is.na(e.value))

dat <- dat %>% group_by(target.name, query.name) %>% 
  arrange(as.numeric(e.value)) %>% 
  mutate(order.num = row_number()) %>% 
  filter(order.num == 1) %>% 
  ungroup()





smalldat <- dat %>% 
  select(target.name, query.name, seq.from, seq.to, strand, e.value, mdl.from, mdl.to)

smalldat <- smalldat %>% left_join(contig_labels, by = 'query.name') %>% 
  group_by(genome, target.name) %>% 
  arrange(as.numeric(e.value)) %>%
  mutate(order.num = row_number()) %>% 
  filter(order.num == 1) %>% 
  ungroup()

RF00177 <- smalldat %>% filter(target.name == "RF00177") 


for(item in unique(smalldat$target.name)){
  print(item)
  modelDat <- smalldat %>% filter(target.name == item)
  if(nrow(modelDat) == 0){
    continue
  }
  modelDat <- modelDat %>% select(query.name, seq.from, seq.to, strand)
  
write.table(x = modelDat, file = paste("~/phd/RNASeq/analysed_genomes_rfam_files/locations/", item,"_locations.txt", sep = ""), row.names = F, col.names = F, quote = F, sep = "\t")
  

}

  write.table(x = RF00177 %>% select(query.name, seq.from, seq.to, strand), file = "~/phd/RNASeq/rfam_files/RF00177_locations.txt", row.names = F, col.names = F, quote = F, sep = "\t")


```

###Get sequences

The `${family}_locations.txt` were then used to extract the nucelotide sequence of all matching regions from each of the corresponding fasta files. 

-   The fasta files needed to be indexed with `esl-sfetch --index ${group}.fna` 

A later step ([cmalign](#section-make_cm_files)) uses a lot of memory. To keep this step managable the files were limited to 20 sequences per file, with multiple files being created for each Rfam family if needed.

-   This is [later](#section-combine_alignments) combined with `esl-alimerge`

```{bash get_nucelotide_sequences, eval = F}   

##from ~/phd/RNASeq/rfam_files/

# > RF00177_rep_seqs.fna

i=0
file_count=1
> RF00177_files/RF00177_rep_seqs_${file_count}.fna
while read line; 
do 
  i=`expr $i + 1`
  if (( $i > 50 )); then
  i=0
  file_count=`expr $file_count + 1`
  > RF00177_files/RF00177_rep_seqs_${file_count}.fna
  fi

  
  contig=`echo $line | cut -d ' ' -f1`; 
  contig_start=`echo $line | cut -d ' ' -f2`; 
  contig_end=`echo $line | cut -d ' ' -f3`; 
  contig_strand=`echo $line | cut -d ' ' -f4`;  
  
  length=`expr $contig_end - $contig_start`
  
  length=`echo $length | tr -d '-'`
  
  if (( $length < 1400 )); then
  echo "$contig too short" 
  continue
  fi

    esl-sfetch -c ${contig_start}..${contig_end} ../representative_genomes/representative_genomes.fna $contig        >> RF00177_files/RF00177_rep_seqs_${file_count}.fna;

done < RF00177_locations.txt


##from ~/phd/RNASeq/rfam_files/locations
##or
##from ~/phd/RNASeq/analysed_genomes_rfam_files/locations
for file in *_locations.txt;
do
outname=`basename $file _locations.txt`

echo $outname

i=0
file_count=1
mkdir -p ../${outname}_files/
> ../${outname}_files/${outname}_rep_seqs_${file_count}.fna
while read line; 
do 
  i=`expr $i + 1`
  if (( $i > 50 )); then
  i=0
  file_count=`expr $file_count + 1`
  > ../${outname}_files/${outname}_rep_seqs_${file_count}.fna
  fi

  
  contig=`echo $line | cut -d ' ' -f1`; 
  contig_start=`echo $line | cut -d ' ' -f2`; 
  contig_end=`echo $line | cut -d ' ' -f3`; 
  contig_strand=`echo $line | cut -d ' ' -f4`;  
  
  length=`expr $contig_end - $contig_start`
  
  length=`echo $length | tr -d '-'`
  


    esl-sfetch -c ${contig_start}..${contig_end} ../../${group}.fna $contig        >> ../${outname}_files/${outname}_rep_seqs_${file_count}.fna;

done < ${outname}_locations.txt



done < $file
done


```

###Make cm files {#make_cm_files}

The files with sequences for each rFam model need to be in stockholm alignment format which is done by running cmalign against the Rfam model.

```{bash make_cm_files, eval=F}
##from ~/phd/RNASeq/rfam_files/
##or
##~/phd/RNASeq/analysed_genomes_rfam_files

for folder in *_files; 
do 

  
  cmmodel=`basename $folder _files`;  

  
  cmfetch  ~/phd/RNASeq/Rfam.cm $cmmodel > current.cm;
  > $folder/ali_files.txt; 
  
  
  for file in $folder/*.fna; 
  do
  
    shortname=`basename $file`;
    outname=`basename $shortname .fna`;  
    cmalign -g --dnaout -o $folder/$outname.cm current.cm $file;  
    echo "$outname.cm" >> $folder/ali_files.txt;  
    
  done;  
done

```


###Remove empty files

Some of the files do not contain sequences and cause problems for the [merging](#section-combine_alignments) step. 

-   I think this is due to some earlier mistakes creating extra empty files that were not removed


```{bash remove_empty_files, eval=F}
for folder in *_files; 
do
  cd $folder
  
  > ali_files_2.txt
  
  while read line; 
  do
  
    line_length=`wc -l $line | cut -d ' ' -f1`
    
    if (( $line_length > 0 )); then
      echo $line >> ali_files_2.txt
    fi
    
  done < ali_files.txt
  mv ali_files_2.txt ali_files.txt
  cd ..

done
```


###Combine alignments {#combine_alignments}

Once the alignments have been built, it is possible to combine these alignments with `esl-alimerge` while also masking these alignments to the original model so that the alignments are kept very similar to the rfam family, while providing coordinates of the locations of sequences for the *representative* and *analysed* genomes.


```{bash combine_alignments, eval=F}
for folder in *_files;
do
  cd $folder
  outname=`basename $folder _files`
  echo $outname
  esl-alimerge --list ali_files.txt | esl-alimask --rf-is-mask - > $outname.stk
  cd ..
  
done
```


These files are downloaded from the server:

-   `cd ~/phd/RNASeq/srna_seqs/version_1/positive_control/large_alignments/alignments`

-   `scp bioc:./phd/RNASeq/rfam_files/alignments/* ./`


##Phylogenetic Distance

The bacterial ribosomal small subunit (RF00177) was used to get the phylogeneitc distances between all the genomes. This was done using [Phylip](https://evolution.genetics.washington.edu/phylip.html).

###Rename IDs

The phylip format for files uses shortened ID, limited to 10 characters. This means there needs to be a lookup table to reverse this in later steps.

```{r rename_alignment_ids, eval=F}
dat <- read.table("~/phd/RNASeq/RF00177.stk", sep = "\t", fill = T, comment.char = "", quote = "", header = F)

dat <- dat %>% separate(V1, into = c("a", "b", "c"), sep = " ", extra = 'merge', remove = F)

dat <- dat %>% mutate(id_test = ifelse(grepl(pattern = "/",x = b), T, F))


current_ids <- dat %>% filter(id_test) %>% select(b) %>% unique()

current_ids <- current_ids %>% separate(col = b, into = "id", extra = "drop", remove=F, sep = "/") %>% mutate(phylip_id = substr(x = b, start = 1, stop = 10))

write.csv(x = current_ids, file = "~/phd/RNASeq/uids_RF00177_alignment.txt", quote = F, row.names = F)
save(current_ids, file = "~/bin/r_git/R/r_files/current_ids.Rda")

```

###reformat_matrix

The phylip tool dnadist was used to create a distance matrix based on the SSU alignment.

The stockholm file was reformatted `esl-reformat phylip RF00177.stk > RF00177_rep_seqs_all.phylip` and this was used in dnadist as an input, with *RF00177_rep_seqs_all.dists* as the output. All settings used were defaults.

The matrix that is made is not in an easily useable format:

-   `cat  RF00177_rep_seqs_all.dists | tr '\n' ' ' | sed 's/ N/\nN/g' > RF00177_rep_MATRIX_all.dists`


###Lookup table (query and target)

A lookup table of  query genomes, target contigs and srna IDs was needed in later steps.

```{bash query_target_pairs, eval=F}
#done in the alignments file (such as ~/phd/RNASeq/srnas/predicted/combined_alignments_ids/alignments)
#saved on MacBook to .../predicted/
> ../query_target_pairs.txt
for file in *.stk; 
do 
  
  echo $file; 
  ID=`echo $file | cut -d '.' -f1,2 | cut -d "_" -f1,2`; 
  ID_2=`echo $file | cut -d '.' -f1,2 `;  
  grep ^"#=GS" $file | sort | uniq | cut -d "/" -f1 | cut -d ' ' -f2 | cut -d '|' -f2 | sed -e "s/$/   $ID   $ID_2/" >> ../query_target_pairs.txt;  
  
done
```


###Maximum phylogenetic distance 

The file containing the queries, targets and sRNA IDs (along with the same files for the *predicted* and *negative* *control* datasets) and the distance matrix were used to get the maximum phylogenetic distance between species for each sRNA.

```{r dna_dists_setup, eval=F, include=F}
run_all <- F
if(run_all){
dat <- read.table("~/phd/RNASeq/RF00177_rep_MATRIX_all.dists", sep = "", header = F, fill = T, stringsAsFactors = F, as.is = T)

dat <- dat %>% filter(!is.na(V2))


colnames(dat)[1] <- "phylip_id"

"NC_009791." %in% colnames(dat)

colnames(dat) <- c("names", dat$phylip_id)

dat[1:10,1:10]




# rownames(dat) <- colnames(dat)

for(i in 1:nrow(dat)){
  for(j in 2:ncol(dat)){
    # if(dat[i,1] == colnames(dat)[j]){
    #   if(dat[i,j] != 0){
    #     print(paste(i, j))
    #   }
    # }
    if(i + 1 == j){
      print(dat[i,j])
    }
  }
}






meltDat <- melt(dat)

colnames(meltDat) <- c("phylip_id", "query.name", "distance")

load(file = "~/bin/r_git/R/r_files/current_ids.Rda")
current_ids <- current_ids %>% unique()

current_ids <- current_ids %>% separate(col = id, into = c("t1", "t2"), sep = "\\|", remove = F, extra = 'warn') 

current_ids <- current_ids %>% mutate(id = ifelse(is.na(t2), t1, t2)) %>% 
  select(-t1, -t2)


contig_labels <- read.table("~/phd/RNASeq/genome_contig_pairs.txt")
colnames(contig_labels) <- c("id", "target.genome")

contig_labels <- contig_labels %>% left_join(current_ids, by = "id") %>% select(-b)


colnames(contig_labels) <- c("target.id", "target.genome", "phylip_id")


# colnames(contig_labels) <- c("target.name", "target.genome")
# contig_labels <- contig_labels %>% 
  # mutate(target.name = substr(x = target.name, start = 1, stop = 10)) %>% 
  # unique()


meltDat <- meltDat %>% left_join(contig_labels, by = 'phylip_id')

colnames(meltDat)[1:2] <- c("target.name", "phylip_id")

colnames(contig_labels) <- c("query.id", "query.genome", "phylip_id")

meltDat <- meltDat %>% left_join(contig_labels, by = 'phylip_id')

ggplot() +
  geom_freqpoly(data = meltDat, aes(x = distance, y = ..count..), binwidth = 0.05)

tmp <- meltDat %>% filter(distance > 0)


ggplot() +
  geom_freqpoly(data = tmp, aes(x = distance, y = ..count..), binwidth = 0.05)

colnames(meltDat)[2] <- c("query.name")


meltDat <- meltDat %>% filter(!is.na(query.genome), !is.na(target.genome))%>% group_by(target.genome, query.genome) %>% arrange(-as.numeric(distance)) %>% mutate(row_num = row_number()) %>% filter(row_num == 1) %>% select(-row_num)

mat <- reshape2::acast(data = meltDat %>% select(target.genome, query.genome, distance), formula = target.genome ~ query.genome)

distanceMat <- as.data.frame(mat)

save(distanceMat, file = "~/phd/RNASeq/distanceMat.Rda")

load("~/phd/RNASeq/distanceMat.Rda")

pairs <- read.table("~/phd/RNASeq/srna_seqs/version_1/predicted/query_target_pairs.txt")
colnames(pairs) <- c("target.name", "query.genome", "ID")
contig_labels <- read.table("~/phd/RNASeq/genome_contig_pairs.txt")
colnames(contig_labels) <- c("target.name", "target.genome")
pairs <- pairs %>% left_join(contig_labels, by = 'target.name')

pairs <- pairs %>% select(target.genome, ID) %>% unique()

pairs <- pairs %>% mutate_all(as.character)

srnas <- unique(pairs$ID)
max_val <- 0
max_dists <- data.frame(id = srnas, distance = NA)
counter <- 0


max_dists <- max_dists %>% mutate(complete = ifelse(is.na(distance), F, T))
length(unique(pairs$target.genome))


item <- 1

for(item in 1:nrow(max_dists)){
  printRemaining(i = item, length = nrow(max_dists), increment = 1)
  # counter <- counter + 1
  # if(counter > 5){
  #   break
  # }
  if(max_dists$complete[item] == T){
    print(paste(max_dists$id[item], "already done."))
    next
  }
  max_val <- 0
  # print(as.character(max_dists$id[item]))
  df <- pairs %>% filter(ID == as.character(max_dists$id[item])) %>% unique()
  

  if(nrow(df) == 1){
    max_val <- 0
    max_dists$distance[item] <- max_val
    max_dists$complete[item] <- T
    next
  }
genomes <- df$target.genome
rows <- match(x = genomes, table = rownames(distanceMat))
cols <- match(x = genomes, table = colnames(distanceMat))
rows <- rows[!is.na(rows)]
cols <- cols[!is.na(cols)]

max_val <- max(c(max(distanceMat[rows, cols]),max_val))

  max_dists$distance[item] <- max_val
  max_dists$complete[item] <- T
}

max_dists_pred <- max_dists
save(max_dists_pred, file = "~/bin/r_git/R/r_files/max_dists_pred.Rda")



pairs <- read.table("~/phd/RNASeq/query_target_pairs_pc.txt")

colnames(pairs) <- c("target.name", "ID")

pairs <- pairs %>% left_join(contig_labels, by = "target.name")

pairs <- pairs %>% mutate_all(as.character)

srnas <- unique(pairs$ID)
max_val <- 0
max_dists <- data.frame(id = srnas, distance = NA)
counter <- 0


max_dists <- max_dists %>% mutate(complete = ifelse(is.na(distance), F, T))
length(unique(dat$target.genome))


item <- 1

for(item in 1:nrow(max_dists)){
  printRemaining(i = item, length = nrow(max_dists), increment = 1)
  # counter <- counter + 1
  # if(counter > 5){
  #   break
  # }
  if(max_dists$complete[item] == T){
    print(paste(max_dists$id[item], "already done."))
    next
  }
  max_val <- 0
  # print(as.character(max_dists$id[item]))
  df <- pairs %>% filter(ID == as.character(max_dists$id[item])) %>% unique()
  

  if(nrow(df) == 1){
    max_val <- 0
    max_dists$distance[item] <- max_val
    max_dists$complete[item] <- T
    next
  }
genomes <- df$target.genome
rows <- match(x = genomes, table = rownames(distanceMat))
cols <- match(x = genomes, table = colnames(distanceMat))
rows <- rows[!is.na(rows)]
cols <- cols[!is.na(cols)]

max_val <- max(c(max(distanceMat[rows, cols]),max_val))

  max_dists$distance[item] <- max_val
  max_dists$complete[item] <- T
}

max_dists_pc <- max_dists
save(max_dists_pc, file = "~/bin/r_git/R/r_files/max_dists_pc.Rda")




pairs <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/query_target_pairs.txt")
colnames(pairs) <- c("target.name", "query.genome", "ID")
contig_labels <- read.table("~/phd/RNASeq/genome_contig_pairs.txt")
colnames(contig_labels) <- c("target.name", "target.genome")
pairs <- pairs %>% left_join(contig_labels, by = 'target.name')

pairs <- pairs %>% select(target.genome, ID) %>% unique()

pairs <- pairs %>% mutate_all(as.character)

srnas <- unique(pairs$ID)
max_val <- 0
max_dists <- data.frame(id = srnas, distance = NA)
counter <- 0


max_dists <- max_dists %>% mutate(complete = ifelse(is.na(distance), F, T))
length(unique(pairs$target.genome))


item <- 1

for(item in 1:nrow(max_dists)){
  printRemaining(i = item, length = nrow(max_dists), increment = 1)
  # counter <- counter + 1
  # if(counter > 5){
  #   break
  # }
  if(max_dists$complete[item] == T){
    print(paste(max_dists$id[item], "already done."))
    next
  }
  max_val <- 0
  # print(as.character(max_dists$id[item]))
  df <- pairs %>% filter(ID == as.character(max_dists$id[item])) %>% unique()
  

  if(nrow(df) == 1){
    max_val <- 0
    max_dists$distance[item] <- max_val
    max_dists$complete[item] <- T
    next
  }
genomes <- df$target.genome
rows <- match(x = genomes, table = rownames(distanceMat))
cols <- match(x = genomes, table = colnames(distanceMat))
rows <- rows[!is.na(rows)]
cols <- cols[!is.na(cols)]

max_val <- max(c(max(distanceMat[rows, cols]),max_val))

  max_dists$distance[item] <- max_val
  max_dists$complete[item] <- T
}

max_dists_nc <- max_dists
save(max_dists_nc, file = "~/bin/r_git/R/r_files/max_dists_nc.Rda")




pairs <- read.table("~/phd/RNASeq/srna_seqs/version_1/predicted/old/query_target_pairs_nr.txt")
colnames(pairs) <- c("target.name", "query.genome", "ID")
contig_labels <- read.table("~/phd/RNASeq/genome_contig_pairs.txt")
colnames(contig_labels) <- c("target.name", "target.genome")
pairs <- pairs %>% left_join(contig_labels, by = 'target.name')

pairs <- pairs %>% select(target.genome, ID) %>% unique()

pairs <- pairs %>% mutate_all(as.character)

srnas <- unique(pairs$ID)
max_val <- 0
max_dists <- data.frame(id = srnas, distance = NA)
counter <- 0


max_dists <- max_dists %>% mutate(complete = ifelse(is.na(distance), F, T))
length(unique(pairs$target.genome))


item <- 1

for(item in 1:nrow(max_dists)){
  printRemaining(i = item, length = nrow(max_dists), increment = 1)
  # counter <- counter + 1
  # if(counter > 5){
  #   break
  # }
  if(max_dists$complete[item] == T){
    print(paste(max_dists$id[item], "already done."))
    next
  }
  max_val <- 0
  # print(as.character(max_dists$id[item]))
  df <- pairs %>% filter(ID == as.character(max_dists$id[item])) %>% unique()
  

  if(nrow(df) == 1){
    max_val <- 0
    max_dists$distance[item] <- max_val
    max_dists$complete[item] <- T
    next
  }
genomes <- df$target.genome
rows <- match(x = genomes, table = rownames(distanceMat))
cols <- match(x = genomes, table = colnames(distanceMat))
rows <- rows[!is.na(rows)]
cols <- cols[!is.na(cols)]

max_val <- max(c(max(distanceMat[rows, cols]),max_val))

  max_dists$distance[item] <- max_val
  max_dists$complete[item] <- T
}

max_dists_pred_nr <- max_dists
save(max_dists_pred_nr, file = "~/bin/r_git/R/r_files/max_dists_pred_nr.Rda")

}
```

```{r dna_dists, eval=F, include=F}
run_all <- F
load("~/bin/r_git/R/r_files/max_dists_pred.Rda")
# load("~/bin/r_git/R/r_files/max_dists_pred_nr.Rda")
load("~/bin/r_git/R/r_files/max_dists_pc.Rda")
load("~/bin/r_git/R/r_files/max_dists_nc.Rda")



max_dists_pred <- max_dists_pred %>% mutate(group = "Predicted")
# max_dists_pred_nr <- max_dists_pred_nr %>% mutate(group = "Predicted NR")
max_dists_pc <- max_dists_pc %>% mutate(group = "Positive Control")
max_dists_nc <- max_dists_nc %>% mutate(group = "Negative Control")


dists <- max_dists_pred %>% bind_rows(max_dists_pc, max_dists_nc) %>% dplyr::rename(max_dist = distance) %>% filter(max_dist != 0)


distsCumulativeCount <- cumulativeCounts(dists = dists, smooth = F)

p <- ggplot() +
  geom_line(data = distsCumulativeCount, aes(x= max_dist, y = cumulative_prop, group = group, colour = group))
p
if(run_all){
ggsave(filename = "~/phd/RNASeq/figures/max_conservation_distance_4.svg", plot = p)
}
```

```{r large_tree, eval=F, include=F}
  # tree <- read.tree("~/bin/r_git/R/r_files/large_labelled_tree.tree")
  tree <- read.tree("~/bin/r_git/R/r_files/all_taxa.tree")
  p <-ggtree(tree) + 
  geom_tiplab() +
  xlim(0,0.8)
  p
  #ggsave(filename = "~/phd/RNASeq/figures/large_tree.svg", device = 'svg', width = 50, height = 50, limitsize = FALSE)
```




#Build families of sRNAs {#build_families_of_srnas}

***


Each individual sRNA was searched against the complete list of sRNAs in order to cluster the related sRNAs into families. These families were then used to search through all of the genomes in the clade to improve on the number of sequences per family. 

![Figure a. show the clade]()


##Check negative control for matches to known elements {#check_negaitves}

Go to:

-   [*Top*](#top)

-   [*Build families of sRNAs*](#section-build_families_of_srnas)

***


```{bash get_ids_and_positions, eval=F, include=T}
##done in ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/alignments_rnaalifold

group='predicted'
cd ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/alignments_rnaalifold
> ../${group}_contig_pos.txt
for file in *.stk;
do 

  ID=`echo $file | cut -d '.' -f1,2`
  echo $ID
  grep "/" $file | grep -v "//" | cut -d ' ' -f1 | sed 's/\// /g' | sed 's/-/ /g'| cut -d '|' -f2 | sort | uniq | sed -e "s/$/ $ID/" >> ../${group}_contig_pos.txt

done

```

##compare_groups_for_overlap



```{r compare_groups_for_overlap, eval=F}
library(GenomicRanges)
ncdat <- read.table("/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/negative_control_contig_pos.txt", sep = " ", fill = T, as.is = T)

pcdat <- read.table("/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/positive_control/large_alignments/positive_control_contig_pos.txt", fill = T, as.is = T)

preddat <- read.table("/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/predicted/large_alignments/predicted_contig_pos.txt", fill = T, as.is = T)


reformat_data <- function(dat){

colnames(dat) <- c("contig", "start", "stop", "srna")
dat <- dat  %>% select(contig, srna, start, stop) %>% mutate(strand = "+")

dat <- dat %>% mutate(start = as.numeric(start), stop = as.numeric(stop))

dat <- dat %>% mutate(tmpstart = ifelse(start < stop, start, stop),
                      tmpend = ifelse(start > stop, start, stop))
dat <- dat %>% filter(!is.na(tmpstart))
return(dat)
}

pcdat <- reformat_data(dat = pcdat)
ncdat <- reformat_data(dat = ncdat)
preddat <- reformat_data(dat = preddat)

getOverlapIDs <- function(queryDat, targetDat){
  queryDat <- queryDat %>% arrange(start)
  targetDat <- targetDat %>% arrange(start)
query <- GRanges(seqnames = queryDat$contig,
                 ranges = IRanges(start = queryDat$tmpstart, end = queryDat$tmpend),
                  strand = queryDat$strand, query_name = queryDat$srna)

target <- GRanges(seqnames = targetDat$contig,
                 ranges = IRanges(start = targetDat$tmpstart, end = targetDat$tmpend),
                  strand = targetDat$strand, query_name = targetDat$srna)


lookup1NC <- data.frame(id1 = queryDat$srna, queryHits = c(1:length(queryDat$srna)))
lookup2PC <- data.frame(id2 = targetDat$srna, subjectHits = c(1:length(targetDat$srna)))

tmp <- GenomicRanges::findOverlaps(query, target, type = 'any')

tmp <- as.data.frame(tmp)

tmp <- tmp %>% left_join(lookup1NC) %>% left_join(lookup2PC)
tmp <- tmp %>% mutate_all(as.character)
tmp <- tmp %>% filter(id1 != id2)

smallDat <- tmp %>% select(id1, id2) %>% unique()
return(smallDat)
}

nc.pc.Dat <- getOverlapIDs(queryDat =ncdat, targetDat = pcdat)
nc.pred.Dat <- getOverlapIDs(queryDat =ncdat, targetDat = preddat)
pc.pred.Dat <- getOverlapIDs(queryDat =preddat, targetDat = pcdat)

dat <- data.frame(ids = c(nc.pc.Dat$id1, nc.pred.Dat$id1))

write.table(dat, file = "~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/not_negative_control_ids.txt", row.names = F, col.names = F, quote = F)

dat2 <- data.frame(ids =  pc.pred.Dat$id1)

write.table(dat2, file = "~/phd/RNASeq/srna_seqs/version_1/predicted/large_alignments/predicted_matches_positive_control_ids.txt", row.names = F, col.names = F, quote = F)

```

##remove_not_nc



```{bash remove_not_nc, eval=F, include=T}
##done in ~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/combined_alignments_ids


cd ~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/

mkdir -p RNAAlifold/keep
mkdir -p alifold/keep
mkdir -p alignments_rnaalifold/keep
mkdir -p rscape_out/keep

mkdir -p RNAAlifold/ignore_2
mkdir -p alifold/ignore_2
mkdir -p alignments_rnaalifold/ignore_2
mkdir -p rscape_out/ignore_2




while read line;
do

mv ./RNAAlifold/$line* ./RNAAlifold/ignore_2
mv ./alifold/$line* ./alifold/ignore_2
mv ./alignments_rnaalifold/$line* ./alignments_rnaalifold/ignore_2
mv ./rscape_out/$line* ./rscape_out/ignore_2

done < not_negative_control_ids.txt

```

does not work
```{bash remove_pc_predicted, eval=F, include=T}
##done in ~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/combined_alignments_ids


cd ~/phd/RNASeq/srna_seqs/version_1/predicted/large_alignments/

mkdir -p RNAAlifold/keep
mkdir -p alifold/keep
mkdir -p alignments_rnaalifold/keep
mkdir -p rscape_out/keep

mkdir -p RNAAlifold/ignore_2
mkdir -p alifold/ignore_2
mkdir -p alignments_rnaalifold/ignore_2
mkdir -p rscape_out/ignore_2




while read line;
do

mv ./RNAAlifold/$line* ./RNAAlifold/ignore_2
mv ./alifold/$line* ./alifold/ignore_2
mv ./alignments_rnaalifold/$line* ./alignments_rnaalifold/ignore_2
mv ./rscape_out/$line* ./rscape_out/ignore_2

done < predicted_matches_positive_control_ids.txt

```


-   move the files in keep/ back into the original folder 
    
    -   *mv* *./keep/\** *./*


#Remove redundancy {#remove_redundancy}

***


Each of the predicted sRNAs have been used in a search of ~1500 genomes. As there are many sRNAs each comntributing to each model, it is important to enusre that each sequence only shows up in one model rather than several. This means combining the duplicated models to remove redundancy. This will be done by getting the coordinates of each match for each contig and checking for overlapping regions and the overlapping regions will be merged.

- done on the server (biochemcompute.uod.otago.ac.nz)
    



##redundancy_test_example


```{python redundacy_test_example}
test_contigs = ['N1', 'N2', 'N3', 'N4']
test_data = {'query_id':['G1', 'G2', 'G3', 'G1', 'G2', 'G3', 'G1', 'G1', 'G3', 'G3', 'G2', 'G3'], 
             'target_contig':['N1', 'N1', 'N1', 'N2', 'N2', 'N2', 'N3', 'N3', 'N3', 'N3', 'N4', 'N4'],
            'target_start':[1, 1, 2, 100, 100, 100, 940, 855, 940, 855, 1010, 1015],
            'target_end':[100, 100, 95, 180, 180, 180, 860, 935, 860, 935, 1110, 1120]}

test_dat = pd.DataFrame(test_data)
print(test_dat)

test_d = {}
for contig in test_contigs:
    print(contig)
    subsetDat =  test_dat.loc[test_dat['target_contig'] == contig]
    print(subsetDat)
    overlap_list = get_overlap_list(subsetDat = subsetDat)
    print(overlap_list)
    test_d = get_overlap_count(overlap_list = overlap_list, d = test_d)

test_d
```


##Coordinates of matches{#contigs_and_cordinates_of_matches}

From the output (stoockholm format) for each RUF, a file containing coordinates (target contig, query ID, start, end) id generated for the predicted and negative control dataset (should be done for the positive control as well).

```{bash contigs_and_cordinates_of_matches, eval=F}
##done in ~/phd/RNASeq/srnas/predicted/large_alignments/alignments
cd ~/phd/RNASeq/srnas/predicted/large_alignments/alignments
> ../../predicted_genomic_sequence_matches.txt
for file in *.stk;
do 

  ID=`echo $file | cut -d '.' -f1,2`
  grep ^"#=GS" $file | sort | uniq | cut -d "[" -f1 | sed -e "s/$/   $ID/" | cut -d ' ' -f2- | cut -d '|' -f2 >> ../../predicted_genomic_sequence_matches.txt

done
 
```

##redundancy_1_R 


-   there is a faster way of doing these steps with GRanges, however there are thresholds and variables that cannot be controlled so it is nopt being used. It might be possible, however the current method is good enough. 
    
    - I have used this for the negative control group as it is so much faster. Any repeats will use this method


```{r redundancy_1_R, eval=F}

dat <- read.table("/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/negative_control_contig_pos.txt", sep = " ", fill = T, as.is = T)
colnames(dat) <- c("contig", "start", "stop", "srna")
dat <- dat  %>% select(contig, srna, start, stop) %>% mutate(strand = "+")

dat <- dat %>% mutate(start = as.numeric(start), stop = as.numeric(stop))

dat <- dat %>% mutate(tmpstart = ifelse(start < stop, start, stop),
                      tmpend = ifelse(start > stop, start, stop))
dat <- dat %>% filter(!is.na(tmpstart))

# dat <- dat %>% separate(col = V1, into = c("contig", "coordinates"), sep = "\\/", remove = F)
# 
# dat <- dat %>% separate(col = coordinates, into = c("start", "stop"), sep = "-", remove = F)
# 
# dat <- dat %>% dplyr::rename(srna = V3) %>% select(contig, srna, start, stop) %>% mutate(strand = "+")
# 
# dat <- dat %>% mutate(start = as.numeric(start), stop = as.numeric(stop))
# 
# dat <- dat %>% mutate(tmpstart = ifelse(start < stop, start, stop),
#                       tmpend = ifelse(start > stop, start, stop))

query <- GRanges(seqnames = dat$contig,
                 ranges = IRanges(start = dat$tmpstart, end = dat$tmpend),
                  strand = dat$strand, query_name = dat$srna)


lookup1 <- data.frame(id1 = dat$srna, queryHits = c(1:length(dat$srna)))
lookup2 <- data.frame(id2 = dat$srna, subjectHits = c(1:length(dat$srna)))


tmp <- GenomicRanges::findOverlaps(query, query, type = 'any')

tmp <- as.data.frame(tmp)

tmp <- tmp %>% left_join(lookup1) %>% left_join(lookup2)

tmp <- tmp %>% filter(id1 != id2)

smallDat <- tmp %>% select(id1, id2) %>% unique()
smallDat <- smallDat %>% mutate_all(as.character)

s2 <- smallDat
s2$id1 <- smallDat$id2
s2$id2 <- smallDat$id1

smallDat <- smallDat %>% bind_rows(s2) %>% unique()

ids <- as.character(unique(dat$srna))
item <- ids[68]
item2 <- "alignments_GCA_000017765.1_689"

groupOverlapItems <- function(smallDat, item, current_ids){
  # print(length(current_ids))
  # print(item)
  if(length(current_ids) == 0){
    current_ids <- item
  }
  df <- smallDat %>% filter(id1 == item)

  if(nrow(df) == 0){
    return(current_ids)
  }
  df$seen <- df$id2 %in% current_ids
  df <- df %>% filter(seen == F)

  if(nrow(df) == 0){
    return(current_ids)
  }
  for(item2 in df$id2){
    current_ids <- unique(c(current_ids, item2))
    current_ids <- groupOverlapItems(smallDat, item2, current_ids)
  }
  return(current_ids)
}

item <- ids[ids == "alignments_GCA_000006945.2_2627"]
tmp <- groupOverlapItems(smallDat, item, current_ids = c())

checked_ids <- c()
for(item in ids){
  if(item %in% checked_ids){
    next
  }
  print(item)
  current_ids <- groupOverlapItems(smallDat, item, current_ids = c())
 
  checked_ids <- c(checked_ids, current_ids)
  
    write.table(x = current_ids, file = paste("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/combined_alignments_ids/", current_ids[1], "_combined_list.txt", sep = ""), append = T, quote = F, row.names = F, col.names = F)

  # mat <- as.data.frame(t(as.matrix(current_ids)))
  # write.table(mat, file = "~/phd/RNASeq/tmp/nc_overlaps", append = T, quote = F, col.names = F, row.names = F, sep = "\t")
}

```

##move_nc_quickly


```{bash move_nc_quickly, eval=F, include=F}
##done in ~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/combined_alignments_ids


cd ~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/

mkdir -p RNAAlifold/keep
mkdir -p alifold/keep
mkdir -p alignments_rnaalifold/keep
mkdir -p rscape_out/keep

mkdir -p RNAAlifold/ignore_2
mkdir -p alifold/ignore_2
mkdir -p alignments_rnaalifold/ignore_2
mkdir -p rscape_out/ignore_2


cd ~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/combined_alignments_ids

for file in *.txt;
do
idname=`basename $file _combined_list.txt`

mv ../RNAAlifold/$idname* ../RNAAlifold/keep
mv ../alifold/$idname* ../alifold/keep
mv ../alignments_rnaalifold/$idname* ../alignments_rnaalifold/keep
mv ../rscape_out/$idname* ../rscape_out/keep

while read line;
do

mv ../RNAAlifold/$line* ../RNAAlifold/ignore_2
mv ../alifold/$line* ../alifold/ignore_2
mv ../alignments_rnaalifold/$line* ../alignments_rnaalifold/ignore_2
mv ../rscape_out/$line* ../rscape_out/ignore_2


done < $file

done
```

##redundancy_1_in_python


This takes a long time to run.
Not sure that this is needed for anything more than a figure.

```{python redundancy_1, eval=F}
alignment_file_counts = pd.read_csv("/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/predicted/original_stats_all.txt", 
                                    header=None, delim_whitespace=True, names=list('abcdef'))
alignment_file_counts = alignment_file_counts.loc[alignment_file_counts['a'] == 'Number_of_sequences:']
alignment_file_counts = alignment_file_counts[['b', 'c']]
alignment_file_counts.columns = ['count', 'id']
alignment_file_counts['id'] = alignment_file_counts['id'].str.replace('.stk', '')
alignment_file_counts.set_index('id', inplace=True)
target_counts = alignment_file_counts.to_dict()

alignDat = pd.read_csv("/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/predicted/predicted_genomic_sequence_matches.txt", header=None, delim_whitespace=True)
alignDat = alignDat.iloc[:,[0,2]]
alignDat.columns = ["details", "query_id"]
alignDat[["target_contig", "coord"]] = alignDat.details.str.split("/", expand = True)
alignDat[["target_start", "target_end"]] = alignDat.coord.str.split("-", expand = True)
alignDat = alignDat[["query_id", "target_contig", "target_start", "target_end"]]
alignDat["target_start"] = alignDat["target_start"].astype(str).astype(int)
alignDat["target_end"] = alignDat["target_end"].astype(str).astype(int)
alignDat = alignDat.sort_values(by=['target_start'])
alignDat[:10]

target_contigs = alignDat.target_contig.unique()
query_ids = alignDat.query_id.unique()

if run_all == True:
    overlapping_ids = []
    lengths = []
    start_val = 0
    end_val = 0
    overlaps = []
    for contig in target_contigs:
        subsetDat =  alignDat.loc[alignDat['target_contig'] == contig]
        overlaps = get_overlap_vals(subsetDat, overlaps)
    df = pd.DataFrame(data = overlaps)
    df.to_csv('/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/predicted/overlaps_data.csv', index=False)
else:
  overlaps = pd.read_csv("/Users/thomasnicholson/bin/python_git/python_files/overlaps_data.csv",
  header=None, delim_whitespace=True) #might be too big for github

overlaps[:10]

fig = sns.displot(overlaps, kde=True)
figure(figsize = (20,20))
fig.savefig("/Users/thomasnicholson/phd/RNASeq/figures/displot.svg", dpi=100)

```

```{r, echo=FALSE, fig.width=8, fig.height=8}
knitr::include_graphics("/Users/thomasnicholson/phd/RNASeq/figures/displot.svg")
```

Group sRNAs if there is enough of an overlap and write out files. 

##redundancy_2



```{python redundancy_2, eval=F}
run_all = False
if run_all == True:
    d = {}
    for contig in target_contigs:
        print(contig)
        subsetDat =  alignDat.loc[alignDat['target_contig'] == contig]
        overlap_list = srna.get_overlap_list(subsetDat = subsetDat)
        d = srna.get_overlap_count(overlap_list = overlap_list, d = d)
    json_data = json.dumps(d)
    file = open('/Users/thomasnicholson/bin/python_git/python_files/dict.json', 'w')
    file.write(json_data)
    file.close()
    query_matches = {}
    query_counts = {}
    overlap_percentages = []
    threshold = 0
    for i in range(0, len(query_ids) -1):
        for j in range(i + 1, len(query_ids)):
            ids =[query_ids[i], query_ids[j]]
            ids.sort()
            current_id = "_".join(ids)
            count = min([target_counts['count'][query_ids[i]], target_counts['count'][query_ids[j]]])
            count = int(count)
            if current_id in d:
                if d[current_id]/count < 1 and d[current_id]/count > threshold:
                    overlap_percentages.append(d[current_id]/count)
                else:
                    overlap_percentages.append(1)
                if d[current_id]/count > threshold:
                    query_matches[current_id] = d[current_id]/count
                    query_counts[current_id] = [d[current_id]/count, count, d[current_id]]
    json_query_matches = json.dumps(query_matches)
    file = open('/Users/thomasnicholson/bin/python_git/python_files/query_matches.json', 'w')
    file.write(json_query_matches)
    file.close()
    json_query_counts = json.dumps(query_counts)
    file = open('/Users/thomasnicholson/bin/python_git/python_files/query_counts.json', 'w')
    file.write(json_query_counts)
    file.close()
    
    all_overlaps = {}
    ids_checked = []
    for key, value in d.items():
        ids = key.split("_")
        id1 = "_".join(ids[:3])
        id2 = "_".join(ids[3:])
        all_overlaps, ids_checked, make_new, counter = srna.unique_set_of_overlaps(all_overlaps, ids_checked, id1 =
        id1,
        id2 = id2)
        all_overlaps, ids_checked, make_new, counter = srna.unique_set_of_overlaps(all_overlaps, ids_checked, id1 =
        id2, id2 = id1)
        if make_new == True:
            all_overlaps[id1] = [id2]
    json_all_overlaps = json.dumps(all_overlaps)
    file = open('/Users/thomasnicholson/bin/python_git/python_files/all_overlaps.json', 'w')
    file.write(json_all_overlaps)
    file.close()
      
    number_of_ids_overlapping = {}
    for key, value in all_overlaps.items():
        number_of_ids_overlapping[key] = [len(value)]
    
    representative_ids = pd.DataFrame(number_of_ids_overlapping)
    representative_ids = representative_ids.T
    representative_ids.columns = ['id_count']
    representative_ids.index.name = 'id1'
    representative_ids.reset_index(inplace=True)
    representative_ids.to_csv('/Users/thomasnicholson/bin/python_git/python_files/representative_ids.csv', index=False)
    
    df = pd.DataFrame.from_dict(query_counts, orient='index', columns = ['percentage', 'total', 'count'])
    df.index.name = 'id'
    df.reset_index(inplace=True)    
    df.to_csv('/Users/thomasnicholson/bin/python_git/python_files/overlap_values.csv', index=False)
    
    combined_d = {}
    ids_checked = []
    for query in query_ids:
        if query not in ids_checked:
            combined_d, ids_checked = combined_alignments(query = query, combined_d = combined_d, ids_checked = ids_checked, query_matches = query_matches)

    json_combined_d = json.dumps(combined_d)
    file = open('/Users/thomasnicholson/bin/python_git/python_files/combined_d.json', 'w')
    file.write(json_combined_d)
    file.close()

else:
    with open('/Users/thomasnicholson/bin/python_git/python_files/dict.json', 'r') as read_file:
        d = json.load(read_file)
    with open('/Users/thomasnicholson/bin/python_git/python_files/query_counts.json', 'r') as read_file:
        query_counts = json.load(read_file)
    with open('/Users/thomasnicholson/bin/python_git/python_files/all_overlaps.json', 'r') as read_file:
        all_overlaps = json.load(read_file)    
    representative_ids = pd.read_csv('/Users/thomasnicholson/bin/python_git/python_files/representative_ids.csv')
    overlap_values_3 = pd.read_csv('/Users/thomasnicholson/bin/python_git/python_files/overlap_values.csv')    
    
    with open('/Users/thomasnicholson/bin/python_git/python_files/combined_d.json', 'r') as read_file:
        combined_d = json.load(read_file)      
```

Not sure if there is a purpose to this section.

##redundancy_2_overlapping_scores

```{python overlapping_scores, eval=F}
outfile = open('/Users/thomasnicholson/bin/python_git/python_files/ids_and_overlaps.csv', 'a')
for key, value in query_matches.items():
    names = key.split("_")
    id1 = names[:3]
    id1 = '_'.join(id1)
    id2 = names[3:]
    id2 = '_'.join(id2)
    outfile.write('%s,%s,%s\n' % (id1, id2, value))
```

-   List all the overlapping sRNAs in files

##output_of_list_of_sRNAs_to_combine



```{r output_of_list_of_sRNAs_to_combine, eval = F}
json_file <- "~/bin/python_git/python_files/combined_d.json"
json_data <- fromJSON(file=json_file)

values <- json_data["GCA_002848605.1_280"]


for(i in values[[1]]){
  print(i)
}
  
for(key in json_data){
  values <- json_data[key]
  print(paste("Key: ", key[1], " of length ", length(values[[1]])))
  for(value in values[[1]]){
    write.table(x = value, file = paste("~/phd/RNASeq/srna_seqs/version_1/predicted/combined_alignments_ids/", key[1], "_combined_list.txt", sep = ""), append = T, quote = F, row.names = F, col.names = F)
  }
}

```

-   Take the overlapping sRNAs, extract the fasta sequences and align the sequences.

##combine_sRNAs_bash



```{bash combine_sRNAs_bash, eval=F}
##done in ~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/combined_alignments_ids
mkdir -p fasta
mkdir -p hmm
mkdir -p alignments

for file in *.txt;
do
max_num="0"
outname=`basename $file _combined_list.txt`
echo $outname
> fasta/$outname.fa
while read line; 
do 

esl-reformat fasta ../alignments_rnaalifold/$line.stk >> fasta/$outname.fa

current_num=`esl-alistat ../alignments_rnaalifold/$line.stk | grep "Number of sequences" | cut -d ' ' -f 4`

if(( $current_num > $max_num ));
then

max_seq="$line.stk"
max_num="$current_num"
fi

done < $file

hmmbuild hmm/$outname.hmm ../alignments_rnaalifold/$max_seq

hmmalign --informat fasta hmm/$outname.hmm fasta/$outname.fa | esl-alimask -g --gapthresh 0.8 -p --pfract 0.5 --pthresh 0.5 - | esl-alimanip   --lnfract 0.6 --lxfract 1.4 --lmin 50 --lmax 500 --detrunc 50 - > alignments/$outname.stk

done


```

-   Get the fasta sequences as done for the known sRNAs

    -   [*get_fasta_sequence*](#get-fasta-sequence)



#Check negative controls {#check_negaitve_controls}

NOT SURE THIS IS USED

***


Description:

-   I want to remove negative control models that match either positive controls or predicted data as these are not true negative controls

-   manually saved a list of IDs (saved from the ncCovRNA file above) for the negative control set where the mean score >= 100 to a file called high_scoring_rnas.txt

##check_high_scoring_negative_control_sequences



```{bash check_high_scoring_negative_control_sequences, eval=F}

> high_scoring_rnas.fna
while read line;
do
echo $line

sequence=`grep "GC RF" alignments_rnaalifold/alignments_${line}.stk | cut -d ' ' -f3- | tr -d '_'`

echo ">$line" >> high_scoring_rnas.fna
echo $sequence >> high_scoring_rnas.fna

done < high_scoring_rnas.txt
```

-   build an hmm database for positive control and predicted

##build_hmm


```{bash build_hmm, eval=F}

##done in ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/alignments_rnaalifold

group='predicted'

for file in *.stk;
do
outname=`basename $file .stk | cut -d '_' -f2-`

hmmbuild ../hmm/${outname}.hmm $file

done

cd ../hmm/

> ../${group}.hmm

cat *.hmm >> ../${group}.hmm

cd ../

hmmpress ${group}.hmm
```

-   Get all of the fasta sequences

##fetch_all_negative_control_seqs


```{bash fetch_all_negative_control_seqs, eval=F}
##done in ~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/alignments_rnaalifold
for file in *.stk;
do

outname=`basename $file .stk | cut -d '_' -f2-`

esl-reformat fasta $file > ../fasta/${outname}.fna

done
```

-   Compare the hmm database to the fasta files of negative controls

##run_hmmscan


```{bash run_hmmscan, eval=F}

##done in ~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/fasta

group='predicted'

mkdir -p ${group}_output

for file in *.fna;
do
outname=`basename $file .fna`
echo $outname
hmmscan  --tblout ${group}_output/$outname.tbl --noali -E 1e-5 ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/${group}.hmm $file

done

```

##hmmscan_summary


```{bash hmmscan_summary, eval=F}
##done in ~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/fasta/${group}_output/
group='predicted'

> ../${group}_hmmscan.tbl
for file in *.tbl;
do

ID=`basename $file .tbl`; 

grep -v ^"#" $file |  sed -e "s/$/   $ID/" >> ../${group}_hmmscan.tbl
done


```

##hmmscan_analysis



```{r hmmscan_analysis}
pcdat <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/fasta/positive_control_hmmscan.tbl")

pcCounts <- pcdat %>% group_by(V20) %>% summarise(count = n())
pcMeans <- pcdat %>% group_by(V20) %>% summarise(mean.val = mean(V5))

pcSummary <- pcCounts %>% full_join(pcMeans)

# pcSummary <- pcSummary %>% filter(count > 3 | mean.val < 1e-10)

write.table(x = pcSummary %>% select(V20), file = "~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/remove_PC.txt", quote = F, row.names = F, col.names = F)


preddat <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/fasta/positive_control_hmmscan.tbl")

predCounts <- preddat %>% group_by(V20) %>% summarise(count = n())
predMeans <- preddat %>% group_by(V20) %>% summarise(mean.val = mean(V5))

predSummary <- predCounts %>% full_join(predMeans)

# pcSummary <- pcSummary %>% filter(count > 3 | mean.val < 1e-10)

write.table(x = predSummary %>% select(V20), file = "~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/remove_PRED.txt", quote = F, row.names = F, col.names = F)

```



##run_RNAcode.sh

```{bash run_RNAcode.sh, eval=F, include=F}
#!/bin/bash

##makes alignments and running alifoldz and r-scape
##GCA accession number.

usage(){
    echo "sraAlignAndFold.sh is a script for making a multiple sequence alignment and
    getting secondary structure information.  
Usage:
 fetchGenomeGCA.sh [opts] [input]

Options:
	-h	Display this help

Input	       
	-r	Folder location

"
}

while getopts "i:o:h" arg; do
case $arg in
	i) 
	FOLDER=${OPTARG};;
	o) 
	OUTPUT=${OPTARG};;
    h)
		usage
		exit
      ;;    
	\?) 
	echo "Unknown option: -${OPTARG}" >&2; exit 1;;
    esac
done

if [ -z ${FOLDER} ]; then
	FOLDER="./"
fi




mkdir -p "$FOLDER/rnacode_out"



let "fileNum = 0"
for file in alignments/*.stk; #change to _R for positive control
do

checkname=`basename $file .stk`
if [ -f "./rnacode_out/${checkname}.rnacode" ]; then
echo "Already exists: $file"
continue
else

	
nseqs=`esl-alistat $file | grep "Number of sequences" | cut -d ":" -f2`

length=`esl-alistat $file | grep "Alignment length:" | cut -d ":" -f2`
largest_length=`esl-alistat $file | grep "Largest" | cut -d ":" -f2`


if (( $length < 500 )); then

diffLength=`expr $largest_length - $length`

if (( $diffLength > $length ));then
echo "Alignment is poor: $file"
continue
fi

if (( $nseqs > 5000 )); then
echo "Skipping $file (length: $length, nseqs: $nseqs)"
echo "$file (length: $length, nseqs: $nseqs)" >> skipped_alignments.txt
continue
fi

if (( $nseqs < 3 )); then
echo "Skipping $file (length: $length, nseqs: $nseqs)"
#echo "$file (length: $length, nseqs: $nseqs)" >> skipped_alignments.txt
continue
fi

echo "Running RNAcode on $file (length: $length, nseqs: $nseqs)"
	
esl-reformat clustal $file | RNAcode --outfile ./rnacode_out/$checkname.rnacode

fi
fi

done


```

###rnacode_summary



```{bash rnacode_summary, eval=F}
#done on server from ~/phd/RNASeq/srna_seqs/version_1/${group}/combined_alignments_ids/rnacode_out/

group="positive_control"
> ../${group}.rnacode;
for file in *.rnacode;
do  
  ID=`basename $file .rnacode`; 
  cat $file | sed -e "s/$/\t$ID/"  >> ../${group}.rnacode;  
done

```

-   formatting for R

    -   cat negative_control.rnacode | sed 's/N/\tN/g' | grep -v "HSS" | grep -v "====" | grep -v "alignment(s) scored in" | grep -v "Delta" > tmp.rnacode

    -   cat predicted.rnacode | sed 's/N/\tN/g' | grep -v "HSS" | grep -v "====" | grep -v "alignment(s) scored in" | grep -v "Delta" > tmp.rnacode

    -   cat positive_control.rnacode | sed 's/N/\tN/g' | grep -v "HSS" | grep -v "====" | grep -v "alignment(s) scored in" | grep -v "Delta" > tmp.rnacode

###protein_coding_filter



```{r protein_coding_filter, eval=F}
ncDat <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/tmp.rnacode",
                    col.names = c("hss.id", "frame", "length", "from", "to", "seq.name", "start", "end", "score", "p.value", "srna"), fill = T)
ncDat <- ncDat %>% mutate(p.value = as.numeric(as.character(p.value)),
                          length = as.numeric(as.character(length)))
ncDat <- ncDat %>% filter(grepl(pattern = "alignments", hss.id) == F) %>% 
  filter(p.value < 0.05, length > 16)
ncRNAcode <- ncDat
save(ncRNAcode, file = "~/bin/r_git/R/r_files/ncRNAcode.Rda")

write.table(x = ncRNAcode %>% select(srna) %>% unique(), file = "~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/remove_RNAcode.txt", quote = F, row.names = F, col.names = F)

predDat <- read.table("~/phd/RNASeq/srna_seqs/version_1/predicted/large_alignments/tmp.rnacode",
                    col.names = c("hss.id", "frame", "length", "from", "to", "seq.name", "start", "end", "score", "p.value", "srna"), fill = T)
predDat <- predDat %>% mutate(p.value = as.numeric(as.character(p.value)),
                          length = as.numeric(as.character(length)))
predDat <- predDat %>% filter(grepl(pattern = "alignments", hss.id) == F) %>% 
  filter(p.value < 0.05, length > 16)
predRNAcode <- predDat
save(predRNAcode, file = "~/bin/r_git/R/r_files/predRNAcode.Rda")



pcDat <- read.table("~/phd/RNASeq/srna_seqs/version_1/positive_control/large_alignments/tmp.rnacode",
                    col.names = c("hss.id", "frame", "length", "from", "to", "seq.name", "start", "end", "score", "p.value", "srna"), fill = T)
pcDat <- pcDat %>% mutate(p.value = as.numeric(as.character(p.value)),
                          length = as.numeric(as.character(length)))
pcDat <- pcDat %>% filter(grepl(pattern = "alignments", hss.id) == F) %>% 
  filter(p.value < 0.05, length > 16)
pcRNAcode <- pcDat


save(pcRNAcode, file = "~/bin/r_git/R/r_files/pcRNAcode.Rda")
```

-   manual made by adding accessions that I found to definity be matching to something.

-   cat remove_* >> foobar

-   cat foobar | sed 's/alignments_//g' | sort | uniq > remove_ALL.txt

##remove_negative_controls_matching_features

```{bash remove_negative_controls_matching_features, eval=F}
##done in ~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/
mkdir -p rscape_out/ignore
mkdir -p alifold/ignore
mkdir -p RNAAlifold/ignore
mkdir -p alignments_rnaalifold/ignore

file="remove_MANUAL.txt"
while read line;
do
echo $line

mv rscape_out/*${line}*  rscape_out/ignore/
mv alifold/*${line}*  alifold/ignore/
mv RNAAlifold/*${line}*  RNAAlifold/ignore/
mv alignments_rnaalifold/*${line}*  alignments_rnaalifold/ignore/

grep -v $line query_target_pairs.txt > foobar
mv foobar query_target_pairs.txt

done < $file



file="remove_ALL.txt"
while read line;
do
echo $line

mv alifold/alignments_${line}.stk.alifold  alifold/ignore/


done < $file


```

#Score sRNAs {#score_rnas}

***

**Scripts involved for scoring the sRNAs**

-   [*run_RNAAlifold.sh*](#section-run_rnaalifold.sh)

    -   Produces the alignment file with predicted secondary structure included (useful for later steps) and a visualisation of the predicted secondary structure.
    
-   [*run_Alifold.sh*](#section-run_alifold.sh) 

    -   Compares the predicted secondary structure to a series of alignments from randomly shuffled sequence to give an idea of the how likley it is that the given secondary structure  could occur by chance (in the form of a z-score of the MFE).

-   [*run_R-scape.sh*](#section-run_r-scape.sh) 

    - Looks for coovaritation in the alignments.

-   [*run_rmfamscan.sh*](#section-run_rmfamscan.sh) *-e* *\<file extentsion\>* *-a*
    
    - Looks for motifs in the sRNAs

***

-   Runs RNAAlifold on all *.stk files in an alignments/ folder
    
    -   moves the alignments into a folder
    
    -   moves secondary structure images into a folder
    
    -   can be stopped and restarted
    

##run_RNAAlifold.sh

Go to:

-   [*Top*](#top)

-   [*Score RNAs*](#section-score_rnas)

***

```{bash run_RNAAlifold.sh, eval=F, include=T}
#!/bin/bash

##makes alignments and running alifoldz and r-scape
##GCA accession number.

usage(){
    echo "sraAlignAndFold.sh is a script for making a multiple sequence alignment and
    getting secondary structure information.  
Usage:
 fetchGenomeGCA.sh [opts] [input]

Options:
	-h	Display this help

Input	       
	-r	Folder location

"
}

while getopts "i:o:h" arg; do
case $arg in
	i) 
	FOLDER=${OPTARG};;
	o) 
	OUTPUT=${OPTARG};;
    h)
		usage
		exit
      ;;    
	\?) 
	echo "Unknown option: -${OPTARG}" >&2; exit 1;;
    esac
done

if [ -z ${FOLDER} ]; then
	FOLDER="./"
fi




mkdir -p "$FOLDER/alifold/post_script"
mkdir -p "$FOLDER/RNAAlifold"
mkdir -p alignments_rnaalifold


let "fileNum = 0"
for file in alignments/*.stk

do
lines=`wc -l < $file`
if (( $lines < 1));then
continue
fi

outname=`basename $file`


if [ -f "$FOLDER/RNAAlifold/$outname.rnaalifold" ]; then
	echo "Already exists: $file"
	continue
fi




echo "Running on: $file"


start=`grep "GCA" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f1`
end=`grep "GCA" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f2`

if [[ $start == "" ]]; then
	start=`grep "NC_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f1`
	end=`grep "NC_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f2`

fi

if [[ $start == "" ]]; then
	start=`grep "NZ_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f1`
	end=`grep "NZ_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f2`

fi

if [[ $start == "" ]]; then
	head $file
fi




length=`expr $end - $start`

if (( $length < 0 )); then
	length=$(( -1 * $length ))
fi

if (( $length < 500 )); then
esl-reformat  clustal $file  | RNAalifold --aln-stk=${file} >> ./RNAAlifold/$outname.rnaalifold
cat alirna.ps > ./alifold/post_script/$outname.ps      
else
	echo "Skipping: $file"
fi

done


for file in alignments_G*;
do
outname=`basename $file .stk.stk`

mv $file ./alignments_rnaalifold/$outname.stk

done
```

-   Combine the output from RNAAlifold into single files for further analysis

###rnaalifold_summary

Go to:

-   [*Top*](#top)

-   [*Score RNAs*](#section-score_rnas)

***

```{bash rnaalifold_summary, eval=F}
#done from ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/RNAALifold
group="negative_control"
> ../${group}.rnaalifold; 
for file in *.rnaalifold;
do   
  
  if [ $file == *"\.stk\.stk\.rnaalifold" ]; then 
    ID=`basename $file .stk.stk.rnaalifold`; 
  else 
    ID=`basename $file .stk.rnaalifold`; 
  fi; 
  
  MFE=`grep "=" $file | rev | cut -d "(" -f1 | rev | cut -d "=" -f1`; echo "$ID $MFE" >> ../${group}.rnaalifold; 

done
```

-   Positive control set has different naming and needs the files moved with another step

###positive_control_alignments

Go to:

-   [*Top*](#top)

-   [*Score RNAs*](#section-score_rnas)

***

```{bash move_positive_control_alignments, eval=F}
for file in alignments_R*;
do
  outname=`basename $file .stk.stk`
  mv $file alignments_rnaalifold/$outname.stk
done
```

-   Negative control set has different naming and needs the files moved with another step

###negative_control_alignments

Go to:

-   [*Top*](#top)

-   [*Score RNAs*](#section-score_rnas)

***

```{bash move_negative_control_alignments, eval=F}
for file in alignments_a*;
do
tmpname=`echo $file | cut -d '_' -f2,3,4,5`
  outname=`basename $tmpname .stk.stk`
  mv $file alignments_rnaalifold/$outname.stk
done
```

###rnaalifold_outputs

Go to:

-   [*Top*](#top)

-   [*Score RNAs*](#section-score_rnas)

***

```{bash rnaalifold_outputs, eval=F}
group="predicted"

cd ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/RNAALifold

> ../${group}_alifold_score.txt;
> ../${group}_mfe.txt;

for file in *.rnaalifold;
do   
  
  if [ $file == *"\.stk\.stk\.rnaalifold" ]; then 
    ID=`basename $file .stk.stk.rnaalifold`; 
  else 
    ID=`basename $file .stk.rnaalifold`; 
  fi; 
  
  MFE=`grep "=" $file | rev | cut -d "(" -f1 | rev | cut -d "=" -f1`; echo "$ID $MFE" >> ../${group}_alifold_score.txt; 
  MFE=`grep "=" $file | rev | cut -d "(" -f1 | rev | cut -d "=" -f2 | cut -d "+" -f1`; echo "$ID $MFE" >> ../${group}_mfe.txt; 

  MFE=`grep "=" $file | rev | cut -d "(" -f1 | rev | cut -d "=" -f2 | cut -d "+" -f2 | tr -d ")"`; echo "$ID $MFE" >> ../${group}_alifold_covariation.txt; 

done


```

##run_rscape.sh

```{bash run_R-scape.sh, eval=F, include=T}
#!/bin/bash

##makes alignments and running alifoldz and r-scape
##GCA accession number.

usage(){
    echo "sraAlignAndFold.sh is a script for making a multiple sequence alignment and
    getting secondary structure information.  
Usage:
 fetchGenomeGCA.sh [opts] [input]

Options:
	-h	Display this help

Input	       
	-r	Folder location

"
}

while getopts "i:o:h" arg; do
case $arg in
	i) 
	FOLDER=${OPTARG};;
	o) 
	OUTPUT=${OPTARG};;
    h)
		usage
		exit
      ;;    
	\?) 
	echo "Unknown option: -${OPTARG}" >&2; exit 1;;
    esac
done

if [ -z ${FOLDER} ]; then
	FOLDER="./"
fi




mkdir -p "$FOLDER/rscape_out"



let "fileNum = 0"
for file in alignments_G*;
do

checkname=`basename $file .stk`
if [ -f "../rscape_out/${checkname}_1.R2R.sto" ]; then
echo "Already exists: $file"
continue
else

echo "Running R-scape on: $file"
	
fi

time R-scape --r2rall --outdir ../rscape_out/ $file > rsacpe.out

done
```

-   Combine the output from Rscape into single files for further analysis

###rscape_summary

Go to:

-   [*Top*](#top)

-   [*Score RNAs*](#section-score_rnas)

***

```{bash rscape_summary,eval=F}
#done from ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/rscape_out/

group="negative_control"
> ../${group}.rscape.cov;
for file in *.sorted.cov;
do  
  tmpname=`echo $file | cut -d '_' -f2,3,4`; 
  ID=`basename $tmpname .stk.stk`; 
  cat $file | sed -e "s/$/	$ID/"  >> ../${group}.rscape.cov;  
done

```


##run_alifold.sh

```{bash run_Alifold.sh, eval=F, include=T}
#!/bin/bash

##makes alignments and running alifoldz and r-scape
##GCA accession number.

usage(){
    echo "sraAlignAndFold.sh is a script for making a multiple sequence alignment and
    getting secondary structure information.  
Usage:
 fetchGenomeGCA.sh [opts] [input]

Options:
	-h	Display this help

Input	       
	-r	Folder location

"
}

while getopts "i:o:h" arg; do
case $arg in
	i) 
	FOLDER=${OPTARG};;
	o) 
	OUTPUT=${OPTARG};;
    h)
		usage
		exit
      ;;    
	\?) 
	echo "Unknown option: -${OPTARG}" >&2; exit 1;;
    esac
done

if [ -z ${FOLDER} ]; then
	FOLDER="./"
fi




mkdir -p "$FOLDER/alifold/post_script"



let "fileNum = 0"
for file in alignments_rnaalifold/*.stk


do

outname=`basename $file`
if [ -f "$FOLDER/alifold/$outname.alifold" ]; then
	#echo "$FOLDER/alifold/$file.alifold"
	echo "Already exists: $file"
	continue
else
	echo "Checking size: $file"
fi


lines=`wc -l < $file`
if (( $lines < 1));then
continue
fi


nseqs=`grep "#=" $file | cut -d ' ' -f2 | sort | uniq | wc -l`


start=`grep "GCA" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f1`
end=`grep "GCA" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f2`

if [[ $start == "" ]]; then
	start=`grep "NC_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f1`
	end=`grep "NC_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f2`

fi

if [[ $start == "" ]]; then
	start=`grep "NZ_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f1`
	end=`grep "NZ_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f2`

fi

if [[ $start == "" ]]; then
	head $file
fi




length=`expr $end - $start`

if (( $length < 0 )); then
	length=$(( -1 * $length ))
fi

if (( $length < 500 )); then

ID=`grep "NC_" $file | head -n 1 | cut -d " " -f2`

if [[ $ID == "" ]]; then
	ID=`grep "NZ_" $file | head -n 1 | cut -d " " -f2`
fi

if [[ $ID == "" ]]; then
	ID=`grep GCA_" $file | head -n 1 | cut -d " " -f2`
fi

if [[ $ID == "" ]]; then
	head $file
else
alignmentLength=`grep $ID $file | grep -v "#" | tr -s ' ' | cut -d ' ' -f2 | wc -c`

diffLength=`expr $alignmentLength - $length`

if (( $diffLength > $length ));then
echo "Alignment is poor: $file"
continue
fi
fi




echo "Running alifoldz.pl on $file (length: $length, nseqs: $nseqs)"

time esl-reformat  clustal $file  | alifoldz.pl > ./alifold/$outname.alifold         
 

else

	echo "Skipping: $file"


fi

done
```


###alifold_summary


```{bash alifold_summary, eval=F}

#done in ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/alifold 

group="negative_control"
> ../${group}.alifold
for file in *.alifold;  
do 

  ID=`echo $file | cut -d '.' -f1,2`; 
  grep -v "#" $file | grep -v "From" | grep -v "\-\-\-" | tr -s ' '  | sed -e "s/$/   $ID/" >> ../${group}.alifold
  
done

```

## run_rmfamscan.sh

###rmfamscan_script

-   Done in ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/alignments_rnaalifold


```{bash run_rmfamscan.sh, eval=F, include=T}
#!/bin/bash

##Run rmfam over all fasta files

usage(){
    echo "run_rmfam_scan.sh is a script for running rmfam_scan over a set of fasta
    files.  
Usage:
 run_rmfam_scan.sh [opts] [extension]

Options:
	-h	Display this help

Input
	-e extension	       
	-a	align
	-o output
	-k keep tmp files

"
}

align="F"
keep="F"
while getopts "e:ao:hk" arg; do
case $arg in
	e)
		extension=${OPTARG}
		;;
	a) 
		align="T"
		;;
    h)
		usage
		exit
      ;;    
    k)
		keep="T"
      	;;   
	\?) 
	echo "Unknown option: -${OPTARG}" >&2; exit 1;;
    esac
done

COUNTER=0
mkdir -p "rmfam_cmscan"
mkdir -p "rmfam_gff_files"
mkdir -p "rmfam_tblout"


let "fileNum = 0"
if [[ $extension == "fna" ]]; then

	for file in *.$extension
	do
		if [ -f "rmfam_tblout/$file.out.tblout" ]; then
			echo "Already exists: $file"
 			continue
		fi
		length=`grep -v ">" $file | wc -c`
		if (( $length < 500 )); then
			echo "Running rmfam_scan on $file (length: $length)"
			time rmfam_scan.pl -g -f ~/phd/RNASeq/RMfam/scripts/RMfam.cm $file -o $file.out 
			mv *.tblout rmfam_tblout
			mv *.cmscan rmfam_cmscan
			mv *.gff rmfam_gff_files
		else
			echo "Skipping: $file"
		fi
	done
else


for file in *.$extension

do


if [ -f "rmfam_tblout/$file.out.tblout" ]; then
	echo "Already exists: $file"
 	continue
else
echo "Checking size: $file"
fi


lines=`wc -l < $file`
if (( $lines < 1));then
continue
fi

# COUNTER=$((COUNTER+1))
# 
# if (( $COUNTER > 100 )); then
# echo "waiting"
# COUNTER=1
# time wait
# 
# 
# 
# fi


# if [[ $align == "T" ]]; then

# echo "Aligning $file"
# esl-reformat  clustal $file > $file.clustal

nseqs=`grep "#=" $file | cut -d ' ' -f2 | sort | uniq | wc -l`


start=`grep "GCA" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f1`
end=`grep "GCA" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f2`

if [[ $start == "" ]]; then
	start=`grep "NC_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f1`
	end=`grep "NC_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f2`

fi

if [[ $start == "" ]]; then
	start=`grep "NZ_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f1`
	end=`grep "NZ_" $file | head -n 1 | cut -d " " -f2 | cut -d "/" -f2 | cut -d "-" -f2`

fi

if [[ $start == "" ]]; then
	head $file
fi




length=`expr $end - $start`

if (( $length < 0 )); then
	length=$(( -1 * $length ))
fi

if (( $length < 500 )); then

ID=`grep "NC_" $file | head -n 1 | cut -d " " -f2`

if [[ $ID == "" ]]; then
	ID=`grep "NZ_" $file | head -n 1 | cut -d " " -f2`
fi

if [[ $ID == "" ]]; then
	ID=`grep GCA_" $file | head -n 1 | cut -d " " -f2`
fi

if [[ $ID == "" ]]; then
	head $file
else
alignmentLength=`grep $ID $file | grep -v "#" | tr -s ' ' | cut -d ' ' -f2 | wc -c`

diffLength=`expr $alignmentLength - $length`

if (( $diffLength > $length ));then
echo "Alignment is poor: $file"
continue
fi
fi




echo "Running rmfam_scan on $file (length: $length, nseqs: $nseqs)"

 time rmfam_scan.pl -g -f ~/phd/RNASeq/RMfam/scripts/RMfam.cm $file -o $file.out 
 
 
 mv *.tblout rmfam_tblout
mv *.cmscan rmfam_cmscan
mv *.gff rmfam_gff_files
 
else

	echo "Skipping: $file"


fi

done

fi

cd rmfam_tblout

let "fileNum = 0"

for file in *.tblout

do

sed 's/  /__/g' $file | sed 's/ /--/g' | sed 's/__/ /g' | tr -s ' ' | sed 's/ --/ /g' | sed 's/-- / /g' | sed 's/--!/ !/g' | tr ' ' '\t' | sed 's/--/_/g' > $file.formatted.tblout

done

```

###rmfamscan_summary

```{bash rmfamscan_summary, eval=F}
##done in ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/rmfam_gff_files

group='predicted'
cd ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/alignments_rnaalifold/rmfam_gff_files
> ../../${group}.rmfam;  
for file in *.gff;    
do    
tmpname=`echo $file | sed 's/\.clustal//g'`;  
ID=`basename $tmpname .stk.stk.gff`;  
grep -v "#" $file | sed -e "s/$/   $ID/" >> ../../${group}.rmfam;  
done

```


##gc_content


-   In order to get gc content info a fasta file is created for each alignment

-   Along with this file, the reference sequence is written to another main file.

###get_fasta_sequence

```{bash get_fasta_sequence, eval=F}
#done from ~/phd/RNASeq/srna_seqs/version_1/positive_control/large_alignments/alignments_rnaalifold 
for file in *.stk;
do
outname=`basename $file .stk`
esl-reformat fasta $file > ../fasta/$outname.fna
done
```


###get_reference_fasta


```{bash get_reference_fasta, eval=F}
#done from ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/alignments_rnaalifold
group='nc'
> ../${group}_rf.fna
for file in *.stk;
do
outname=`basename $file .stk`
echo ">$outname" >> ../${group}_rf.fna
cat $file | grep "#=GC RF" | cut -d ' ' -f3-  | tr -d ' ' >> ../${group}_rf.fna
done
```

-   GC percentage is calculated from the _rf.fna file using:

    -   sRNAGCPercentage.py -i ${group}_rf.fna -o ${group}_rf.gc

###sRNAGCPercentage.py

```{python sRNAGCPercentage.py, eval=F, include=T}
#!/usr/bin/python


##import packages
import sys
from Bio import SeqIO
from Bio.SeqUtils import GC
import getopt


help = '''
    sRNAGCPercentage.py v 0.1 (August 2020) is a script for {}.
    Usage:
         sRNAGCPercentage.py [options] <input> <output>
    
    Options:
        -h	Display this help
        -q  Supress messages
    Input
        -i	<input> the input
        -o	<output> the output

    
'''

def usage():
    print help

def rungetopts():
    try:
        opts, args = getopt.getopt(sys.argv[1:], "i:o:qh", ["input", "output", "quiet", "help"])
    except getopt.GetoptError as err:
        print(err)
        usage()
        sys.exit(2)
    input = ""
    output = ""
    for o, a in opts:
            if o in ("-h", "--help"):
                usage()
                sys.exit()
            elif o in ("-i", "--input"):
                input = a
            elif o in ("-o", "--output"):
                output = a
            else:
                assert False, "unhandled option"
    if output == "":
        print "-o <output> missing. For more help use -h"
        sys.exit(2)
    if input == "":
        print "-i <input> missing. For more help use -h"
        sys.exit(2)
    return(input, output)


def main():

    inFile, outFile = rungetopts()
    record = list(SeqIO.parse(inFile, "fasta"))
    output = open(outFile, "a")
    for my_seq in record:
        id = my_seq.id
        gc_value = GC(my_seq.seq)
        output.write("%s\t%s\n" % (id, gc_value))



if __name__ == "__main__":
    main()

```




##get RNA labels from Rfam {#get_rna_labels}

```{bash get_rna_labels, eval=F}
> rfam_descriptions.txt
for folder in *_files;
do
outname=`basename $folder _files`
echo $outname
description=`cmfetch  ~/phd/RNASeq/Rfam.cm $outname | grep ^"NAME" | head -n 1 | tr -s ' ' | cut -d ' ' -f2-`

echo "${outname} ${description}" >> rfam_descriptions.txt

done
```

###view_rfam_descriptions


```{r view_rfam_descriptions}
rfam <- read.table("~/phd/RNASeq/srna_seqs/version_1/positive_control/rfam_descriptions.txt", sep = " ")

```



##sRNA_read_depths


###sRNA_read_depths_script


```{bash sRNA_read_depths, eval=F, include=T}
##Done in ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/alignments_rnaalifold
group='predicted'
if [[ $group ==  'positive_control' ]];
then
cd ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/analysed_genomes/alignments
> ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/${group}_read_depths_summary_ALL_reads.txt
else
cd ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/alignments_rnaalifold
> ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/${group}_read_depths_summary.txt
fi

#file=alignments_GCA_000006765.1_12.stk
for file in *.stk;
  do
  genome_name=`echo $file | cut -d '_' -f2,3`
  ID=`echo $file | cut -d '_' -f2,3,4 | sed 's/\.stk//g'`
  
  cat $file | grep -v ^"#" | grep "/" | grep -v "//" | cut -d ' ' -f1 > ~/phd/RNASeq/tmp/tmp.txt
  while read line; 
    do
    contig=`echo $line | cut -d '/' -f1`
    coord=`echo $line | cut -d '/' -f2`
    realstart=`echo $coord | cut -d '-' -f1`
    realstop=`echo $coord | cut -d '-' -f2`
    start=`echo $coord | cut -d '-' -f1`
    stop=`echo $coord | cut -d '-' -f2`    
    #echo $contig
    genome=`grep $contig ~/phd/RNASeq/sequences/contig_ids_accession.lookup | cut -f2`
    genus=`grep $contig ~/phd/RNASeq/contig_descriptions.txt | cut -f2 | cut -d '_' -f1`
#    if [[ $genome != $genome_name ]]; then
#      continue
#    fi
    stats=`esl-seqstat -a ~/phd/RNASeq/sequences/${genome}.fna`
    esl-seqstat -a ~/phd/RNASeq/sequences/${genome}.fna | grep "=" > ~/phd/RNASeq/tmp/tmp.stats
    current_count=0
    while read stat_line;
      do
      chromosome=`echo "$stat_line" | grep $contig | wc -l | cut -d ' ' -f8`
      if (( $chromosome > 0 ));
        then
        tmpstart=$(($start + $current_count))
        tmpstop=$(($stop + $current_count))
        if (( $tmpstart < $tmpstop  )); then
          start=$tmpstart
          stop=$tmpstop
        else
          stop=$tmpstart
          start=$tmpstop
        fi
        
        if [[ ! -d ~/phd/RNASeq/genera/${genus}/${genome}.data/plot_files ]];
          then
          echo "Genome: ${genome} has no plot files"
          continue
        fi
        #echo "~/phd/RNASeq/genera/${genus}/${genome}.data/plot_files $start $stop"
        > ~/phd/RNASeq/tmp/test.plot
        counter="1"
        for plotfile in ~/phd/RNASeq/genera/${genus}/${genome}.data/plot_files/*.plot;
          do
          if [[ $plotfile == *"ncRNA"* ]]; then
            continue
          elif [[ $plotfile == *"rev"* ]]; then
            continue
          elif [[ $plotfile == *"fwd"* ]]; then
            continue            
          fi
          echo "$plotfile $genus $genome"
          sed -n "${start},${stop}{p;${stop}q;}"  $plotfile > ~/phd/RNASeq/tmp/tmp.plot
          if [[  $counter ==  "1" ]];
          then
            cat ~/phd/RNASeq/tmp/tmp.plot > ~/phd/RNASeq/tmp/test.plot
            counter="2"
          else
            cat ~/phd/RNASeq/tmp/test.plot > ~/phd/RNASeq/tmp/tmp2.plot 
            paste ~/phd/RNASeq/tmp/tmp2.plot ~/phd/RNASeq/tmp/tmp.plot > ~/phd/RNASeq/tmp/test.plot
          fi
        done
        #cp test.plot ~/phd/RNASeq/tmp
        summarise_sRNA_read_depths.R
        cat ~/phd/RNASeq/tmp/test.values | sed -e "s/$/ $ID $genus $genome_name $genome $contig $realstart $realstop $start $stop/" >> ~/phd/RNASeq/srna_seqs/version_1/${group}/large_alignments/${group}_read_depths_summary_reads.txt
      else
        length=`echo $stat_line | cut -d ' ' -f3`
        current_count=$(($current_count + $length))
      fi
      
    done < ~/phd/RNASeq/tmp/tmp.stats
  done < ~/phd/RNASeq/tmp/tmp.txt
done
```

###sRNA_read_depths_predicted


-   Get read depths for the originally predicted sRNAs

```{bash sRNA_read_depths_predicted, eval=F, include=T}
##done in ~/phd/RNASeq/genera/
#${genera}/${accession}.data

#cd ~/phd/RNASeq/genera/
#> ~/phd/RNASeq/srna_seqs/version_1/predicted/large_alignments/predicted_read_depths_summary_reads_from_new_calls.txt
#for genera in *;
#do
genera="Serratia"
echo $genera

> ~/phd/RNASeq/srna_seqs/version_1/predicted/large_alignments/predicted_read_depths_summary_reads_${genera}.txt


cd ~/phd/RNASeq/genera/${genera}/

for folder in *.data;
do
  accession=`basename $folder .data`
  cd ~/phd/RNASeq/genera/${genera}/${accession}.data
  echo $accession
  
  while read line;
  do
    #echo $line
    contig=`echo $line | cut -d ' ' -f1`
    if [[ $contig == "sequence"  ]]; then
      continue
    fi
    #coord=`echo $line | cut -d '/' -f2`
    realstart=`echo $line | cut -d ' ' -f3`
    realstop=`echo $line | cut -d ' ' -f4`
    start=`echo $line | cut -d ' ' -f3`
    stop=`echo $line | cut -d ' ' -f4` 
    ID=`echo $line | cut -d ' ' -f13`
    genome=`echo $ID | cut -d "_" -f1,2`
    echo "${genome} ${contig} (${ID}): ${realstart}-${realstop}"
    stats=`esl-seqstat -a ~/phd/RNASeq/sequences/${genome}.fna`
    esl-seqstat -a ~/phd/RNASeq/sequences/${genome}.fna | grep "=" > ~/phd/RNASeq/tmp/${genera}_tmp.stats
    current_count=0
    while read stat_line;
      do
      chromosome=`echo "$stat_line" | grep $contig | wc -l | cut -d ' ' -f8`
      if (( $chromosome > 0 ));
        then
        tmpstart=$(($start + $current_count))
        tmpstop=$(($stop + $current_count))
        if (( $tmpstart < $tmpstop  )); then
          start=$tmpstart
          stop=$tmpstop
        else
          stop=$tmpstart
          start=$tmpstop
        fi
        
        if [[ ! -d ~/phd/RNASeq/genera/${genera}/${genome}.data/plot_files ]];
          then
          echo "Genome: ${genome} has no plot files"
          continue
        fi
        #echo "~/phd/RNASeq/genera/${genus}/${genome}.data/plot_files $start $stop"
        > ~/phd/RNASeq/tmp/test.plot
        counter="1"
        for plotfile in ~/phd/RNASeq/genera/${genera}/${genome}.data/plot_files/*.plot;
          do
          if [[ $plotfile == *"ncRNA"* ]]; then
            continue
          elif [[ $plotfile == *"rev"* ]]; then
            continue
          elif [[ $plotfile == *"fwd"* ]]; then
            continue            
          fi
          echo "$plotfile $genera $genome"
          sed -n "${start},${stop}{p;${stop}q;}"  $plotfile > ~/phd/RNASeq/tmp/${genera}_tmp.plot
          if [[  $counter ==  "1" ]];
          then
            cat ~/phd/RNASeq/tmp/${genera}_tmp.plot > ~/phd/RNASeq/tmp/${genera}_test.plot
            counter="2"
          else
            cat ~/phd/RNASeq/tmp/${genera}_test.plot > ~/phd/RNASeq/tmp/${genera}_tmp2.plot 
            paste ~/phd/RNASeq/tmp/${genera}_tmp2.plot ~/phd/RNASeq/tmp/${genera}_tmp.plot > ~/phd/RNASeq/tmp/${genera}_test.plot
          fi
        done
        #cp test.plot ~/phd/RNASeq/tmp
        summarise_sRNA_read_depths.R ~/phd/RNASeq/tmp/${genera}_test.plot
        cat ~/phd/RNASeq/tmp/test.values | sed -e "s/$/ $ID $genera $genome_name $genome $contig $realstart $realstop $start $stop/" >> ~/phd/RNASeq/srna_seqs/version_1/predicted/large_alignments/predicted_read_depths_summary_reads_${genera}.txt
      else
        length=`echo $stat_line | cut -d ' ' -f3`
        current_count=$(($current_count + $length))
      fi
      
    done < ~/phd/RNASeq/tmp/${genera}_tmp.stats
  done < ${accession}_new_calls.txt
  
done

#done

```

###combine_predicted_read_depths


```{bash combine_predicted_read_depths, eval=F}
##done in ~/phd/RNASeq/srna_seqs/version_1/predicted/large_alignments

cd ~/phd/RNASeq/srna_seqs/version_1/predicted/large_alignments
> predicted_read_depths_summary_new_calls.txt
cat predicted_read_depths_summary_reads_* | cut -d ' ' -f1,2,3 >> predicted_read_depths_summary_new_calls.txt


```


###srna_read_depths_new_calls_pc


```{bash srna_read_depths_new_calls_pc, eval = F}

genera="Escherichia"
echo $genera



cd ~/phd/RNASeq/genera/${genera}/

for folder in *.data;
do
  accession=`basename $folder .data`
  cd ~/phd/RNASeq/genera/${genera}/${accession}.data
  echo $accession
  
  cp gff_files/${accession}.gff ./
  
  cmscanToGffWrapper.R -f ${accession}.tblout -g ${accession}
  
  mv *.gff gff_files
  
  combine_gff_files.R -f ./gff_files/ -o ${accession}
  
done

```

###match_pc_pred_ids


```{bash match_pc_pred_ids, eval=F}
##done in ~/phd/RNASeq/genera

cd ~/phd/RNASeq/genera
cat */*/*_new_calls.txt | cut -f12- | grep "RF0" > ../new_calls/all_new_calls.txt

##done in ~/phd/RNASeq/genera
cd ~/phd/RNASeq/new_calls

while read line;
do
#echo $line


pcids=`echo $line | rev | cut -d ' ' -f2- | rev`
predid=`echo $line | rev | cut -d ' ' -f1 | rev`

echo $pcids | tr , '\n' | sed -e "s/$/   $predid/" | grep -v "=" | grep "RF" | sort | uniq >> ~/phd/RNASeq/pc_pred_ids.txt

done < ../new_calls/all_new_calls.txt

```



###summarise_sRNA_read_depths.R




```{r summarise_sRNA_read_depths.R, eval=F, include=T}
#!/usr/bin/env Rscript
library(dplyr, quietly = T, warn.conflicts = F)
dat <- read.table("~/phd/RNASeq/tmp/test.plot")

valuesDat <- dat %>%
  summarise_all(list(max)) %>% as.matrix() %>% t()

values <- valuesDat[,1]
outDat <- data.frame(mean = mean(values), max  = max(values))

write.table(x = outDat, file = "~/phd/RNASeq/tmp/test.values", row.names = F, col.names = F, quote = F)
```

#Results 


***

##summary_results 

```{bash number_of_sRNAs_predicted, eval=F}
##done in ~/phd/RNASeq/genera

cd ~/phd/RNASeq/genera

cat */*/*_new_calls.txt |  grep "_sra_calls.gff" | wc -l ##rnas
ls */*/*_new_calls.txt | wc -l ##genomes

ls | wc -l ##genera

ls */*/plot_files/*_ncRNA.plot | wc -l ##experiments


cd ~/phd/RNASeq/srna_seqs/version_1/predicted/large_alignments/alignments_rnaalifold

> ../predicted_ids.txt
ls alignments_GCA_* | sed 's/alignments_//g' |  sed 's/.stk//g' >> ../predicted_ids.txt

wc -l ../predicted_ids.txt



cd ~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/alignments_rnaalifold

> ../predicted_ids.txt
ls alignments_GCA_* | sed 's/alignments_//g' |  sed 's/.stk//g' >> ../negative_control_ids.txt

wc -l ../negative_control_ids.txt

```

```{r number_of_sRNAs_predicted_r, eval=F}
load("~/bin/r_git/R/r_files/predDat.Rda")

remaining_pred_srnas <- read.table("~/phd/RNASeq/srna_seqs/version_1/predicted/large_alignments/predicted_ids.txt", sep = "\t", fill =  T)

remaining_pred_srnas <- remaining_pred_srnas %>% dplyr::rename(ID = V1) %>% mutate(keep =T)

new_calls <- read.table("~/phd/RNASeq/genera/new_calls_simple.txt", sep = "\t", fill =  T)
new_calls <- new_calls %>% filter(V5 != "", V5 != "id")
colnames(new_calls) <- c("contig", "start", "stop", "new_feature", "ID")
newCalls <- new_calls %>% select(ID, new_feature)

predDat <- predDat %>% left_join(newCalls, by = "ID") %>% full_join(remaining_pred_srnas, by = "ID")

predDat <- predDat %>% filter(!is.na(keep))

table(predDat$new_feature)

```

##conservation_distance 


-   Analysis of the evolutionary distance of all the sequences in a given sRNA

    -   the maximum distance between sequences in an sRNA was selected 
    
    -   this is then plotted below in a cumulative proportion plot for each of PC, NC and Predicted datasets.


```{r conservation_distance, eval=T}
load("~/bin/r_git/R/r_files/max_dists_pred.Rda")
# load("~/bin/r_git/R/r_files/max_dists_pred_nr.Rda")
load("~/bin/r_git/R/r_files/max_dists_pc.Rda")
load("~/bin/r_git/R/r_files/max_dists_nc.Rda")


not_nc <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/not_negative_control_ids.txt")

not_nc <- not_nc %>% mutate(remove = T) %>% dplyr::rename(id = V1)

max_dists_nc <- max_dists_nc %>% left_join(not_nc, by = "id") %>%  filter(is.na(remove))


max_dists_pred <- max_dists_pred %>% mutate(group = "Predicted")
# max_dists_pred_nr <- max_dists_pred_nr %>% mutate(group = "Predicted NR")
max_dists_pc <- max_dists_pc %>% mutate(group = "Positive Control")
max_dists_nc <- max_dists_nc %>% mutate(group = "Negative Control")


dists <- max_dists_pred %>% bind_rows(max_dists_pc, max_dists_nc) %>% dplyr::rename(max_dist = distance) %>% filter(max_dist != 0)


distsCumulativeCount <- cumulativeCounts(dists = dists, smooth = F)

p <- ggplot() +
  geom_line(data = distsCumulativeCount, aes(x= max_dist, y = cumulative_prop, group = group, colour = group))
p
run_all <- F
if(run_all){
ggsave(filename = "~/phd/RNASeq/figures/max_conservation_distance_5.svg", plot = p)
}

```

-   The ROC curve using conservation distance as a predictor

###conservation_distance_roc_curve

```{r conservation_distance_roc_curve, eval = T}
load( file = "~/bin/r_git/R/r_files/max_dists_pred.Rda")
load(file = "~/bin/r_git/R/r_files/max_dists_pc.Rda")
load(file = "~/bin/r_git/R/r_files/max_dists_nc.Rda")

not_nc <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/not_negative_control_ids.txt")

not_nc <- not_nc %>% mutate(remove = T) %>% dplyr::rename(id = V1)

max_dists_nc <- max_dists_nc %>% left_join(not_nc, by = "id") %>%  filter(is.na(remove))

max_dists_pred <- max_dists_pred %>% mutate(group = "Predicted")
max_dists_pc <- max_dists_pc %>% mutate(group = "Positive Control")
max_dists_nc <- max_dists_nc %>% mutate(group = "Negative Control")


dists <- max_dists_pred %>% bind_rows(max_dists_pc, max_dists_nc) %>% dplyr::rename(max_dist = distance) %>% filter(max_dist > 0)

head(dists)

rocData <- dists %>% filter(group != "Predicted") %>% mutate(response = ifelse(group == "Positive Control", 1, 0))
roc.curve(response = rocData$response, predicted = rocData$max_dist,
          main="ROC curve for Maximum Phylogenetic Distance")


write_data <- T
if(write_data){
svg(filename="~/phd/RNASeq/figures/distance_roc.svg",
     width=20,
     height=20,
     pointsize=12)
roc.curve(response = rocData$response, predicted = rocData$max_dist,
          main="ROC curve for Maximum Phylogenetic Distance")


dev.off()
}

```

###distance_check


```{r distance_check, eval = F}
load( file = "~/bin/r_git/R/r_files/max_dists_pred.Rda")
load(file = "~/bin/r_git/R/r_files/max_dists_pc.Rda")
load(file = "~/bin/r_git/R/r_files/max_dists_nc.Rda")

not_nc <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/not_negative_control_ids.txt")

not_nc <- not_nc %>% mutate(remove = T) %>% dplyr::rename(id = V1)

max_dists_nc <- max_dists_nc %>% left_join(not_nc, by = "id") %>%  filter(is.na(remove))

max_dists_pred <- max_dists_pred %>% mutate(group = "Predicted")
max_dists_pc <- max_dists_pc %>% mutate(group = "Positive Control")
max_dists_nc <- max_dists_nc %>% mutate(group = "Negative Control")


dists <- max_dists_pred %>% bind_rows(max_dists_pc, max_dists_nc) %>% dplyr::rename(max_dist = distance) %>% filter(max_dist > 0)

head(dists)

rocData <- dists %>% filter(group != "Predicted") %>% mutate(response = ifelse(group == "Positive Control", 1, 0))

library(ROCR)
data(ROCR.simple)
pred <- prediction( rocData$max_dist, rocData$response)
perf <- performance(pred,"tpr","fpr")
plot(perf)
str(perf)

cutoffs <- data.frame(cut=perf@alpha.values[[1]], fpr=perf@x.values[[1]], 
                      tpr=perf@y.values[[1]])

```

-   Tree generated by taking all_taxa_names.txt (made from an earlier section) and using the commontree section of Taxonomy on ncbi and downloading the phylip tree.

-   mv ~/Downloads/phyliptree.phy all_taxa_family.tree to rename and move out of the downloads folder.

-   subset_taxa.tree made by copy/pasting a subset (of the range of taxa I already have).

-   this is converted into genera_subset.txt with: 

    -   cat subset_taxa.tree | sed 's/(//g' | sed 's/)//g' | cut -d ':' -f1 > genera_subset.txt 
    
    -   further \n\n was removed in bbedit


###predicted_data_upsetr

```{r predicted_data_upsetr_setup, eval=F, include=F}

pairs <- read.table("~/phd/RNASeq/srna_seqs/version_1/predicted/query_target_pairs.txt")
colnames(pairs) <- c("target.name", "query.genome", "ID")
contig_labels <- read.table("~/phd/RNASeq/genome_contig_pairs.txt")
colnames(contig_labels) <- c("target.name", "target.genome")
pairs <- pairs %>% left_join(contig_labels, by = 'target.name')

genus_labels <- read.table("~/phd/RNASeq/contig_genus_lables.txt")

colnames(genus_labels) <- c("target.name", "genus")

pairs <- pairs %>% left_join(genus_labels)
repDat <- pairs %>% select(ID, genus) %>% mutate(count = 1)
mat <- reshape2::acast(repDat, formula = ID ~ genus)

upsetDat <- as.data.frame(mat)

upsetDat$names <- row.names(upsetDat)
upsetDat[upsetDat != 0] <- 1

genus_selection <- read.table("~/bin/python_git/python_files/genera_list.txt")

colVals<- match(x = genus_selection$V1, table = colnames(upsetDat))

colVals <- colVals[!is.na(colVals)]

upsetSubsetPredicted <- upsetDat[,colVals]

save(upsetSubsetPredicted, file='~/bin/r_git/R/r_files/upsetSubsetPredicted.Rda')

```


```{r predicted_data_upsetr, eval=T}
load('~/bin/r_git/R/r_files/upsetSubsetPredicted.Rda')


UpSetR::upset(upsetSubsetPredicted, sets = colnames(upsetSubsetPredicted), mb.ratio = c(0.55, 0.45), order.by = "freq", keep.order = T)

write_data <- F
if(write_data){
svg(filename="~/phd/RNASeq/figures/upsetr_plot_pred_2.svg",
     width=15,
     height=10,
     pointsize=12)
UpSetR::upset(upsetSubsetPredicted, sets = colnames(upsetSubsetPredicted), mb.ratio = c(0.55, 0.45), order.by = "freq", keep.order = T)

dev.off()
}

```

###pc_data_upsetr


```{r pc_data_upsetr}

pairs <- read.table("~/phd/RNASeq/query_target_pairs_pc.txt")
colnames(pairs) <- c("target.name", "ID")
contig_labels <- read.table("~/phd/RNASeq/genome_contig_pairs.txt")
colnames(contig_labels) <- c("target.name", "target.genome")
pairs <- pairs %>% left_join(contig_labels, by = 'target.name')

genus_labels <- read.table("~/phd/RNASeq/contig_genus_lables.txt")

colnames(genus_labels) <- c("target.name", "genus")

pairs <- pairs %>% left_join(genus_labels)
repDat <- pairs %>% select(ID, genus) %>% mutate(count = 1)
mat <- reshape2::acast(repDat, formula = ID ~ genus)


upsetDat <- as.data.frame(mat)

upsetDat$names <- row.names(upsetDat)
upsetDat[upsetDat != 0] <- 1

genus_selection <- read.table("~/bin/python_git/python_files/genera_list.txt")

colVals<- match(x = genus_selection$V1, table = colnames(upsetDat))

colVals <- colVals[!is.na(colVals)]

upsetSubset <- upsetDat[,colVals]

sumsUpset <- rowSums(upsetSubset)

sumsDat <- data.frame(ID = row.names(upsetSubset), sums = sumsUpset)

UpSetR::upset(upsetSubset, sets = colnames(upsetSubset), mb.ratio = c(0.55, 0.45), order.by = "freq", nintersects = 15, keep.order = T)

write_data <- F
if(write_data){
svg(filename="~/phd/RNASeq/figures/upsetr_plot_pc_2.svg",
     width=15,
     height=10,
     pointsize=12)
UpSetR::upset(upsetSubset, sets = colnames(upsetSubset), mb.ratio = c(0.55, 0.45), order.by = "freq", nintersects = 15, keep.order = T)

dev.off()
}

```


##read_depths

***

###read_depths_setup


```{r read_depths_setup, eval=F, include=T}
ncRDepth <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/negative_control_read_depths_summary_reads.txt")
pcRDepth <- read.table("~/phd/RNASeq/srna_seqs/version_1/positive_control/large_alignments/positive_control_read_depths_summary.txt")
predRDepth <- read.table("~/phd/RNASeq/srna_seqs/version_1/predicted/large_alignments/predicted_read_depths_summary.txt")

predRDepthnewcalls <- read.table("~/phd/RNASeq/srna_seqs/version_1/predicted/large_alignments/predicted_read_depths_summary_new_calls.txt", fill = T)


predRDepthnewcalls$V2 <- as.numeric(as.character(predRDepthnewcalls$V2))
predRDepthnewcalls <- predRDepthnewcalls %>% mutate(V4 = as.numeric(as.character(V1))) %>% mutate(V4 = ifelse(V2 > V4, V4, 0.5*V2)) %>% select(V4, V2, V3)

predRDepthnewcalls <- predRDepthnewcalls %>% filter(!is.na(V2))

pcpredids <- read.table("~/phd/RNASeq/pc_pred_ids.txt", fill = T)



colnames(ncRDepth) <- c("mean.val", "max.val", "srna", "genus", "srna.genome.accession", "target.genome.accession",
                        "target.contig", "target.start", "target.end", "adj.target.start", "adj.target.end")
colnames(pcRDepth) <- c("mean.val", "max.val", "srna", "genus", "srna.genome.accession", "target.genome.accession",
                        "target.contig", "target.start", "target.end", "adj.target.start", "adj.target.end")
colnames(predRDepth) <- c("mean.val", "max.val", "srna", "srna.genome.accession", "target.genome.accession",
                        "target.contig", "target.start", "target.end", "adj.target.start", "adj.target.end")

colnames(predRDepthnewcalls) <- c("mean.val", "max.val", "srna")

colnames(pcpredids) <- c("pc.id", "srna")

predRDepth <- predRDepth %>% bind_rows(predRDepthnewcalls)

predRDepthnewcalls <- predRDepthnewcalls %>% left_join(pcpredids, by = "srna")

pcRDepthnewcallsMax <- predRDepthnewcalls %>% filter(!is.na(pc.id)) %>% group_by(pc.id) %>% summarise(max.va.newl = max(max.val))
pcRDepthnewcallsMean <- predRDepthnewcalls %>% filter(!is.na(pc.id)) %>% group_by(pc.id) %>% summarise(mean.val.new = max(mean.val))


pcRDepthnewcalls <- predRDepthnewcalls %>% filter(!is.na(pc.id)) %>% select(-srna)%>% dplyr::rename(srna = pc.id)

pcRDepthnewcalls <- pcRDepthnewcalls %>% select(mean.val, max.val, srna)

pcRDepth <- pcRDepth %>% bind_rows(pcRDepthnewcalls)

not_nc <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/not_negative_control_ids.txt")

not_nc <- not_nc %>% separate(V1, into = c("t1", "id"), extra = 'merge', sep = "_") %>% select(-t1)

ncRDepth <- ncRDepth %>% select(-genus)
pcRDepth <- pcRDepth %>% select(-genus)

save(ncRDepth, file = "~/bin/r_git/R/r_files/ncRDepth.Rda")
save(pcRDepth, file = "~/bin/r_git/R/r_files/pcRDepth.Rda")
save(predRDepth, file = "~/bin/r_git/R/r_files/predRDepth.Rda")


```

###read_depths

```{r read_depths}
load("~/bin/r_git/R/r_files/ncRDepth.Rda")
load("~/bin/r_git/R/r_files/pcRDepth.Rda")
load("~/bin/r_git/R/r_files/predRDepth.Rda")


ggplot() +
  geom_freqpoly(data = pcRDepth, aes(x = mean.val, y = log(..density..)), binwidth = 50) +
  geom_freqpoly(data = ncRDepth, aes(x = mean.val, y = log(..density..)), binwidth = 50, colour = "blue") +
  geom_freqpoly(data = predRDepth, aes(x = mean.val, y = log(..density..)), binwidth = 50, colour = "red")

pcRDepth <- pcRDepth %>% mutate(response = 1) %>% filter(max.val > 0)
ncRDepth <- ncRDepth %>% mutate(response = 0)
rocData <- pcRDepth %>% bind_rows(ncRDepth) 

rocDataMaxMax <- rocData %>% group_by(srna, response) %>% summarise(max.max.val = max(max.val))
rocDataMeanSum <- rocData %>% group_by(srna, response) %>% summarise(max.max.val = sum(mean.val))
rocDataMaxSum <- rocData %>% group_by(srna, response) %>% summarise(max.max.val = sum(max.val))



roc.curve(response = rocDataMaxSum$response, predicted = rocDataMaxSum$max.max.val, 
          main="ROC curve for Read Depths")



pcRDepth <- pcRDepth %>% mutate(group = "Positive Control") %>% filter(max.val > 0)
predRDepth <- predRDepth %>% mutate(group = "Predicted") 
ncRDepth <- ncRDepth %>% mutate(group = "Negative Control")

dists <- pcRDepth %>% bind_rows(ncRDepth, predRDepth) %>% group_by(srna, group) %>% summarise(max_dist = max(max.val))#%>% dplyr::rename(max_dist = distance) %>% filter(max_dist != 0)


distsCumulativeCount <- cumulativeCounts(dists = dists, smooth = F)

distsCumulativeCount <- distsCumulativeCount %>% dplyr::rename(max_read_counts = max_dist)

p <- ggplot() +
  geom_line(data = distsCumulativeCount, aes(x= max_read_counts, y = cumulative_prop, group = group, colour = group))
p


write_data <- F
if(write_data){
  
  ggsave(filename = "~/phd/RNASeq/figures/max_read_depths.svg", plot = p)

  
svg(filename="~/phd/RNASeq/figures/reads_max.svg",
     width=20,
     height=20,
     pointsize=12)
roc.curve(response = rocDataMaxSum$response, predicted = rocDataMaxSum$max.max.val, 
          main="ROC curve for Read Depths")

dev.off()

svg(filename="~/phd/RNASeq/figures/reads_mean.svg",
     width=20,
     height=20,
     pointsize=12)
roc.curve(response = rocDataMeanSum$response, predicted = rocDataMeanSum$max.max.val, 
          main="ROC curve for Read Depths")

dev.off()

}
```

###read_depths_check


```{r read_depths_check, eval=F}
load("~/bin/r_git/R/r_files/ncRDepth.Rda")
load("~/bin/r_git/R/r_files/pcRDepth.Rda")
load("~/bin/r_git/R/r_files/predRDepth.Rda")

pcRDepth <- pcRDepth %>% mutate(response = 1) %>% filter(max.val > 0)
ncRDepth <- ncRDepth %>% mutate(response = 0)
rocData <- pcRDepth %>% bind_rows(ncRDepth) 

rocData <- rocData %>% group_by(srna, response) %>% summarise(max.max.val = sum(max.val))

pred <- prediction( rocData$max.max.val, rocData$response)
perf <- performance(pred,"tpr","fpr")
plot(perf)
str(perf)

cutoffs <- data.frame(cut=perf@alpha.values[[1]], fpr=perf@x.values[[1]], 
                      tpr=perf@y.values[[1]])

```

##Covariation

-   The files need the ID column to be separated out so these lines need running.

    -   cat predicted.rscape.cov | sed 's/GC/\tGC/g' > tmp.cov

    -   cat negative_control.rscape.cov | sed 's/GC/\tGC/g' > tmp.cov

    -   cat positive_control.rscape.cov | sed 's/RF/\tRF/g' > tmp.cov


###rscape_setup

```{r rscape_setup, eval = F, include=T}
pcCov <- read.table("~/phd/RNASeq/srna_seqs/version_1/positive_control/large_alignments/tmp.cov", sep = "\t", comment.char = "#", as.is = T, header = F, fill = T, col.names = c("V1", "left_pos", "right_pos", "score", "e.value", "substitutions", "V2", "power", "ID"))
ncCov <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/tmp.cov", sep = "\t", comment.char = "#", as.is = T, header = F, fill = T, col.names = c("V1", "left_pos", "right_pos", "score", "e.value", "substitutions", "V2", "power", "ID"))

predCov <- read.table("~/phd/RNASeq/srna_seqs/version_1/predicted/large_alignments/tmp.cov", sep = "\t", comment.char = "#", as.is = T, header = F, fill = T, col.names = c("V1", "left_pos", "right_pos", "score", "e.value", "substitutions", "V2", "power", "ID"))

#colnames(pcCov) <- c("V1", "left_pos", "right_pos", "score", "e.value", "substitutions", "power")
#colnames(ncCov) <- c("V1", "left_pos", "right_pos", "score", "e.value", "substitutions", "power")

pcCov <- pcCov %>% mutate(ID = ifelse(V1 == "no significant pairs", left_pos, ID))


pcCov$score[pcCov$V1 == "no significant pairs"] <- 0
pcCov$e.value[pcCov$V1 == "no significant pairs"] <- 10
pcCov$power[pcCov$V1 == "no significant pairs"] <- 0
pcCov$substitutions[pcCov$V1 == "no significant pairs"] <- 0

pcCov$left_pos[pcCov$V1 == "no significant pairs"] <- "-"
pcCov$right_pos[pcCov$V1 == "no significant pairs"] <- "-"
pcCov$V1[pcCov$V1 == "no significant pairs"] <- "-"

ncCov <- ncCov %>% mutate(ID = ifelse(V1 == "no significant pairs", left_pos, ID))

ncCov$score[ncCov$V1 == "no significant pairs"] <- 0
ncCov$e.value[ncCov$V1 == "no significant pairs"] <- 10
ncCov$power[ncCov$V1 == "no significant pairs"] <- 0
ncCov$substitutions[ncCov$V1 == "no significant pairs"] <- 0

ncCov$left_pos[ncCov$V1 == "no significant pairs"] <- "-"
ncCov$right_pos[ncCov$V1 == "no significant pairs"] <- "-"
ncCov$V1[ncCov$V1 == "no significant pairs"] <- "-"

predCov <- predCov %>% mutate(ID = ifelse(V1 == "no significant pairs", left_pos, ID))


predCov$score[predCov$V1 == "no significant pairs"] <- 0
predCov$e.value[predCov$V1 == "no significant pairs"] <- 10
predCov$power[predCov$V1 == "no significant pairs"] <- 0
predCov$substitutions[predCov$V1 == "no significant pairs"] <- 0

predCov$left_pos[predCov$V1 == "no significant pairs"] <- "-"
predCov$right_pos[predCov$V1 == "no significant pairs"] <- "-"
predCov$V1[predCov$V1 == "no significant pairs"] <- "-"


load("~/bin/r_git/R/r_files/ncRNAcode.Rda")
load("~/bin/r_git/R/r_files/pcRNAcode.Rda")
load("~/bin/r_git/R/r_files/predRNAcode.Rda")

ncRNAcode <- ncRNAcode %>% separate(col = srna, into = c("t1", "t2", "t3"), sep = "_", remove = F, extra = 'merge') %>% mutate(ID = paste(t2, t3, sep = "_")) %>% select(-t1, -t2, -t3) %>%  group_by(ID) %>% mutate(counter = row_number()) %>% filter(counter == 1) %>% select(-counter) %>% ungroup()

pcRNAcode <- pcRNAcode %>% mutate(ID = srna) %>%  group_by(ID) %>% mutate(counter = row_number()) %>% filter(counter == 1) %>% select(-counter) %>% ungroup()
pcCov <- pcCov %>% separate(col = ID, into = c("t1"), sep = "_", remove = F, extra = 'drop') %>% mutate(ID = t1) %>% select(-t1)


predRNAcode <- predRNAcode %>% mutate(ID = srna) %>%  group_by(ID) %>% mutate(counter = row_number()) %>% filter(counter == 1) %>% select(-counter) %>% ungroup()

ncCov <- ncCov %>% left_join(ncRNAcode, by = "ID") 
pcCov <- pcCov %>% left_join(pcRNAcode, by = "ID") 
predCov <- predCov %>% left_join(predRNAcode, by = "ID") 

ncCovRNA <- ncCov %>% filter(is.na(p.value))
ncCovProtein <- ncCov %>% filter(!is.na(p.value))

predCovRNA <- predCov %>% filter(is.na(p.value))
predCovProtein <- predCov %>% filter(!is.na(p.value))

pcCovRNA <- pcCov %>% filter(is.na(p.value))
pcCovProtein <- pcCov %>% filter(!is.na(p.value))

pcIDLen <- length(unique(pcCov$ID))
predIDLen <- length(unique(predCov$ID))
ncIDLen <- length(unique(ncCov$ID))

pcCovMean <- pcCov %>% group_by(ID) %>% summarise(mean_score = mean(score.x))
pcCovCount <- pcCov %>% group_by(ID) %>% summarise(count = n())
pcCovMax <- pcCov %>% group_by(ID) %>% summarise(min_eval = min(e.value))
pcCov <- pcCovMean %>% full_join(pcCovMax, by = "ID") %>% 
  full_join(pcCovCount, by = "ID")

ncCovMean <- ncCovRNA %>% group_by(ID) %>% summarise(mean_score = mean(score.x))
ncCovCount <- ncCovRNA %>% group_by(ID) %>% summarise(count = n())
ncCovMax <- ncCovRNA %>% group_by(ID) %>% summarise(min_eval = min(e.value))
ncCovRNA <- ncCovMean %>% full_join(ncCovMax, by = "ID") %>% 
  full_join(ncCovCount, by = "ID") %>% filter(!is.na(mean_score))

predCovMean <- predCovRNA %>% group_by(ID) %>% summarise(mean_score = mean(score.x))
predCovCount <- predCovRNA %>% group_by(ID) %>% summarise(count = n())
predCovMax <- predCovRNA %>% group_by(ID) %>% summarise(min_eval = min(e.value))
predCovRNA <- predCovMean %>% full_join(predCovMax, by = "ID") %>% 
  full_join(predCovCount, by = "ID")


nc_ids <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/negative_control_alignment_ids.txt")
colnames(nc_ids) <- "ID"

ncCovRNA <- ncCovRNA %>% full_join(nc_ids, by = "ID")
ncCovRNA$mean_score[is.na(ncCovRNA$mean_score)] <- 0
ncCovRNA$min_eval[is.na(ncCovRNA$min_eval)] <- 10
ncCovRNA$count[is.na(ncCovRNA$count)] <- 1

# pc_ids <- read.table("~/phd/RNASeq/srna_seqs/version_1/positive_control/large_alignments/positive_control_alignment_ids.txt")
# colnames(pc_ids) <- "ID"
# 
# pcCov <- pcCov %>% full_join(pc_ids, by = "ID")
# pcCov$mean_score[is.na(pcCov$mean_score)] <- 0
# pcCov$min_eval[is.na(pcCov$min_eval)] <- 10
# pcCov$count[is.na(pcCov$count)] <- 0

save(pcCov, file = "~/bin/r_git/R/r_files/pcCovariation.Rda")
save(ncCovRNA, file = "~/bin/r_git/R/r_files/ncCovariation.Rda")
save(predCovRNA, file = "~/bin/r_git/R/r_files/predCovariation.Rda")


```

###rscape_check

```{r rscape_check, eval=F, include=T}
load("~/bin/r_git/R/r_files/pcCovariation.Rda")
load("~/bin/r_git/R/r_files/ncCovariation.Rda")


pcCov <- pcCov %>% mutate(response = 1) #%>% filter(mean_score > 0)
ncCovRNA <- ncCovRNA %>% mutate(response = 0) #%>% filter(mean_score > 0)
rocData <- pcCov %>% bind_rows(ncCovRNA) %>% mutate(combined_score = count * mean_score) %>% filter(!is.na(combined_score)) 


pred <- prediction( (rocData$mean_score * rocData$count), rocData$response)
perf <- performance(pred,"tpr","fpr")

dat <- data.frame(fpr = perf@x.values[[1]], tpr = perf@y.values[[1]], cutoff = perf@alpha.values[[1]])

plot(perf)

cutoffs <- data.frame(cut=perf@alpha.values[[1]], fpr=perf@x.values[[1]], 
                      tpr=perf@y.values[[1]])

```

###rscape

```{r rscape, eval = T}
load("~/bin/r_git/R/r_files/pcCovariation.Rda")
load("~/bin/r_git/R/r_files/ncCovariation.Rda")
load("~/bin/r_git/R/r_files/predCovariation.Rda")

ggplot() +
  geom_freqpoly(data = pcCov, aes(x = mean_score, y = log(..density..)), binwidth = 100) +
  geom_freqpoly(data = ncCovRNA, aes(x = mean_score, y = log(..density..)), binwidth = 100, colour = "blue") +
  geom_freqpoly(data = predCovRNA, aes(x = mean_score, y = log(..density..)), binwidth = 100, colour = "red")

pcCov <- pcCov %>% mutate(response = 1) 
ncCovRNA <- ncCovRNA %>% mutate(response = 0)
rocData <- pcCov %>% bind_rows(ncCovRNA) %>% mutate(combined_score = count * mean_score) %>% filter(!is.na(combined_score))  #%>%  filter(mean_score > 0)
roc.curve(response = rocData$response, predicted = rocData$min_eval, 
          main="ROC curve for Covariation Scores")
roc.curve(response = rocData$response, predicted = rocData$mean_score, 
          main="ROC curve for Covariation Scores", add.roc = F)
roc.curve(response = rocData$response, predicted = rocData$count, 
          main="ROC curve for Covariation Scores", add.roc = F)
roc.curve(response = rocData$response, predicted = rocData$combined_score, 
          main="ROC curve for Covariation Scores", add.roc = F)

pcCov <- pcCov %>% mutate(group = "Positive Control")
predCovRNA <- predCovRNA %>% mutate(group = "Predicted") 
ncCovRNA <- ncCovRNA %>% mutate(group = "Negative Control")

dists <- pcCov %>% bind_rows(predCovRNA, ncCovRNA) %>% dplyr::rename(max_dist = mean_score) %>% select(ID, max_dist, group) 


distsCumulativeCount <- cumulativeCounts(dists = dists, smooth = F)

distsCumulativeCount <- distsCumulativeCount %>% dplyr::rename(rscape_cov_mean_score = max_dist)

p <- ggplot() +
  geom_line(data = distsCumulativeCount, aes(x= rscape_cov_mean_score, y = cumulative_prop, group = group, colour = group)) + 
  xlim(min = 0, max = 1500)
  
p

dists <- pcCov %>% bind_rows(predCovRNA, ncCovRNA) %>% dplyr::rename(max_dist = min_eval) %>% select(ID, max_dist, group) 


distsCumulativeCount <- cumulativeCounts(dists = dists, smooth = F)

distsCumulativeCount <- distsCumulativeCount %>% dplyr::rename(rscape_cov_min_eval = max_dist)

p <- ggplot() +
  geom_line(data = distsCumulativeCount, aes(x= rscape_cov_min_eval, y = cumulative_prop, group = group, colour = group)) + 
  xlim(min = 0, max = 0.05)
  
p


dists <- pcCov %>% bind_rows(predCovRNA, ncCovRNA) %>% dplyr::rename(max_dist = count) %>% select(ID, max_dist, group) 


distsCumulativeCount <- cumulativeCounts(dists = dists, smooth = F)

distsCumulativeCount <- distsCumulativeCount %>% dplyr::rename(rscape_cov_count = max_dist)

p <- ggplot() +
  geom_line(data = distsCumulativeCount, aes(x= rscape_cov_count, y = cumulative_prop, group = group, colour = group)) + 
  xlim(min = 0, max = 150)
  
p


write_data <- F
if(write_data){
  
    ggsave(filename = "~/phd/RNASeq/figures/covariation_rscape.svg", plot = p)

  
svg(filename="~/phd/RNASeq/figures/cov_combined.svg",
     width=20,
     height=20,
     pointsize=12)
roc.curve(response = rocData$response, predicted = rocData$combined_score, 
          main="ROC curve for Covariation combined", add.roc = F)


dev.off()



svg(filename="~/phd/RNASeq/figures/cov_count.svg",
     width=20,
     height=20,
     pointsize=12)
roc.curve(response = rocData$response, predicted = rocData$count, 
          main="ROC curve for Covariation count", add.roc = F)


dev.off()

svg(filename="~/phd/RNASeq/figures/cov_mean.svg",
     width=20,
     height=20,
     pointsize=12)
roc.curve(response = rocData$response, predicted = rocData$mean_score, 
          main="ROC curve for Covariation mean", add.roc = F)


dev.off()


svg(filename="~/phd/RNASeq/figures/cov_min_eval.svg",
     width=20,
     height=20,
     pointsize=12)
roc.curve(response = rocData$response, predicted = rocData$min_eval, 
          main="ROC curve for Covariation min eval", add.roc = F)


dev.off()
}

```

   made using sRNAGCPercentage.py

    - input is the fasta file


###alifold_cov

```{r alifold_cov, eval = T, include=T}
pcCovAli <- read.table("~/phd/RNASeq/srna_seqs/version_1/positive_control/large_alignments/positive_control_alifold_covariation.txt", sep = "", comment.char = "#", as.is = T, header = F, fill = T, col.names = c("ID", "alifold_cov_score"))
ncCovAli <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/negative_control_alifold_covariation.txt", sep = "", comment.char = "#", as.is = T, header = F, fill = T, col.names = c("ID", "alifold_cov_score"))
predCovAli <- read.table("~/phd/RNASeq/srna_seqs/version_1/predicted/large_alignments/predicted_alifold_covariation.txt", sep = "", comment.char = "#", as.is = T, header = F, fill = T, col.names = c("ID", "alifold_cov_score"))




save(pcCovAli, file = "~/bin/r_git/R/r_files/pcCovAli.Rda")
save(ncCovAli, file = "~/bin/r_git/R/r_files/ncCovAli.Rda")
save(predCovAli, file = "~/bin/r_git/R/r_files/predCovAli.Rda")



load("~/bin/r_git/R/r_files/pcCovAli.Rda")
load("~/bin/r_git/R/r_files/ncCovAli.Rda")
load("~/bin/r_git/R/r_files/predCovAli.Rda")


pcCovRoc <- pcCovAli %>% mutate(response = 1) 
ncCovRoc <- ncCovAli %>% mutate(response = 0)
rocData <- pcCovRoc %>% bind_rows(ncCovRoc) %>% filter(!is.na(alifold_cov_score))
roc.curve(response = rocData$response, predicted = rocData$alifold_cov_score, 
          main="ROC curve for Alifold Covariation Scores")

pcCovAli <- pcCovAli %>% mutate(group = "Positive Control")
predCovAli <- predCovAli %>% mutate(group = "Predicted") 
ncCovAli <- ncCovAli %>% mutate(group = "Negative Control")

dists <- pcCovAli %>% bind_rows(predCovAli, ncCovAli) %>% dplyr::rename(max_dist = alifold_cov_score) 


distsCumulativeCount <- cumulativeCounts(dists = dists, smooth = F)

distsCumulativeCount <- distsCumulativeCount %>% dplyr::rename(alifold_cov_score = max_dist)

p <- ggplot() +
  geom_line(data = distsCumulativeCount, aes(x= alifold_cov_score, y = cumulative_prop, group = group, colour = group))
p


write_data <- F
if(write_data){
  
  ggsave(filename = "~/phd/RNASeq/figures/covariation_alifold.svg", plot = p)
}


```



##GC Content {#gc_content_results}

```{r gc_content, eval = T}
pcGC <- read.table("~/phd/RNASeq/srna_seqs/version_1/positive_control/large_alignments/pc_rf.gc", sep = "\t", comment.char = "#", as.is = T, header = F, fill = T)
ncGC <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control_no_shuffle.gc", sep = "\t", comment.char = "#", as.is = T, header = F, fill = T)
predGC <- read.table("~/phd/RNASeq/srna_seqs/version_1/predicted.gc", sep = "\t", comment.char = "#", as.is = T, header = F, fill = T)

pcGC <- pcGC %>% separate(col = V1, into = "ID", extra = "drop", sep = "\\[")
ncGC <- ncGC %>% separate(col = V1, into = "ID", extra = "drop", sep = "\\[")

pcGC <- pcGC %>% mutate(response = 1)
ncGC <- ncGC %>% mutate(response = 0)

rocData <- pcGC %>% bind_rows(ncGC)

roc.curve(response = rocData$response, predicted = rocData$V2,
          main="ROC curve for GC%")
write_data <- T
if(write_data){
svg(filename="~/phd/RNASeq/figures/gc.svg",
     width=20,
     height=20,
     pointsize=12)
roc.curve(response = rocData$response, predicted = rocData$V2,
          main="ROC curve for GC%")

dev.off()
}


save(pcGC, file= "~/bin/r_git/R/r_files/pcGC.Rda")
save(ncGC, file= "~/bin/r_git/R/r_files/ncGC.Rda")
save(predGC, file= "~/bin/r_git/R/r_files/predGC.Rda")

```

##Secondary Structure {#secondary_structure_results}

###alifold_setup

-  Need to run

    - cd ~/phd/RNASeq/srna_seqs/version_1/positive_control/large_alignments

    - grep "-" positive_control.alifold > positive_control_fixed.alifold
    
- It appears fine for the other groups 

```{r alifold_setup, eval = F}
pcAlifold<- read.table("~/phd/RNASeq/srna_seqs/version_1/positive_control/large_alignments/positive_control_fixed.alifold", header = F, comment.char = "#", quote = "", sep = "", fill = T, as.is = T, col.names = c( "From",      "To",    "Strand",    "Native.MFE",    "Mean.MFE",     "STDV",      "Z", "ID"))
ncAlifold<- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/negative_control.alifold", header = F, comment.char = "#", quote = "", sep = "", fill = T, as.is = T)

predAlifold<- read.table("~/phd/RNASeq/srna_seqs/version_1/predicted/large_alignments/predicted.alifold", header = F, comment.char = "#", quote = "", sep = "", fill = T, as.is = T)

colnames(pcAlifold) <- c( "From",      "To",    "Strand",    "Native.MFE",    "Mean.MFE",     "STDV",      "Z", "ID")
colnames(ncAlifold) <- c( "From",      "To",    "Strand",    "Native.MFE",    "Mean.MFE",     "STDV",      "Z", "ID")
colnames(predAlifold) <- c( "From",      "To",    "Strand",    "Native.MFE",    "Mean.MFE",     "STDV",      "Z", "ID")

ncAlifold <- ncAlifold %>% filter(grepl(pattern = "GCA_", ID), STDV > 0) 
pcAlifold <- pcAlifold %>% filter(grepl(pattern = "RF", ID))
predAlifold <- predAlifold %>% filter(grepl(pattern = "GCA_", ID)) 


pcAlifoldsd <- pcAlifold %>% select(ID, STDV)
predAlifoldsd <- predAlifold %>% select(ID, STDV)

pcAlifoldMean <- pcAlifold %>% group_by(ID) %>% summarise(z_mean = mean(as.numeric(Z), na.rm = T))
pcAlifoldMax <- pcAlifold %>% group_by(ID) %>% summarise(z_max = max(as.numeric(Z), na.rm = T))

ncAlifoldMean <- ncAlifold %>% group_by(ID) %>% summarise(z_mean = mean(as.numeric(Z), na.rm = T))
ncAlifoldMax <- ncAlifold %>% group_by(ID) %>% summarise(z_max = max(as.numeric(Z), na.rm = T))

predAlifoldMean <- predAlifold %>% group_by(ID) %>% summarise(z_mean = mean(as.numeric(Z), na.rm = T))
predAlifoldMax <- predAlifold %>% group_by(ID) %>% summarise(z_max = max(as.numeric(Z), na.rm = T))

pcAlifold <- pcAlifoldMean %>% full_join(pcAlifoldMax, by = "ID") %>% full_join(pcAlifoldsd, by = "ID")
ncAlifold <- ncAlifoldMean %>% full_join(ncAlifoldMax, by = "ID")
predAlifold <- predAlifoldMean %>% full_join(predAlifoldMax, by = "ID") %>% full_join(predAlifoldsd, by = "ID")


save(pcAlifold, file = "~/bin/r_git/R/r_files/pcAlifold.Rda")
save(ncAlifold, file = "~/bin/r_git/R/r_files/ncAlifold.Rda")
save(predAlifold, file = "~/bin/r_git/R/r_files/predAlifold.Rda")
```

###alifold_check

-   The original ROC plot was showing a flat spot near the start. 

    -   The code below was used to check what this was. 
    -   When the standard deviation is zero then Z scores are meaningless and need removing.
    -   This was added to the above code and fixed the problem.

```{r alifold_check, eval=F}
load("~/bin/r_git/R/r_files/pcAlifold.Rda")
load("~/bin/r_git/R/r_files/ncAlifold.Rda")
pcAlifold <- pcAlifold %>% mutate(response = 1)
ncAlifold <- ncAlifold %>% mutate(response = 0)

rocData <- pcAlifold %>% bind_rows(ncAlifold)
rocData <- rocData[!is.na(rocData$z_mean),] 
rocData <- rocData[!is.na(rocData$z_max),] 

pred <- prediction( rocData$z_mean, rocData$response)
perf <- performance(pred,"tpr","fpr")
plot(perf)
str(perf)

cutoffs <- data.frame(cut=perf@alpha.values[[1]], fpr=perf@x.values[[1]], 
                      tpr=perf@y.values[[1]])

tmp <- rocData %>% filter(z_mean > -0.35, z_mean < 0.06)

```


###alifold_results

```{r alifold, eval = T}
load("~/bin/r_git/R/r_files/pcAlifold.Rda")
load("~/bin/r_git/R/r_files/ncAlifold.Rda")
load("~/bin/r_git/R/r_files/predAlifold.Rda")

pcAlifold <- pcAlifold %>% mutate(response = 1) %>% filter(STDV > 0)
ncAlifold <- ncAlifold %>% mutate(response = 0)



rocData <- pcAlifold %>% bind_rows(ncAlifold)
rocData <- rocData[!is.na(rocData$z_mean),] 
rocData <- rocData[!is.na(rocData$z_max),] 


ggplot() +
  geom_freqpoly(data = rocData, aes(x = z_mean, y = ..count.., group = as.character(response), color = as.character(response)), binwidth = 1)

roc.curve(response = rocData$response, predicted = rocData$z_mean,
          main="ROC curve for Z-score Alifoldz")


write_data <- T
if(write_data){
svg(filename="~/phd/RNASeq/figures/alifold_mean.svg",
     width=20,
     height=20,
     pointsize=12)
roc.curve(response = rocData$response, predicted = rocData$z_mean,
          main="ROC curve for Z-score Alifoldz mean")

dev.off()

svg(filename="~/phd/RNASeq/figures/alifold_max.svg",
     width=20,
     height=20,
     pointsize=12)
roc.curve(response = rocData$response, predicted = rocData$z_max,
          main="ROC curve for Z-score Alifoldz max")

dev.off()
}


rocData %>% group_by(response) %>% summarise(count = n())
rocData %>% group_by(response) %>% filter(z_mean <= -1) %>% summarise(count = n())

load("~/bin/r_git/R/r_files/pcAlifold.Rda")
load("~/bin/r_git/R/r_files/ncAlifold.Rda")
load("~/bin/r_git/R/r_files/predAlifold.Rda")


pcAlifold <- pcAlifold %>% mutate(group = "Positive Control")%>% filter(STDV > 0)
predAlifold <- predAlifold %>% mutate(group = "Predicted") %>% filter(STDV > 0)
ncAlifold <- ncAlifold %>% mutate(group = "Negative Control")

dists <- pcAlifold %>% bind_rows(predAlifold, ncAlifold) %>% dplyr::rename(max_dist = z_max) 


distsCumulativeCount <- cumulativeCounts(dists = dists, smooth = F)

distsCumulativeCount <- distsCumulativeCount %>% dplyr::rename(alifold_z_score = max_dist)

p <- ggplot() +
  geom_line(data = distsCumulativeCount, aes(x= alifold_z_score, y = cumulative_prop, group = group, colour = group))
p


write_data <- F
if(write_data){
  
  ggsave(filename = "~/phd/RNASeq/figures/z_score_alifold.svg", plot = p)
}




```

###MFE

```{r MFE, eval = T, echo=T}
pcMFE <- read.table("~/phd/RNASeq/srna_seqs/version_1/positive_control/large_alignments/positive_control.rnaalifold", sep = "", comment.char = "#", as.is = T, header = F, fill = T)
ncMFE <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/negative_control.rnaalifold", sep = "", comment.char = "#", as.is = T, header = F, fill = T)
predMFE <- read.table("~/phd/RNASeq/srna_seqs/version_1/predicted/large_alignments/predicted.rnaalifold", sep = "", comment.char = "#", as.is = T, header = F, fill = T)

pcMFE <- pcMFE %>% filter(V1 != "From", grepl(pattern = "-", x = V1) ==F, V1 != "ERROR")
ncMFE <- ncMFE %>% filter(V1 != "From", grepl(pattern = "-", x = V1) ==F, V1 != "ERROR")
predMFE <- predMFE %>% filter(V1 != "From", grepl(pattern = "-", x = V1) ==F, V1 != "ERROR")

pcMFE <- pcMFE %>% mutate(group = "Positive Control")
ncMFE <- ncMFE %>% mutate(group = "Negative Control")
predMFE <- predMFE %>% mutate(group = "Predicted")

mfe <- pcMFE %>% bind_rows(ncMFE, predMFE)

ggplot(data = mfe) +
  geom_freqpoly(aes(x = V2, y = ..density.., group = group, colour = group), binwidth = 2)

pcMFE <- pcMFE %>% mutate(response = 1) %>%  filter(!is.na(V2))
ncMFE <- ncMFE %>% mutate(response = 0) %>%  filter(!is.na(V2))

rocData <- pcMFE %>% bind_rows(ncMFE) 

roc.curve(response = rocData$response, predicted = rocData$V2,
          main="ROC curve for MFE")



write_data <- T
if(write_data){
svg(filename="~/phd/RNASeq/figures/mfe.svg",
     width=20,
     height=20,
     pointsize=12)
roc.curve(response = rocData$response, predicted = rocData$V2,
          main="ROC curve for MFE")

dev.off()

}


save(pcMFE, file= "~/bin/r_git/R/r_files/pcMFE.Rda")
save(ncMFE, file= "~/bin/r_git/R/r_files/ncMFE.Rda")
save(predMFE, file= "~/bin/r_git/R/r_files/predMFE.Rda")



```



##ncRNA motifs {#ncrna_motifs}


```{r motifs, eval = T}

load("~/bin/r_git/R/r_files/pcMotif.Rda")
load("~/bin/r_git/R/r_files/ncMotif.Rda")
load("~/bin/r_git/R/r_files/predMotif.Rda")

ncMotif <- ncMotif %>% mutate(response = 0)
pcMotif <- pcMotif %>% mutate(response = 1)

rocData <- pcMotif %>% bind_rows(ncMotif)

roc.curve(response = rocData$response, predicted = rocData$max_score,
          main="ROC curve for motifs")

write_data <- F
if(write_data){
svg(filename="~/phd/RNASeq/figures/motifs_max.svg",
     width=20,
     height=20,
     pointsize=12)
roc.curve(response = rocData$response, predicted = rocData$max_score,
          main="ROC curve for motifs max")

dev.off()

svg(filename="~/phd/RNASeq/figures/motifs_mean.svg",
     width=20,
     height=20,
     pointsize=12)
roc.curve(response = rocData$response, predicted = rocData$mean_score,
          main="ROC curve for motifs mean")

dev.off()

}


```

###motifs_setup

Go to:

-   [*Top*](#top)

-   [*Results*](#section-results)

***


```{r motifs_setup, eval=F}
pcMotif <- read.table("~/phd/RNASeq/srna_seqs/version_1/positive_control/large_alignments/positive_control.rmfam", sep = "", comment.char = "#", as.is = T, header = F, fill = T)
ncMotif <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/negative_control.rmfam", sep = "", comment.char = "#", as.is = T, header = F, fill = T)

predMotif <- read.table("~/phd/RNASeq/srna_seqs/version_1/predicted/predicted.rmfam", sep = "", comment.char = "#", as.is = T, header = F, fill = T)

colnames(pcMotif) <- c("seqname", "source", "feature", "start", "end", "score", "strand", "frame", "attribute", "ID")
colnames(ncMotif) <- c("seqname", "source", "feature", "start", "end", "score", "strand", "frame", "attribute", "ID")
colnames(predMotif) <- c("seqname", "source", "feature", "start", "end", "score", "strand", "frame", "attribute", "ID")

pcMotifMean <- pcMotif %>% group_by(ID) %>% summarise(mean_score = mean(score))
pcMotifMax <- pcMotif %>% group_by(ID) %>% summarise(max_score = max(score))

pcMotif <- pcMotifMean %>% full_join(pcMotifMax, by = "ID")


ncMotifMean <- ncMotif %>% group_by(ID) %>% summarise(mean_score = mean(score))
ncMotifMax <- ncMotif %>% group_by(ID) %>% summarise(max_score = max(score))
ncMotif <- ncMotifMean %>% full_join(ncMotifMax, by = "ID")

predMotifMean <- predMotif %>% group_by(ID) %>% summarise(mean_score = mean(score))
predMotiffMax <- predMotif %>% group_by(ID) %>% summarise(max_score = max(score))

predMotif <- predMotifMean %>% full_join(predMotiffMax, by = "ID")


save(pcMotif, file = "~/bin/r_git/R/r_files/pcMotif.Rda")
save(ncMotif, file = "~/bin/r_git/R/r_files/ncMotif.Rda")
save(predMotif, file = "~/bin/r_git/R/r_files/predMotif.Rda")

```

##RandomForest

***

###random_forest_data_setup

```{r random_forest_data_setup, eval=F}
load("~/bin/r_git/R/r_files/max_dists_pc.Rda")
load("~/bin/r_git/R/r_files/max_dists_nc.Rda")

max_dists_pc <- max_dists_pc %>% dplyr::rename(ID = id) %>% select(ID, distance)
max_dists_nc <- max_dists_nc  %>% separate(col = id, into = c("t1", "ID"), sep = "_", extra = "merge")  %>% select(-t1)  %>% select(ID, distance)


load("~/bin/r_git/R/r_files/ncRDepth.Rda")
load("~/bin/r_git/R/r_files/pcRDepth.Rda")

pcRDepthMaxs <- pcRDepth %>% dplyr::rename(ID = srna) %>% group_by(ID) %>% summarise(read.max.score  = sum(max.val))
pcRDepthMeans <- pcRDepth %>% dplyr::rename(ID = srna) %>% group_by(ID) %>% summarise(reads.mean.score  = sum(mean.val))
pcRDepth <- pcRDepthMaxs %>% full_join(pcRDepthMeans, by = "ID")

ncRDepthMaxs <- ncRDepth %>% dplyr::rename(ID = srna) %>% group_by(ID) %>% summarise(read.max.score  = sum(max.val))
ncRDepthMeans <- ncRDepth %>% dplyr::rename(ID = srna) %>% group_by(ID) %>% summarise(reads.mean.score  = sum(mean.val))
ncRDepth <- ncRDepthMaxs %>% full_join(ncRDepthMeans, by = "ID")


load("~/bin/r_git/R/r_files/pcCovariation.Rda") ##pcCov
load("~/bin/r_git/R/r_files/ncCovariation.Rda") ##ncCovRNA

ncCovRNA <- ncCovRNA %>% filter(!is.na(mean_score)) %>% mutate(combined_score = count * mean_score) %>% 
  dplyr::rename(cov.mean.score = mean_score, cov.min.eval = min_eval, cov.count = count, cov.combined.score = combined_score)
pcCov <- pcCov %>% filter(!is.na(mean_score)) %>% mutate(combined_score = count * mean_score) %>% 
  dplyr::rename(cov.mean.score = mean_score, cov.min.eval = min_eval, cov.count = count, cov.combined.score = combined_score)



load("~/bin/r_git/R/r_files/pcGC.Rda")
load("~/bin/r_git/R/r_files/ncGC.Rda")

pcGC <- pcGC %>% dplyr::rename(gc.score = V2) %>% select(ID, gc.score)
ncGC <- ncGC %>% group_by(ID) %>% summarise(gc.score = mean(V2)) 

load("~/bin/r_git/R/r_files/pcAlifold.Rda")
load("~/bin/r_git/R/r_files/ncAlifold.Rda")

pcAlifold <- pcAlifold %>% separate(col = ID, into = c("t1", "t2"), sep = "_") %>% separate(t2, into = "ID", sep = "\\.", extra = "drop") %>% select(-t1, -STDV) 

ncAlifold <- ncAlifold %>% separate(col = ID, into = c("t1", "id"), sep = "_", extra = "merge")  %>% select(-t1) %>% dplyr::rename(ID = id)


load("~/bin/r_git/R/r_files/pcMFE.Rda")
load("~/bin/r_git/R/r_files/ncMFE.Rda")

pcMFE <- pcMFE %>% dplyr::rename(ID = V1, mfe.score = V2) %>% select(ID, mfe.score)

ncMFE <- ncMFE %>% separate(col = V1, into = c("t1", "ID"), sep = "_", extra = "merge")  %>% select(-t1) %>% dplyr::rename(mfe.score = V2) %>% select(ID, mfe.score)



load("~/bin/r_git/R/r_files/pcMotif.Rda")
load("~/bin/r_git/R/r_files/ncMotif.Rda")

pcMotif <- pcMotif %>% separate(col = ID, into = c("t1", "t2"), sep = "_") %>% separate(t2, into = "ID", sep = "\\.", extra = "drop") %>% select(-t1) %>% 
  dplyr::rename(motif.mean.score = mean_score, motif.max.score = max_score)

ncMotif <- ncMotif %>% separate(col = ID, into = c("t1", "t2"), sep = "_", extra = "merge") %>% separate(t2, into = c("t3", "t4"), sep = "\\.", extra = "drop") %>% mutate(ID = paste(t3, t4, sep=".")) %>% select(ID, mean_score, max_score) %>% 
  dplyr::rename(motif.mean.score = mean_score, motif.max.score = max_score)

remaining_nc_srnas <- read.table("~/phd/RNASeq/srna_seqs/version_1/negative_control/large_alignments/negative_control_ids.txt", sep = "\t", fill =  T)
remaining_nc_srnas <- remaining_nc_srnas %>% dplyr::rename(ID = V1) %>% mutate(keep =T)


pcDat <- pcMFE %>% 
  full_join(pcGC, by = "ID") %>% 
  full_join(max_dists_pc, by = "ID") %>% 
  full_join(pcRDepth, by = "ID") %>% 
  full_join(pcCov, by = "ID") %>% 
  full_join(pcMotif, by = "ID")%>% 
  full_join(pcAlifold, by = "ID") %>% 
  mutate(group = "Positive Control") %>% 
  filter(!is.na(read.max.score)) %>% 
  unique() 

ncDat <- ncMFE %>% 
  full_join(ncGC, by = "ID") %>% 
  full_join(max_dists_nc, by = "ID") %>% 
  full_join(ncRDepth, by = "ID") %>% 
  full_join(ncCovRNA, by = "ID") %>% 
  full_join(ncMotif, by = "ID")%>% 
  full_join(ncAlifold, by = "ID") %>% 
  mutate(group = "Negative Control") 


ncDat <- ncDat %>%  left_join(remaining_nc_srnas, by = "ID") %>% filter(!is.na(keep)) %>% select(-keep) %>%  unique()



dat <- pcDat %>% bind_rows(ncDat)




dat$mfe.score[is.na(dat$mfe.score)] <- 0
dat$gc.score[is.na(dat$gc.score)] <- 50
dat$distance[is.na(dat$distance)] <- 0
dat$reads.mean.score[is.na(dat$reads.mean.score)] <- 0
dat$read.max.score[is.na(dat$read.max.score)] <- 0
dat$cov.mean.score[is.na(dat$cov.mean.score)] <- 0
dat$cov.min.eval[is.na(dat$cov.min.eval)] <- 10
dat$cov.combined.score[is.na(dat$cov.combined.score)] <- 0
dat$cov.count[is.na(dat$cov.count)] <- 0
dat$motif.mean.score[is.na(dat$motif.mean.score)] <- 0
dat$motif.max.score[is.na(dat$motif.max.score)] <- 0
dat$z_mean[is.na(dat$z_mean)] <- 10
dat$z_max[is.na(dat$z_max)] <- 10

randomForestDat <- dat

save(randomForestDat, file = "~/bin/r_git/R/r_files/randomForestDat.Rda")
```

###random_forest_setup

```{r random_forest_setup, eval = F}

load("~/bin/r_git/R/r_files/randomForestDat.Rda")

dat <- randomForestDat %>% select(-ID) %>% unique
set.seed(101)
randomNum <- runif(n = nrow(dat), min = 0, max = 1)

dat$random <- randomNum
dat2 <- dat %>% mutate(group = ifelse(group == "Positive Control", 1, 0)) #%>% select(-na_count)

dat2$group <- as.factor(dat2$group) 

dat2 <- dat2 %>% select(-cov.count, -cov.combined.score)

colGroupNum <- match(x = "group", table = colnames(dat2))

data_set_size <- floor(nrow(dat2)/2)
indexes <- sample(1:nrow(dat2), size = data_set_size)

training <- dat2[indexes,]
validation1 <- dat2[-indexes,]
save(training, file = "~/bin/r_git/R/r_files/training.Rda")
save(validation1, file = "~/bin/r_git/R/r_files/validation1.Rda")

rf_classifier = randomForest(group ~ ., data=training, ntree=100, importance=TRUE)
rf_classifier
save(rf_classifier, file = "~/bin/r_git/R/r_files/rf_classifier.Rda")
```

###random_forest

```{r random_forest, eval = T}
load("~/bin/r_git/R/r_files/rf_classifier.Rda")
load("~/bin/r_git/R/r_files/training.Rda")
load("~/bin/r_git/R/r_files/validation1.Rda")
load("~/bin/r_git/R/r_files/randomForestDat.Rda")

dat <- randomForestDat %>% select(-ID) %>% unique
set.seed(101)
randomNum <- runif(n = nrow(dat), min = 0, max = 1)

dat$random <- randomNum
varImpPlot(rf_classifier)
colGroupNum <- match(x = "group", table = colnames(validation1))
# Make predictions
prediction_for_table <- predict(rf_classifier,validation1[,-colGroupNum])
table(observed=validation1[,colGroupNum],predicted=prediction_for_table)
dat3 <- dat %>% select(-group)
corMat <- cor(dat3, method = "spearman")
round(corMat, 2)
  get_lower_tri<-function(cormat){
    cormat[upper.tri(cormat)] <- NA
    return(cormat)
  }
  get_upper_tri <- function(cormat){
    cormat[lower.tri(cormat)]<- NA
    return(cormat)
  }
upper_tri <- get_upper_tri(corMat)

melted_cormat <- melt(upper_tri, na.rm = TRUE)

# melted_cormat <- melted_cormat %>% filter(Var1 != "cov.combined.score", Var1 != "reads.mean.score", Var1 != "motif.mean.score", Var1 != "z_mean", Var1 != "cov.min.eval")%>% filter(Var2 != "cov.combined.score", Var2 != "reads.mean.score", Var2 != "motif.mean.score", Var2 != "z_mean", Var2 != "cov.min.eval")

p <- ggplot(data = melted_cormat, aes(Var2, Var1, fill = value))+
 geom_tile(color = "white")+
 scale_fill_gradient2(low = "blue", high = "red", mid = "white",
   midpoint = 0, limit = c(-1,1), space = "Lab",
   name="spearman\nCorrelation") +
  theme_minimal()+
 theme(axis.text.x = element_text(angle = 45, vjust = 1,
    size = 12, hjust = 1))+
 coord_fixed()
p
ggsave(filename = "~/phd/RNASeq/figures/corrmat.svg", plot = p)


write_data <- F
if(write_data){
svg(filename="~/phd/RNASeq/figures/random_forest.svg",
     width=20,
     height=20,
     pointsize=12)
varImpPlot(rf_classifier)


dev.off()
}

```


###correlation_heat_map

```{r correlation_heat_map, eval=T}
load("~/bin/r_git/R/r_files/randomForestDat.Rda")
dat <- randomForestDat %>% select(-ID) %>% unique
set.seed(101)
randomNum <- runif(n = nrow(dat), min = 0, max = 1)
dat$random <- randomNum
dat3 <- dat %>% select(-group)



dNames <- colnames(dat3)
pNames <- colnames(dat3)
pvalMatrix<-matrix(1, length(dNames), length(dNames))
rhoMatrix <-matrix(0, length(dNames), length(dNames))
sigMatrix <-matrix("",length(dNames), length(dNames))

colnames(pvalMatrix)    <-pNames
rownames(pvalMatrix)    <-pNames
colnames(rhoMatrix)     <-pNames
rownames(rhoMatrix)     <-pNames
colnames(sigMatrix)     <-pNames
rownames(sigMatrix)     <-pNames
sigCount     <- 0
sigCount2015 <- 0
for(i in 1:length(dNames)){
      for(j in 1:length(dNames)){
   spear<-cor.test(dat3[,dNames[i] == colnames(dat3)], dat3[,dNames[j] == colnames(dat3)], method = "spearman", exact = T)
   pvalMatrix[i,j] <- spear$p.value
   rhoMatrix[i,j]  <- spear$estimate
   if(spear$p.value < 0.05/(15*15)){
sigMatrix[i,j]  <- "X"
                sigCount <- sigCount + 1
   }

      }
}


heatmap.2(rhoMatrix, cellnote=sigMatrix,notecex=1.5,notecol="black", col=rev(redblue(40)), density.info="none", trace="none", dendrogram=c("column"), symm=F,symkey=T,symbreaks=T, scale="none", key.title = "", srtRow=45, adjRow=c(0, 1), srtCol=45, adjCol=c(1,1), breaks=(-20:20)/20,
margins = c(8, 8), cexRow=1.5, cexCol=1.5,font=2)


```

###random_forest_roc

```{r random_forest_roc, eval=T}
load("~/bin/r_git/R/r_files/rf_classifier.Rda")
load("~/bin/r_git/R/r_files/training.Rda")
load("~/bin/r_git/R/r_files/validation1.Rda")
colGroupNum <- match(x = "group", table = colnames(validation1))

prediction_for_roc_curve <- predict(rf_classifier,validation1[,-colGroupNum],type="prob")



validation1$prob <- prediction_for_roc_curve[,2]
validation_roc <- validation1 %>% select(group, prob) %>% mutate(pred = ifelse(prob > 0.06, 1, 0))
table(observed=validation_roc$group,predicted=validation_roc$pred)
roc.curve(response = validation_roc$group, predicted = validation_roc$prob,
          main="ROC curve for MFE")
library(ROCR)
pred <- prediction( validation_roc$prob, validation_roc$group)
perf <- performance(pred,"tpr","fpr")
plot(perf)
str(perf)

cutoffs <- data.frame(cut=perf@alpha.values[[1]], fpr=perf@x.values[[1]], 
                      tpr=perf@y.values[[1]])

```


###random_forsest_predicted_data

```{r random_forsest_predicted_data, eval=T}
load("~/bin/r_git/R/r_files/rf_classifier.Rda")
load("~/bin/r_git/R/r_files/randomForestDat.Rda")
load("~/bin/r_git/R/r_files/validation1.Rda")
colGroupNum <- match(x = "group", table = colnames(validation1))
prediction_for_roc_curve <- predict(rf_classifier,validation1[,-colGroupNum],type="prob")
validation1$probability <- prediction_for_roc_curve[,2]


dat <- randomForestDat %>% select(-ID) %>% unique()
set.seed(101)
randomNum <- runif(n = nrow(dat), min = 0, max = 1)

dat$random <- randomNum

colGroupNum <- match(x = "group", table = colnames(dat))
prediction_randomForestDat <- predict(rf_classifier,dat[,-colGroupNum],type="prob")
dat$probability <- prediction_randomForestDat[,2]

load("~/bin/r_git/R/r_files/max_dists_pred.Rda")

max_dists_pred <- max_dists_pred %>% dplyr::rename(ID = id) %>% select(ID, distance)



load("~/bin/r_git/R/r_files/predRDepth.Rda")

predRDepthMaxs <- predRDepth %>% dplyr::rename(ID = srna) %>% group_by(ID) %>% summarise(read.max.score  = sum(max.val))
predDepthMeans <- predRDepth %>% dplyr::rename(ID = srna) %>% group_by(ID) %>% summarise(reads.mean.score  = sum(mean.val))
predRDepth <- predRDepthMaxs %>% full_join(predDepthMeans, by = "ID") %>%  filter(read.max.score > 0)

load("~/bin/r_git/R/r_files/predCovariation.Rda") ##pcCovRNA

predCovRNA <- predCovRNA %>% filter(!is.na(mean_score)) %>% mutate(combined_score = count * mean_score) %>% 
  dplyr::rename(cov.mean.score = mean_score, cov.min.eval = min_eval, cov.count = count, cov.combined.score = combined_score)




load("~/bin/r_git/R/r_files/predGC.Rda")

predGC <- predGC %>% dplyr::rename(gc.score = V2) %>% separate(V1, into = "ID", sep = "\\[", extra= 'drop') %>% select(ID, gc.score)

load("~/bin/r_git/R/r_files/predAlifold.Rda")

predAlifold <- predAlifold %>% separate(col = ID, into = c("t1", "id"), sep = "_", extra = "merge")  %>% select(-t1, -STDV) %>% dplyr::rename(ID = id) %>% filter(!is.na(ID))


load("~/bin/r_git/R/r_files/predMFE.Rda")

predMFE <- predMFE %>% dplyr::rename(ID = V1, mfe.score = V2) %>% select(ID, mfe.score)





load("~/bin/r_git/R/r_files/predMotif.Rda")

predMotif <- predMotif %>% filter(grepl(pattern = ".stk.gff", x = ID) == F)  %>% 
  dplyr::rename(motif.mean.score = mean_score, motif.max.score = max_score)



predDat <- predMFE %>% 
  full_join(predGC, by = "ID") %>% 
  full_join(max_dists_pred, by = "ID") %>% 
  full_join(predRDepth, by = "ID") %>% 
  full_join(predCovRNA, by = "ID") %>% 
  full_join(predMotif, by = "ID")%>% 
  full_join(predAlifold, by = "ID") %>% 
  mutate(group = "Predicted")

predDat <- predDat  %>% unique()

set.seed(101)
randomNum <- runif(n = nrow(predDat), min = 0, max = 1)

predDat$random <- randomNum



predDat$mfe.score[is.na(predDat$mfe.score)] <- 0
predDat$gc.score[is.na(predDat$gc.score)] <- 50
predDat$distance[is.na(predDat$distance)] <- 0
predDat$reads.mean.score[is.na(predDat$reads.mean.score)] <- 0
predDat$read.max.score[is.na(predDat$read.max.score)] <- 0
predDat$cov.mean.score[is.na(predDat$cov.mean.score)] <- 0
predDat$cov.min.eval[is.na(predDat$cov.min.eval)] <- 10
predDat$cov.combined.score[is.na(predDat$cov.combined.score)] <- 0
predDat$cov.count[is.na(predDat$cov.count)] <- 0
predDat$motif.mean.score[is.na(predDat$motif.mean.score)] <- 0
predDat$motif.max.score[is.na(predDat$motif.max.score)] <- 0
predDat$z_mean[is.na(predDat$z_mean)] <- 10
predDat$z_max[is.na(predDat$z_max)] <- 10

colGroupNum <- match(x = "group", table = colnames(predDat))
colIDNum <- match(x = "ID", table = colnames(predDat))


prediction_for_predcited_data <- predict(rf_classifier,predDat[,-c(colIDNum, colGroupNum)], type = 'response')
prob_for_predcited_data <- predict(rf_classifier,predDat[,-c(colIDNum, colGroupNum)], type = 'prob')

predDat$probability <- prob_for_predcited_data[,2]


##alifold < -4
##distance > 0.071546

predDat <- predDat %>% 
  mutate(prediction = ifelse(probability > 0.09, 1, 0)) ##0.3

table(predDat$prediction)

predDat <- predDat %>% 
  mutate(prediction = ifelse(z_mean < -4.2, 1, 0)) 

table(predDat$prediction)

predDat <- predDat %>% 
  mutate(prediction = ifelse(distance > 0.05, 1, 0)) 

table(predDat$prediction)

predDat <- predDat %>% 
  mutate(prediction = ifelse(read.max.score >= 2029, 1, 0))

table(predDat$prediction)


dat <- dat %>% 
  mutate(prediction = ifelse(probability > 0.3, 1, 0)) 

table(observed=dat$group,predicted=dat$prediction)

dat <- dat %>% 
  mutate(prediction = ifelse(z_mean < -4.2, 1, 0)) 

table(observed=dat$group,predicted=dat$prediction)

dat <- dat %>% 
  mutate(prediction = ifelse(distance > 0.05, 1, 0)) 

table(observed=dat$group,predicted=dat$prediction)

dat <- dat %>% 
  mutate(prediction = ifelse(read.max.score >= 2029, 1, 0))

table(observed=dat$group,predicted=dat$prediction)

dat <- dat %>% 
  mutate(prediction = ifelse(mfe.score < -15, 1, 0))

table(observed=dat$group,predicted=dat$prediction)


table(randomForestDat$group)
rocData <- randomForestDat  %>% mutate(response = ifelse(group == "Positive Control", 1, 0))
roc.curve(response = rocData$response, predicted = rocData$distance,
          main="ROC curve for Maximum Phylogenetic Distance")


save(predDat, file="~/bin/r_git/R/r_files/predDat.Rda")



tmp <- predDat %>% mutate(group = "Predicted") %>% select(group, probability)

allDat <- dat %>% select(group, probability) %>% bind_rows(tmp) 


p <- ggplot() +
  geom_freqpoly(data = allDat, aes(x = probability, y = ..density.., group = group, color = group), binwidth = 0.05) +
  xlim(min = 0, max = 1) 
p

ggsave(filename = "~/phd/RNASeq/figures/probabilites_rf.svg", plot = p)


```


##Examples

###examples_setup

```{r examples_setup, eval=T}
load("~/bin/r_git/R/r_files/predDat.Rda")

new_calls <- read.table("~/phd/RNASeq/genera/new_calls_simple.txt", sep = "\t", fill =  T)
new_calls <- new_calls %>% filter(V5 != "", V5 != "id")
colnames(new_calls) <- c("contig", "start", "stop", "new_feature", "ID")
newCalls <- new_calls %>% select(ID, new_feature)

predDat <- predDat %>% left_join(newCalls, by = "ID")

predDat <- predDat %>% mutate(prediction = ifelse(new_feature == F, 1, prediction))

predNew <- predDat %>% filter(prediction ==  1, new_feature == T)

```




###plots

```{r example_plots, eval=T}
ggplot() + 
  geom_freqpoly(data = predDat %>% filter(read.max.score> 0), aes(x = read.max.score, y = ..density.., group = prediction, color = as.character(prediction)), binwidth = 20) +
  xlim(c(0, 500))


ggplot() + 
  geom_freqpoly(data = predDat %>% filter(mfe.score < 0), aes(x = mfe.score, y = ..density.., group = prediction, color = as.character(prediction)), binwidth = 5) +
  xlim(c(-100, 0))


ggplot() + 
  geom_freqpoly(data = predDat , aes(x = gc.score, y = ..density.., group = prediction, color = as.character(prediction)), binwidth = 2) +
  xlim(c(10, 90))


ggplot() + 
  geom_freqpoly(data = predDat %>% filter(distance> 0), aes(x = distance, y = ..density.., group = prediction, color = as.character(prediction)), binwidth = 0.05) +
  xlim(c(0, 1))


ggplot() + 
  geom_freqpoly(data = predDat %>% filter(cov.count> 0), aes(x = cov.count, y = ..density.., group = prediction, color = as.character(prediction)), binwidth = 1) +
  xlim(c(0, 50))


ggplot() + 
  geom_freqpoly(data = predDat %>% filter(motif.max.score> 0), aes(x = motif.max.score, y = ..density.., group = prediction, color = as.character(prediction)), binwidth = 1) +
  xlim(c(0, 50))


ggplot() + 
  geom_freqpoly(data = predDat %>% filter(motif.max.score> 0), aes(x = motif.max.score, y = ..density.., group = prediction, color = as.character(prediction)), binwidth = 1) +
  xlim(c(0, 50))

```



#Scripts

***

##callPeaksforGenome.sh {#callpeaksforgenome}

Wrapper for a series of scripts that downloads genomes and fastq files, maps reads and calls peaks for a given genome. The fastq files are downloaded from SRA using a list of available experiment IDs.

```{bash callPeaksforGenome.sh, eval = F, echo=T}
#!/bin/bash

##-----------------------------------------------------------------##
##--------------------------- Setup Variables ---------------------##
##-----------------------------------------------------------------##

FILE_PATH=`dirname $0`
number_of_sra="10"
output_path="./"
CPUS='6'
output_log=/dev/stdout
display_available_files="F"

##-----------------------------------------------------------------##
##------------------------ User Input Options ---------------------##
##-----------------------------------------------------------------##

while getopts "g:n:o:c:qth" arg; do
  case $arg in
    g)
      gca=$OPTARG
      ;;
    n)
      number_of_sra=$OPTARG
      ;;      
    o)
      output_path=$OPTARG
      ;;
	c)
      CPUS=$OPTARG
      ;;                  
	q)
      output_log=$gca.log
      ;;
    t)
    display_available_files="T"
    ;; 
    h)
echo '# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -'

      ;;
      
    esac
done    

##-----------------------------------------------------------------##
##-------------------------- Tests For Inputs ---------------------##
##-----------------------------------------------------------------##
if [[ -z $gca ]]; then
echo 'Error: GCA needed. Specify with -g <gca>'
echo ' '
echo 'Use -h for more help.'
echo ' '
exit
fi

counts=`grep $gca ~/phd/RNASeq/SRA_bacteria_RNAseq.txt | grep "PAIRED" | grep "Illumina HiSeq" | wc -l`
if (( $counts == 0 )); then
echo "No valid RNAseq datasets for $gca"

exit
fi

if [[ $display_available_files == "T" ]]; then
grep $gca ~/phd/RNASeq/SRA_bacteria_RNAseq.txt | grep "PAIRED" | grep "Illumina HiSeq"
exit
fi

##-----------------------------------------------------------------##
##---------------------- Set up folders/files ---------------------##
##-----------------------------------------------------------------##

cd $output_path
mkdir -p "$gca.data"
cd "$gca.data"
mkdir gff_files      
echo "Output to $output_log"

if (( $counts > $number_of_sra )); then

grep $gca ~/phd/RNASeq/SRA_bacteria_RNAseq.txt | grep "PAIRED" | cut -f1 | head -n $number_of_sra > tmp1

else

grep $gca ~/phd/RNASeq/SRA_bacteria_RNAseq.txt | grep "PAIRED" | cut -f1 > tmp1

fi


##-----------------------------------------------------------------##
##---------------------- Download Genome and GFF ------------------##
##-----------------------------------------------------------------##

	if [[ -f "${gca}.fna" ]]; then
	echo "$gca.fna already downloaded."
	else
	echo "Downloading $gca Genome and GFF files"
	fetch_genomes_from_GCA.sh -r $gca -g >> $output_log
	fi
	
if [ $? -eq 0 ]; then
    echo " "
else
     echo "Error: Downloading $gca Genome and GFF files failed. See fetch_genomes_from_GCA.sh"
     exit $?
fi


##-----------------------------------------------------------------##
##-------------- Download and Process RNA-Seq Files ----------------##
##-----------------------------------------------------------------##
file_lines=`cat tmp1`

for line in $file_lines ; 
do
	
	if [[ -f "${line}_sra_calls.gff" ]]; then
	
	echo "$line already downloaded."
	
	else
	
	echo "Downloading $line"
    fasterq-dump --split-3 -p $line >> $output_log
	echo "Mapping reads"
    sra2plot.1.0.3.sh -s $line -r $gca -d -n $CPUS  >> $output_log
    
    plot_lenegth=`wc -l $line.plot  | cut -d ' ' -f2`
    rm *.sam    
    	if [ $plot_lenegth -gt 0 ]; then
    	rm ${line}*fwd.plot
    	rm ${line}*.rev.plot
    	rm fastq/${line}*.fastq
    	rm trimmed/${line}*.fastq
    	fi
    rm /Users/thomasnicholson/ncbi/public/sra/*.cache
    echo "Removing CDS"
    removeProteinCodingRNA.R -f $line -g $gca >> $output_log
    echo "Calling Peaks"
    run_rnaPeakCalling.R -f $line  -g $gca >> $output_log
    
    fi
    cp ${line}_sra_calls.gff ./gff_files/
done

##-----------------------------------------------------------------##
##---------------------- Search for rFam models -------------------##
##-----------------------------------------------------------------##

rfamscan() { counts=$( bc -l <<< "scale=2;$(esl-seqstat $1.fna | grep ^"Total" | tr -s ' ' | cut -d ' ' -f4)*2/1000000"); cmscan -Z $counts  --cut_ga --rfam --nohmmonly --tblout $1.tblout --fmt 2 --clanin ~/Downloads/Rfam.clanin.txt ~/Downloads/Rfam.cm $1.fna; cmscanToGffWrapper.R -f $1.tblout -g $1;}

if [[ -f "${gca}_ncRNA.gff" ]]; then
	echo "${gca}_ncRNA.gff exists"
else
	echo "Running cmscan using rfam models"
	rfamscan $gca  >> $output_log
fi

cp $gca.gff ./gff_files/
cp ${gca}_ncRNA.gff ./gff_files


##-----------------------------------------------------------------##
##------------------------ Combine GFF Files ----------------------##
##-----------------------------------------------------------------##

if [[ ! -f "${gca}_new_calls.txt" ]]; then
combine_gff_files.R -f ./gff_files/ -o $gca
fi

echo "Finished."
rm tmp1
```

###fetch_genomes_from_GCA.sh

Downloads a given genome and corresponding annotation file (GFF3 format).

```{bash fetch_genomes_from_GCA.sh, eval = F, echo=T}
#!/bin/bash

##-----------------------------------------------------------------##
##---------------------------- Help Message -----------------------##
##-----------------------------------------------------------------##

usage(){
    echo "fetch_genomes_from_GCA.sh is a script for downloading a genome (and GFF file) from a GCA accession.  
Usage:
 fetch_genomes_from_GCA.sh [opts] [input]

Options:
	-h	Display this help

Input	       
	-r	Reference genome accession (required)
	-o	Output name
	-e Fasta file extension
   	-g include the GFF file

"
}

##-----------------------------------------------------------------##
##------------------------ User Input Options ---------------------##
##-----------------------------------------------------------------##

while getopts "r:o:e:gh" arg; do
case $arg in
	r) 
	GENOME=${OPTARG};;
	o) 
	OUTPUT=${OPTARG};;
	e) 
	EXTENSION=${OPTARG};;
	g)
      GFF='y'
      ;;  
    h)
		usage
		exit
      ;;    
	\?) 
	echo "Unknown option: -${OPTARG}" >&2; exit 1;;
    esac
done

##-----------------------------------------------------------------##
##-------------------------- Tests For Inputs ---------------------##
##-----------------------------------------------------------------##

if [ -z ${GENOME} ]; then
    echo "Error: No input specified." >&2
    usage
    exit 1
fi

if [ -z ${OUTPUT} ]; then

OUTPUT=${GENOME}

fi

if [ -z ${EXTENSION} ]; then

EXTENSION="fna"

fi

##-----------------------------------------------------------------##
##------------------------ Get IDs for download -------------------##
##-----------------------------------------------------------------##

AssemblyName=$(esearch -db assembly -query ${GENOME} | efetch -format docsum | xtract -pattern DocumentSummary -element AssemblyName)
refseqID=$(esearch -db assembly -query ${GENOME} | efetch -format docsum | xtract -pattern DocumentSummary -element RefSeq)

refseq1=$(echo $refseqID | head -c 7 | tail -c 3)
refseq2=$(echo $refseqID | head -c 10 | tail -c 3)
refseq3=$(echo $refseqID | head -c 13 | tail -c 3)



##-----------------------------------------------------------------##
##----------------------- Download fasta file ---------------------##
##-----------------------------------------------------------------##

if [ ! -f $OUTPUT.$EXTENSION ];then

fastaLink="ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/$refseq1/$refseq2/$refseq3/$refseqID._$AssemblyName/$refseqID._$AssemblyName._genomic.fna.gz"

downloadLink=$(echo $fastaLink | sed 's/\._/_/g')

curl $downloadLink > $OUTPUT.$EXTENSION.gz 
sleep 1
gunzip $OUTPUT.$EXTENSION.gz 

if [ $? -eq 0 ]; then
    echo " "
else
    exit $?
fi


echo "$OUTPUT.$EXTENSION downloaded using $downloadLink"

else

fastaLink="ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/$refseq1/$refseq2/$refseq3/$refseqID._$AssemblyName/$refseqID._$AssemblyName._genomic.fna.gz"

downloadLink=$(echo $fastaLink | sed 's/\._/_/g')

echo "$OUTPUT.$EXTENSION already downloaded. To download again use $downloadLink"


fi

##-----------------------------------------------------------------##
##------------------------ Download GFF file ----------------------##
##-----------------------------------------------------------------##

if [[ $GFF = 'y' ]]; then

if [ ! -f $OUTPUT.gff ];then

      
gffLink="ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/$refseq1/$refseq2/$refseq3/$refseqID._$AssemblyName/$refseqID._$AssemblyName._genomic.gff.gz"

downloadLink=$(echo $gffLink | sed 's/\._/_/g')

curl $downloadLink > $OUTPUT.gff.gz 
sleep 1
gunzip $OUTPUT.gff.gz 

if [ $? -eq 0 ]; then
    echo " "
else
     exit $?
fi

echo "$OUTPUT.gff downloaded using $downloadLink"

else

gffLink="ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/$refseq1/$refseq2/$refseq3/$refseqID._$AssemblyName/$refseqID._$AssemblyName._genomic.gff.gz"

downloadLink=$(echo $gffLink | sed 's/\._/_/g')

echo "$OUTPUT.gff already downloaded. To download again use $downloadLink"


fi

fi


```

###sra2plot.1.0.3.sh


Script that maps reads from fastq file to genome and produces a plot file with read depths for each nucleotide.

```{bash sra2plot.1.0.3.sh, eval=F, echo=T}
#!/bin/sh
#Downloads fastq files from SRA, trims, maps and generates plotfiles for visualisation in artemis

#Dependencies:
#curl
#sratoolkit
#samtools 1.6 (older versions may not work for generating plotfiles)
#bowtie2
#trimmomatic 0.36

usage(){
    echo "sra2plot.sh is a wrapper script for downloading, mapping and visualising RNA-seq data from the NCBI Sequence Read Archive (SRA). Currently assumes paired end reads with TruSeq3 adaptors. Path for trimmomatic needs to be set to run. 
Usage sra2plot [opts] [input]
    
    Options:
		-h	Display this help

		Input	       
	       	-r	Reference genome accession (required)
		-s	SRA run accession or name of split fastq files (Required. Format: FILE_1.fastq FILE_2.fastq)
    		-n	Number of cores

		Turn off defaults
		-d	Turn off download. Default: download genome and SRA from NCBI if not found in working directory. 
			(Genome accession must be in Genbank nucleotide format: https://www.ncbi.nlm.nih.gov/Sequin/acc.html)
		-t	Turn off trimming
		-m	Turn off mapping
		-p	Don't make plotfiles
		-x	Don't cleanup files"
}
TPATH="/Users/thomasnicholson/bin/Trimmomatic_binary-0.36"
OUTDIR=""
SRA=""
GENOME=""
TRIM=true
MAP=true
PLOT=true
CLEAN=true
DOWNLOAD=true
THREADS=1

while getopts :s:r:n:thdmpx opt; do
    case "${opt}" in
	h) usage;exit;;
	t) TRIM=false;;
	s) SRA=${OPTARG};;
	r) GENOME=${OPTARG};;
	d) DOWNLOAD=false;;
	m) MAP=false;;
	p) PLOT=false;;
	x) CLEAN=false;;
	n) THREADS=${OPTARG};;
	\?) echo "Unknown option: -${OPTARG}" >&2; exit 1;;
	:) echo "Missing option argument for -${OPTARG}" >&2; exit 1;;
	*) echo "Unimplemented option: -${OPTARG}" >&2; exit;;
    esac
done
shift $((${OPTIND}-1))

if [ -z ${GENOME} ] || [ -z ${SRA} ]; then
    echo "Error: No input specified." >&2
    usage
    exit 1
fi

if [ -z ${TPATH} ]; then
    echo "Error: Path to trimmomatic install folder is not set.\n" >&2
    exit 1
fi

if $DOWNLOAD;then
    if [ ! -f ${GENOME}.fna ];then
	fetch_genomes_from_GCA.sh -r ${GENOME} -g
    fi
    if [ ! -f ${SRA}_*.fastq ];then
	fastq-dump --split-3 ${SRA}
    fi
fi

if $TRIM;then 
    if [ ! -d trimmed ];then
	mkdir trimmed
    fi
    java -jar ${TPATH}/trimmomatic-0.36.jar PE -threads `echo $((2*${THREADS}))` ${SRA}_1.fastq ${SRA}_2.fastq trimmed/${SRA}_1_paired.fastq trimmed/${SRA}_1_unpaired.fastq trimmed/${SRA}_2_paired.fastq trimmed/${SRA}_2_unpaired.fastq ILLUMINACLIP:${TPATH}/adapters/TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36
fi

if $MAP; then
    #Build index of genome if necessary
    if [ ! -d index ]; then
	mkdir index 
	fi
	bowtie2-build ${GENOME}.fna ${GENOME} &&

	mv *.bt2* index/
    
    bowtie2 -p `echo "$((${THREADS}))"` -x index/${GENOME} -1 trimmed/${SRA}_1_paired.fastq -2 trimmed/${SRA}_2_paired.fastq -S ${SRA}.sam
fi

if $PLOT;then
    samtools view -bS -@ ${THREADS} ${SRA}.sam > ${SRA}.bam
    samtools sort -@ ${THREADS} ${SRA}.bam > ${SRA}.sorted.bam
    # Forward strand.
    #alignments of the second in pair if they map to the forward strand
    samtools view -b -f 128 -F 16 -@ ${THREADS} ${SRA}.sorted.bam > ${SRA}.fwd1.bam
    samtools index ${SRA}.fwd1.bam
    #alignments of the first in pair if they map to the reverse strand
    samtools view -b -f 80 -@ ${THREADS} ${SRA}.sorted.bam > ${SRA}.fwd2.bam
    samtools index ${SRA}.fwd2.bam
    #combine alignments that originate on the forward strand
    samtools merge -f ${SRA}.fwd.bam ${SRA}.fwd1.bam ${SRA}.fwd2.bam
    samtools index ${SRA}.fwd.bam

    # Reverse strand
    #alignments of the second in pair if they map to the reverse strand
    samtools view -b -f 144 -@ ${THREADS} ${SRA}.sorted.bam > ${SRA}.rev1.bam
    samtools index ${SRA}.rev1.bam
    #alignments of the first in pair if they map to the forward strand
    samtools view -b -f 64 -F 16 -@ ${THREADS} ${SRA}.sorted.bam > ${SRA}.rev2.bam
    samtools index ${SRA}.rev2.bam
    #combine alignments that originate on the reverse strand.
    samtools merge -f ${SRA}.rev.bam ${SRA}.rev1.bam ${SRA}.rev2.bam
    samtools index ${SRA}.rev.bam

    #Generate plotfiles
    samtools mpileup -aa ${SRA}.fwd.bam > ${SRA}.fwd.mpileup
    samtools mpileup -aa ${SRA}.rev.bam > ${SRA}.rev.mpileup
    cat ${SRA}.fwd.mpileup | cut -f4 > ${SRA}.fwd.plot
    cat ${SRA}.rev.mpileup | cut -f4 > ${SRA}.rev.plot
    paste ${SRA}.rev.plot ${SRA}.fwd.plot > ${SRA}.plot   
fi

if $CLEAN; then
    rm *.bam *.mpileup *.bai
	if [ ! -d fastq ]; then
	    mkdir fastq
	fi
	mv ${SRA}_*.fastq fastq/
fi



#To-do
#add install checks
#add opts for directory outputs
#write readme
#make logs/verbose?


```

###removeProteinCodingRNA.R


In order to call non-coding RNA expression, expression of coding regions must be ignored as not all of the RNA-Seq experiemtns are focused on ncRNA. This script does this by setting coding regions (defined based on the annotation file) to a read depth of 0.

```{r removeProteinCodingRNA.R, eval = F, echo=T}
#!/usr/bin/env Rscript
suppressMessages(library('getopt'))



spec = matrix(c(
  'sra', 'f', 1, "character",
  'help' , 'h', 0, "logical",
  'stranded' , 's', 0, "logical",
  'gff' , 'g', 1, "character",
  'file_path', 'p', 2, "character",
  'range', 'r', 2, "integer",
  'out_name', 'o', 2, "character"
), byrow=TRUE, ncol=4)


opt = getopt(spec)

if ( !is.null(opt$help) ) {
  cat("removeProteinCoding.R version 1.0\n")
  cat(" \n")
  cat("Use removeProteinCoding.R <options> -f <sra plot file> -g <gff file>\n")
  cat(" \n")
  cat("Options:\n")
  cat("  -f <sra plot file> The file that contains the plot data. Do not inclue the .plot file extension\n")
  cat("  -g <gff file> The file that contains the gff data. Do not inclue the gff file extension\n")
  cat("  -s <stranded data> The data is stranded\n")
  cat("  -p <file path> The location of the other files and the output file\n")
  cat("  -r <protein coding range> The number of nucleotides either side of a CDS region that should also be set to zero\n")
  cat("  -o <output file name> The name of the output file. Do not inclue the gff file extension. The default is the same as the sra input\n")
  q(status=1)
}

if ( is.null(opt$sra) ) {
  cat("Error: -f <sra plot file> is required.\n")
  q(status=1)
}
if ( is.null(opt$gff) ) {
  cat("Error: -g <gff file> is required.\n")
q(status=1)
}
suppressMessages(library(tidyverse))
suppressMessages(library(tjnFunctions))

if ( is.null(opt$file_path ) ) { opt$file_path = "." }
if ( is.null(opt$range ) ) { opt$range = 50 }
if ( is.null(opt$out_name ) ) { opt$out_name = opt$sra }
if(is.null(opt$stranded)){
  stranded <- F
}else{
  stranded <- T
}
sraName <- opt$sra
gffName <- opt$gff
filePath <- opt$file_path


plotDat <- read.table(paste(filePath, "/", sraName, ".plot", sep = ""))
gffDat <- read.table(paste(filePath, "/", gffName, ".gff", sep = ""), sep = "\t", fill = T, comment.char = "#", quote = "")

colnames(gffDat) <- c("sequence", "source", "feature", "start", "end", "score", "strand", "phase", "Atrribute")

plotDat <- removeCDSregions(plotDat = plotDat, gffDat = gffDat, stranded = stranded, time.it = T)



cat(paste("Writing the plot output to ", filePath, "/", opt$out_name, "_ncRNA.plot\n", sep = ""))
write.table(plotDat%>%select(V1,V2), file = paste(filePath, "/", opt$out_name, "_ncRNA.plot", sep = ""), quote = F, row.names = F, col.names = F, sep = "\t")


```

###run_rnaPeakCalling.R


Regions of expression are called on each individual RNA-Seq experiment by looking for regions where read depths are > 15 for atleast 50nt.

```{r run_rnaPeakCalling.R, eval = F, echo=T}
#!/usr/bin/env Rscript
suppressMessages(library('getopt'))

spec = matrix(c(
  'sra', 'f', 1, "character",
  'help' , 'h', 0, "logical",
  'stranded' , 's', 0, "logical",
  'quiet' , 'q', 0, "logical",
  'gff' , 'g', 1, "character",
  'file_path', 'p', 2, "character",
  'range', 'r', 2, "integer",
  'out_name', 'o', 2, "character"
), byrow=TRUE, ncol=4)


opt = getopt(spec)

if ( !is.null(opt$help) ) {
  cat("run_rnaPeakCalling.R version 1.0\n")
  cat(" \n")
  cat("Use run_rnaPeakCalling.R <options> -f <sra plot file> -g <gff file>\n")
  cat(" \n")
  cat("Options:\n")
  cat("  -f <sra plot file> The file that contains the plot data. Do not inclue the .plot file extension\n")
  cat("  -g <gff file> The file that contains the gff data. Do not inclue the gff file extension\n")
  cat("  -s <stranded data> The data is stranded\n")
  cat("  -q <quiet> Do not print any updates\n")
  cat("  -p <file path> The location of the other files and the output file\n")
  cat("  -r <protein coding range> The number of nucleotides either side of a CDS region that should also be set to zero\n")
  cat("  -o <output file name> The name of the output file. Do not inclue the gff file extension. The default is the same as the sra input\n")
  q(status=1)
}

if ( is.null(opt$sra) ) {
  cat("Error: -f <sra plot file> is required.\n")
  q(status=1)
}
if ( is.null(opt$gff) ) {
  cat("Error: -g <gff file> is required.\n")
  q(status=1)
}



suppressMessages(library(tidyverse))
suppressMessages(library(tjnFunctions))
###--- column 1 is reverse and column 2 is forward ---###

if ( is.null(opt$file_path ) ) { opt$file_path = "." }
if ( is.null(opt$range ) ) { opt$range = 50 }
if ( is.null(opt$out_name ) ) { opt$out_name = opt$sra }
if(is.null(opt$stranded)){
  stranded <- F
}else{
  stranded <- T
}

if(is.null(opt$quiet)){
  quiet <- F
}else{
  quiet <- T
}

sraName <- opt$sra
gffName <- opt$gff
filePath <- opt$file_path

ptm <- proc.time()


gffDat  <- tryCatch({
  suppressWarnings(gffDat <- read.table(paste(filePath, "/", gffName, ".gff", sep = ""), sep = "\t", fill = T, comment.char = "#", quote = ""))
  gffDat
}, error =  function(e) {
  cat(paste("Error: ", opt$file_path, "/", opt$gff, ".gff not found.\n", sep = ""))
  q(status=1)
})


plotDat  <- tryCatch({
  suppressWarnings(plotDat <- read.table(paste(filePath, "/", sraName, ".plot", sep = "")))
  plotDat
}, error =  function(e) {
  cat(paste("Error: ", opt$file_path, "/", opt$sra, ".plot not found.\n", sep = ""))
  q(status=1)
})

total <- (sum(plotDat$V1) + sum(plotDat$V2))/1000000

colnames(gffDat) <- c("sequence", "source", "feature", "start", "end", "score", "strand", "phase", "Atrribute")

plotDatncRNA  <- tryCatch({
  ##Change this path or put the header file in the working directory
  suppressWarnings(plotDatncRNA <- read.table(paste(filePath, "/", sraName, "_ncRNA.plot", sep = "")))

  plotDatncRNA
}, error =  function(e) {
  plotDat <- read.table(paste(filePath, "/", sraName, ".plot", sep = ""))
  if(quiet == F){
    cat("Running removeCDSregions\n")

  }
  plotDatncRNA <- removeCDSregions(plotDat = plotDat, gffDat = gffDat, stranded = stranded, time.it = T)

  plotDatncRNA
} )

plotDatncRNA$V1 <- plotDatncRNA$V1/total
plotDatncRNA$V2 <- plotDatncRNA$V2/total



cat("Running rnPeakCalling\n")

cat("Calling forward\n")
callsDatFwd <- rnaPeakCalling(dat = plotDatncRNA, col.num = 2, small_peaks = F, plot_threshold = 15/total)

cat("Calling reverse\n")
callsDatRev <- rnaPeakCalling(dat = plotDatncRNA, col.num = 1, small_peaks = F, plot_threshold = 15/total)


callsDatFwd <- callsDatFwd%>%mutate(strand = "+")
callsDatRev <- callsDatRev%>%mutate(strand = "-")

runningTime <- proc.time() - ptm
  printRunningTime(runningTime = runningTime)

  if("feature.length" %in% colnames(callsDatFwd) == F){
    print(colnames(callsDatFwd))
    print(head(callsDatFwd))
    cat("Warning: feature.length column not found in callsDatFwd.\n")
    quitStatus <- T
    callsDatFwdTmp <- callsDatFwd%>%filter(start != 0)%>%
      mutate(feature.length = stop - start)%>%
      mutate(feature.score = feature.length*mean.score)%>%
      filter(feature.score > 3)
  }else{
  callsDatFwdTmp <- callsDatFwd%>%filter(start != 0)%>%
    mutate(feature.score = feature.length*mean.score)%>%
    filter(feature.score > 3)
  }
  if("feature.length" %in% colnames(callsDatRev) == F){
    print(colnames(callsDatRev))
    print(head(callsDatRev))
    cat("Warning: feature.length column not found in callsDatRevTmp.\n")
    quitStatus <- T
    callsDatRevTmp <- callsDatRev%>%filter(start != 0)%>%
      mutate(feature.length = stop - start)%>%
      mutate(feature.score = feature.length*mean.score)%>%
      filter(feature.score > 3)
  }else{
  callsDatRevTmp <- callsDatRev%>%filter(start != 0)%>%
    mutate(feature.score = feature.length*mean.score)%>%
    filter(feature.score > 3)
  }
  
  # if(quitStatus == T){
  #   q(status=1)
  # }

gffMain <- readLines(paste(filePath, "/", gffName, ".gff", sep = ""))
gffMain <- data.frame(text = gffMain)
genomeInfo <- as.character(gffMain[8,1])
genomeBuild <- as.character(gffMain[4,1])
genomeSpecies <- as.character(gffMain[9,1])
accession <- strsplit(genomeInfo, " ")[[1]][2]



gffFwd <- callsDatFwdTmp%>%mutate(strand = "+",
                                                 source = "sraAlignedncRNAExpression",
                                                 seqname = accession,
                                                 median.val = round(mean.score*100),
                                                 feature = "ncRNA",
                                                 frame = ".",
                                                 attribute = paste("ID=rna_fwd_", row_number(), sep = ""))%>%
  select(seqname, source, feature, start, stop, median.val, strand, frame, attribute)

gffRev <- callsDatRevTmp%>%mutate(strand = "-",
                                                 source = "sraAlignedncRNAExpression",
                                                 seqname = accession,
                                                 median.val = round(mean.score*100),
                                                 feature = "ncRNA",
                                                 frame = ".",
                                                 attribute = paste("ID=rna_rev_", row_number(), sep = ""))%>%
  select(seqname, source, feature, start, stop, median.val, strand, frame, attribute)%>%
  arrange(as.numeric(start))



gff <- gffFwd%>%bind_rows(gffRev)%>%arrange(as.numeric(start))
gff <- gff%>%filter(start != 0)




fileConn<-file(paste(filePath, "/", opt$out_name, "_sra_calls.gff", sep = ""))
writeLines(c("##gff-version 3",
             "#!gff-spec-version 1.21",
             "#!processor R script (local) with manual add of top section",
             genomeBuild,
             paste("#!genome-build-accession NCBI_Assembly:", opt$gff, sep = ""),
             paste("#!annotation-date ", Sys.Date(), sep = ""),
             "#!annotation-source sraPlotSummary.R (local version)",
             genomeInfo,
             genomeSpecies), fileConn)
close(fileConn)

cat(paste("Writing the gff output to ", filePath, "/", opt$out_name, "_sra_calls.gff\n", sep = ""))
write.table(x = gff, file = paste(filePath, "/", opt$out_name, "_sra_calls.gff", sep = ""), row.names = F, col.names = F, quote = F, sep = "\t", append = T)



```

###rfamscan


Annotations of known sRNAs in the downloaded annotation file were supplemented by searching for known rFam families in each genome.

```{bash rfamscan, eval = F, echo=T}
rfamscan() { counts=$( bc -l <<< "scale=2;$(esl-seqstat $1.fna | grep ^"Total" | tr -s ' ' | cut -d ' ' -f4)*2/1000000"); cmscan -Z $counts  --cut_ga --rfam --nohmmonly --tblout $1.tblout --fmt 2 --clanin ~/Downloads/Rfam.clanin.txt ~/Downloads/Rfam.cm $1.fna; cmscanToGffWrapper.R -f $1.tblout -g $1;}
```

####cmscanToGFFWrapper.R


The output from running cmscan needs to be in the same format as the rest of the data (GFF3).

```{r cmscanToGFFWrapper.R, eval=F, echo=T}
#!/usr/bin/env Rscript
library('getopt')


spec = matrix(c(
  'cmscanOutput', 'f', 1, "character",
  'gcf', 'g', 1, "character",
  'help' , 'h', 0, "logical",
  'file_path', 'p', 2, "character",
  'out_name', 'o', 2, "character"
), byrow=TRUE, ncol=4)


opt = getopt(spec)
#
# opt$cmscanOutput <- "GCA_000017745.1.tblout"
# opt$gcf <- "GCA_000017745.1"
# opt$file_path <- "~/phd/RNASeq/escherichia/"
# opt$output <- "escherichia_test"

if ( !is.null(opt$help) ) {
  cat("cmscanToGffWrapper.R version 1.0\n\n")
  cat("Use cmscanToGffWrapper.R <options> -f <cmscan ouptut file> -g <gff file>\n\n")
  cat("Options:\n")
  cat("  -f <cmscan ouptut file> The file that contains the cmscan output\n")
  cat("  -g <gff file> The file that contains the gff data. Do not inclue the gff file extension\n")
  cat("  -f <file path> The location of the other files and the output file\n")
  cat("  -o <output file name> The name of the output file. Do not inclue the gff file extension. The default is the same as the gca input\n")
   q(status=1)
}

if ( is.null(opt$cmscanOutput) ) {
  cat("Error: -f <cmscan ouptut file> is required.\n")
  q(status=1)
}
if ( is.null(opt$gcf) ) {
  cat("Error: -g <gff file> is required.\n")
  q(status=1)
}

library(tidyverse)
library(tjnFunctions)

if ( is.null(opt$file_path ) ) { opt$file_path = "." }
if ( is.null(opt$output ) ) { opt$output = opt$gcf }

rfamRes <- read.table(paste(opt$file_path, opt$cmscanOutput, sep = "/"), header = F, comment.char = "#",quote = "", fill = T)


gff <- cmscanToGff(rfamRes = rfamRes)


gffMain <- readLines(paste(opt$file_path, "/", opt$gcf, ".gff", sep = ""))
gffMain <- data.frame(text = gffMain)
genomeInfo <- as.character(gffMain[8,1])
genomeBuild <- as.character(gffMain[4,1])
genomeSpecies <- as.character(gffMain[9,1])
accession <- strsplit(genomeInfo, " ")[[1]][2]

fileConn<-file(paste(opt$file_path, "/",opt$output, "_ncRNA.gff", sep = ""))
writeLines(c("##gff-version 3",
             "#!gff-spec-version 1.21",
             "#!processor R script (local)",
             genomeBuild,
             paste("#!genome-build-accession NCBI_Assembly:", opt$gcf, sep = ""),
             paste("#!annotation-date ", Sys.Date(), sep = ""),
             "#!annotation-source cmscan (rFam) (local version)",
             genomeInfo,
             genomeSpecies), fileConn)
close(fileConn)


write.table(x = gff, file = paste(opt$file_path, "/",opt$output, "_ncRNA.gff", sep = ""), row.names = F, col.names = F, quote = F, sep = "\t", append = T)

```

###cmscanToLookupTable.R



The output from running cmscan needs to be in the same format as the rest of the data (GFF3).

```{r cmscanToLookupTable.R, eval=F, echo=T}
#!/usr/bin/env Rscript
library('getopt')

cmscanToLookup <- function(rfamRes){
  colnames(rfamRes) <- c("idx", "target.name", "accession1", "query.name", "accession2", "clan.name", "mdl", "mdl.from",  "mdl.to", "seq.from",   "seq.to",
                         "strand", "trunc", "pass",   "gc",  "bias",  "score",   "E.value", "inc", "olp", "anyidx", "afrct1", "afrct2", "winidx", "wfrct1", "wfrct2", "description.of.target")
  
  rfamRes <- rfamRes%>%
    mutate(seq.from2 = seq.from)%>%
    mutate(seq.from = ifelse(seq.from > seq.to, seq.to, seq.from))%>%
    mutate(seq.to = ifelse(seq.from2 > seq.to, seq.from2, seq.to))
  
  gff <- data.frame(seqname = rfamRes$query.name,
                    source = rep("rfam", nrow(rfamRes)),
                    feature = rep("ncRNA", nrow(rfamRes)),
                    start = rfamRes$seq.from,
                    end = rfamRes$seq.to,
                    score = rfamRes$score,
                    strand = rfamRes$strand,
                    frame = rep(".", nrow(rfamRes)),
                    attribute = rfamRes$accession1)
  return(gff)
}


spec = matrix(c(
  'cmscanOutput', 'f', 1, "character",
  'gcf', 'g', 1, "character",
  'help' , 'h', 0, "logical",
  'file_path', 'p', 2, "character",
  'out_name', 'o', 2, "character"
), byrow=TRUE, ncol=4)


opt = getopt(spec)
#
# opt$cmscanOutput <- "GCA_000017745.1.tblout"
# opt$gcf <- "GCA_000017745.1"
# opt$file_path <- "~/phd/RNASeq/escherichia/"
# opt$output <- "escherichia_test"

if ( !is.null(opt$help) ) {
  cat("cmscanToGffWrapper.R version 1.0\n\n")
  cat("Use cmscanToGffWrapper.R <options> -f <cmscan ouptut file> -g <gff file>\n\n")
  cat("Options:\n")
  cat("  -f <cmscan ouptut file> The file that contains the cmscan output\n")
  cat("  -g <gff file> The file that contains the gff data. Do not inclue the gff file extension\n")
  cat("  -f <file path> The location of the other files and the output file\n")
  cat("  -o <output file name> The name of the output file. Do not inclue the gff file extension. The default is the same as the gca input\n")
  q(status=1)
}

if ( is.null(opt$cmscanOutput) ) {
  cat("Error: -f <cmscan ouptut file> is required.\n")
  q(status=1)
}
if ( is.null(opt$gcf) ) {
  cat("Error: -g <gff file> is required.\n")
  q(status=1)
}

library(tidyverse)
library(tjnFunctions)

if ( is.null(opt$file_path ) ) { opt$file_path = "." }
if ( is.null(opt$output ) ) { opt$output = opt$gcf }

rfamRes <- read.table(paste(opt$file_path, opt$cmscanOutput, sep = "/"), header = F, comment.char = "#",quote = "", fill = T)


gff <- cmscanToLookup(rfamRes = rfamRes)
gff <- gff %>% arrange(start)


write.table(x = gff, file = paste(opt$file_path, "/",opt$output, "_ncRNA.lookup", sep = ""), row.names = F, col.names = F, quote = F, sep = "\t")

```



###combine_gff_files.R


For each genome all of the individual annotation files are combined into a single file with the description column incuding details of the origin of each annotation.

```{r combine_gff_files.R, eval=F, echo=T}
#!/usr/bin/env Rscript
suppressMessages(library('getopt'))


# getopts -----------------------------------------------------------------


spec = matrix(c(
  'sra', 'f', 1, "character",
  'gff', 'g', 1, 'character',
  'help' , 'h', 0, "logical",
  'stranded' , 's', 0, "logical",
  'quiet' , 'q', 0, "logical",
  'file_path', 'p', 2, "character",
  'out_name', 'o', 2, "character",
  'random_data', 'r', 1, "character"
), byrow=TRUE, ncol=4)


opt = getopt(spec)

if ( !is.null(opt$help) ) {
  cat("combine_gff_files.R version 1.0\n")
  cat(" \n")
  cat("Use combine_gff_files.R <options> -f <files>\n")
  cat(" \n")
  cat("Options:\n")
  cat("  -f <files> The gff files\n")
  cat("  -s <stranded data> The data is stranded\n")
  cat("  -r <random data> The file to remove CDS regions from\n")
  cat("  -q <quiet> Do not print any updates\n")
  cat("  -p <file path> The location of the other files and the output file\n")
  cat("  -o <output file name> The name of the output file. Do not inclue the gff file extension. The default is the same as the sra input\n")
  q(status=1)
}

if ( is.null(opt$sra) ) {
  cat("Error: -f <files> is required.\n")
  q(status=1)
}

if ( is.null(opt$out_name) ) {
  cat("Error: -o <output file name> is required.\n")
  q(status=1)
}


# packages ----------------------------------------------------------------


suppressMessages(library(tidyverse))
suppressMessages(library(comparativeSRA))

# defining variables ------------------------------------------------------


if ( is.null(opt$file_path ) ) { opt$file_path = "." }
if ( is.null(opt$out_name ) ) { opt$out_name = opt$sra }
if(is.null(opt$stranded)){
  stranded <- F
}else{
  stranded <- T
}

if(is.null(opt$quiet)){
  quiet <- F
}else{
  quiet <- T
}


#####

file_path <- opt$file_path
files <- list.files(paste(file_path, opt$sra, sep = "/"), pattern = ".gff$")
# import data -------------------------------------------------------------


#print(files)
dat <- data.frame(sequence = as.character("0"), source = as.character("0"), feature = as.character("0"),
                  start = as.integer("0"), end = as.integer("0"), score = as.character("0"),
                  strand = as.character("0"), phase = as.character("0"), Atrribute = as.character("0"), file_name = as.character("start_row"), stringsAsFactors = F)
i <- 2
for(i in 1:length(files)){
  tmp  <- tryCatch({
    suppressWarnings(tmp <- read.table(paste(file_path, opt$sra, files[i], sep = "/"), comment.char = "#", quote = "", sep = "\t", as.is = T))
  }, error =  function(e) {
    cat(paste("Error: ", "row ", i, ", ", file_path, "/", opt$sra, "/", files[i], " cannot be opened.\n", sep = ""))
    cat(paste(e, "\n"))
  })

  if(class(tmp) == "NULL"){
    next
  }

  if(ncol(tmp) != 9){
    cat(paste("Error: ", "row ", i, ", ", file_path, "/", opt$sra, "/", files[i], " contains ", ncol(tmp), " columns.\n", sep = ""))
    next
  }

  colnames(tmp) <- c("sequence", "source", "feature", "start", "end", "score", "strand", "phase", "Atrribute")

  tmp <- tmp%>%mutate(file_name = files[i])%>%mutate(score = as.character(score))

  if(files[i] == opt$random_data){
    tmp <- tmp%>%
  filter(feature != "CDS", feature != "gene", feature != "pseudogene", feature != "exon", feature != "region")
  }else{
  
  dat <- dat%>%bind_rows(tmp)
}
}
if(!is.null(opt$random_data)){
   ncRNAgff <- dat%>%
     filter(feature != "gene", feature != "pseudogene", feature != "exon", feature != "region")
}else{
ncRNAgff <- dat%>%
  filter(feature != "CDS", feature != "gene", feature != "pseudogene", feature != "exon", feature != "region")
}

# main section  -------------------------------------------------------------------


ncRNAgff <- ncRNAgff%>%arrange(start) %>% filter((end - start) > 0)# %>% arrange(strand)


mergedDat <- data.frame(sequence = as.character("0"), feature = as.character("0"),
                        start = as.integer("0"), end = as.integer("0"),
                        strand = as.character("0"), file_names = as.character("start_row"),
                        row_numbers = as.character("0"), prop_overlap = as.numeric(0), new_feature = F,
                        number_of_rnaseq_files = as.integer("0"),
                        score = as.character("0"),
                        stringsAsFactors = F)

##loop through the combined gff files and combine features that overlap
i <- 3
current_feature <- F #is there a current feature being written?
new_feature <- T

for(i in 1:(nrow(ncRNAgff))){
  ##check if the feature is already known
  if(ncRNAgff$source[i] != "sraAlignedncRNAExpression"){
    new_feature <- F
  }

  ##if there is no current feature then set a new start value
  if(current_feature == F){
  start_val <- ncRNAgff$start[i]
  start_i <- i
  end_val <- ncRNAgff$end[i]
  }



  ##set the new end value
  if(ncRNAgff$end[i] > end_val){
  end_val <- ncRNAgff$end[i]
  }

  if(i == nrow(ncRNAgff)){
    
    ##check if the subsequent feature was contained within the first feature
    if(ncRNAgff$end[start_i] < end_val){
      prop_val <- (ncRNAgff$end[start_i] - ncRNAgff$start[i])/(end_val - start_val)
    }else{
      prop_val <- 1
    }
    
    tmp <- data.frame(sequence = ncRNAgff$sequence[i],
                      feature = ncRNAgff$feature[i],
                      start = start_val, end = end_val,
                      strand = ncRNAgff$strand[i],
                      file_names = paste(ncRNAgff$file_name[start_i:i], collapse = ","),
                      row_numbers = paste(c(start_i:i), collapse = ","),
                      prop_overlap = prop_val,
                      new_feature = new_feature,
                      number_of_rnaseq_files = length(start_i:i),
                      score = as.character(ncRNAgff$score[i]),
                      stringsAsFactors = F)
    mergedDat <- mergedDat%>%bind_rows(tmp)
    current_feature <- F
    new_feature <- T
  }else{
    
    
  ##check if the cuurent end value overlaps with the next starting value and update the end value if it does
  if(end_val > ncRNAgff$start[i + 1]){
    end_val <- ncRNAgff$end[i + 1]
    current_feature <- T
  }else{

    ##check if the subsequent feature was contained within the first feature
    if(ncRNAgff$end[start_i] < end_val){
    prop_val <- (ncRNAgff$end[start_i] - ncRNAgff$start[i])/(end_val - start_val)
    }else{
      prop_val <- 1
    }

    tmp <- data.frame(sequence = ncRNAgff$sequence[i],
                      feature = ncRNAgff$feature[i],
                      start = start_val, end = end_val,
                      strand = ncRNAgff$strand[i],
                      file_names = paste(ncRNAgff$file_name[start_i:i], collapse = ","),
                      row_numbers = paste(c(start_i:i), collapse = ","),
                      prop_overlap = prop_val,
                      new_feature = new_feature,
                      number_of_rnaseq_files = length(start_i:i),
                      score = as.character(ncRNAgff$score[i]),
                      stringsAsFactors = F)
    mergedDat <- mergedDat%>%bind_rows(tmp)
    current_feature <- F
    new_feature <- T
  }
  }
}





mergedDat <- mergedDat%>%filter(number_of_rnaseq_files > 0, file_names != "start_row")

# if(!is.null(opt$random_data)){
#   mergedDat <- mergedDat %>% filter(file_names != opt$gff)
# }

mergedDat <- mergedDat %>% mutate(id =  paste(opt$out_name, row_number(), sep = "_"))

cat(paste("Writing the output to ", file_path, "/", opt$out_name, "_new_calls.txt\n", sep = ""))
write.table(x = mergedDat, file = paste(file_path, "/", opt$out_name, "_new_calls.txt", sep = ""), row.names = F, col.names = T, quote = F, sep = "\t")




```







##run_rnapeakcalling.2.0.r


Regions of expression are called on each individual RNA-Seq experiment by looking for regions where read depths are > 15 for atleast 50nt.

```{r run_rnaPeakCalling2.0.R, eval = F, echo=T}
#!/usr/bin/env Rscript

##no idea which packages are needed
library(tidyverse)
library(devtools)
library(lubridate)
library(genoPlotR)
library(drake)
library(ape)
library(Biostrings)
library(ROSE)
library(reshape2)

suppressMessages(library(tidyverse))
suppressMessages(library(comparativeSRA))
genera_list <- list.files("~/phd/RNASeq/genera/")

genera <- "Acinetobacter"

for(genera in genera_list){
  print(genera)
  if(genera == "Escherichia"){
    next
  }
  
  
  accession_list <- list.files(paste("~/phd/RNASeq/genera/",  genera, "/", sep = ""), pattern = ".data$")
  accessionsDat <- data.frame(accession_list = accession_list)
  
  accessionsDat <- accessionsDat %>% mutate_all(as.character)
  accession_folder <-  accessionsDat$accession_list[1]
  
  
  for(accession_folder in accessionsDat$accession_list){
    accession <- unlist(strsplit(accession_folder, "\\."))[c(1,2)]
    accession <- paste(accession, collapse = ".")
    files <- list.files(paste("~/phd/RNASeq/genera/",  genera, "/", accession ,".data/plot_files/", sep = ""), pattern = ".plot$")
    
    filesDat <- data.frame(files = files)
    
    filesDat <- filesDat %>% filter(grepl(pattern = "ncRNA", x = files)==F,
                                    grepl(pattern = "fwd", x = files)==F,
                                    grepl(pattern = "rev", x = files)==F,
                                    grepl(pattern = accession, x = files)==F) %>% mutate_all(as.character)
    
    
    if(nrow(filesDat) == 0){
      next
    }
    print(accession)
    
    gffDat <- read.table(paste("~/phd/RNASeq/genera/",  genera, "/", accession ,".data/gff_files/", accession, ".gff", sep = ""), sep = "\t", fill = T, comment.char = "#", quote = "")
    colnames(gffDat) <- c("sequence", "source", "feature", "start", "end", "score", "strand", "phase", "Atrribute")
    
    regions <- gffDat %>% filter(feature == "region", start == "1") %>% select(sequence, start, end)
    
    current_pos <- 0
    for(i in 1:nrow(regions)){
      # print(regions$start[i])
      regions$end[i] <- regions$end[i] + current_pos
      regions$start[i] <- regions$start[i] + current_pos
      current_pos <- regions$end[i]
      
    }
    
    file_name <-  filesDat$files[1]
    
    for(file_name in filesDat$files){
      print(file_name)
      sra_id <- unlist(strsplit(file_name, "\\."))[1]
      
      plotFile <- read.table(paste("~/phd/RNASeq/genera/",  genera, "/", accession ,".data/plot_files/", file_name, sep = ""))
      
      
      
      
      
      
      cdsDat <- gffDat %>% filter(feature == "CDS")
      
      for(i in 1:nrow(regions)){
        contig <- regions$sequence[i]
        increase_val <- regions$start[i]
        cdsDat <- cdsDat %>% mutate(start = ifelse(sequence == contig, start + increase_val, start),
                                    end = ifelse(sequence == contig, end + increase_val, end))
        
      }
      
      
      
      positions <- cdsDat %>% select(sequence,start, end) %>% mutate(start = start - 149) %>% mutate(start = ifelse(start < 1, 1, start))  %>% mutate(end = end + 149) %>% mutate(end = ifelse(end > max(regions$end), max(regions$end), end))
      
      
      
      
      
      
      positions$new <- do.call(paste, c(positions, sep=":")) 
      positions$new <- Map(":", positions$start, positions$end)
      
      
      values <- unlist(positions$new[1:1000])
      
      
      positions <- data.frame(rowNum = values, type="CDS")
      
      starts <- data.frame(rowNum = cdsDat$start, type2 ="start")
      stops <- data.frame(rowNum = cdsDat$end, type2 ="stop")
      starts <- starts %>% mutate(rowNum = rowNum - 149) %>% mutate(rowNum = ifelse(rowNum < 1, 1, rowNum))
      stops <- stops %>% mutate(rowNum = rowNum + 149) %>% mutate(rowNum = ifelse(rowNum > max(regions$end), max(regions$end), rowNum))
      
      starts_and_stops <- starts %>% bind_rows(stops)
      
      positions <- positions %>% 
        left_join(starts_and_stops, by = "rowNum") %>% 
        mutate(type2 = ifelse(is.na(type2), "remove", type2))
      
      plotDat <- plotFile %>% mutate(value = ifelse(V1 > V2, V1, V2)) %>% select(value) %>% mutate(rowNum = row_number())
      
      plotDat <- plotDat %>% left_join(positions, by = "rowNum") %>% mutate(type2 = ifelse(is.na(type2), "intergenic", type2)) %>% 
        filter(type2 != "remove")
      
      
      plotDat <- plotDat %>% unique()
      
      
      
      plotDat <- plotDat %>% mutate(type = ifelse(is.na(type), "intergenic", "CDS"))
      
      total <- sum(plotDat$value)/1000000
      
      plotDat$value <- plotDat$value/total
      
      # save(plotDat, file = "~/phd/RNASeq/tmp/plotDat.Rda")
      # 
      # load("~/phd/RNASeq/tmp/plotDat.Rda")
      
      checkDat <- plotDat %>% filter(value > 15/total & type == "intergenic" )
      
      
      # checkDat <- data.frame(value = "0.04", rowNum = c(1,2,3,4,5,15,16,17,18,21,22,23,50,51,52,56,61,62,63,64,100,101,102,103),
      #                        type = "intergenic")
      # checkDat <- checkDat %>% mutate(type = ifelse(rowNum > 15 & rowNum < 30, "CDS", "intergenic"))
      
      plotDat <- checkDat
      
      callsDat <- data.frame(start = rep(as.character("0"), 20000), stop = rep(as.character("0"), 20000), stringsAsFactors = F)
      start <- 0
      stop <- 0
      current_feature <- F
      cds <- F
      id_pos <- 0
      
      
      i <- 1
      for(i in 1:nrow(plotDat)){
        printRemaining(i = i, length = nrow(plotDat))
        if(i == nrow(plotDat)){
          if(current_feature){
            if((plotDat$rowNum[i] - 25) < stop){
              stop <- plotDat$rowNum[i]
              if(plotDat$type[i] == "CDS"){
                cds <- T
              }
            }
            if(cds){
              current_feature <- F
              cds <- F
              next
            }
            id_pos <- id_pos + 1
            # print(paste(start,stop, id_pos))
            callsDat$start[id_pos] <- start
            callsDat$stop[id_pos] <- stop
            current_feature <- F
            cds <- F
          }
        }
        
        if(current_feature == F){
          start <- plotDat$rowNum[i]
          stop <- plotDat$rowNum[i]
          if(plotDat$type[i] == "CDS"){
            cds <- T
          }
          current_feature <- T
          next
        }
        
        if(plotDat$type2[i] == "stop"){
          stop <- plotDat$rowNum[i]
          cds <- T
          next
        }
        
        if((plotDat$rowNum[i] - 25) < stop){
          stop <- plotDat$rowNum[i]
          if(plotDat$type[i] == "CDS"){
            cds <- T
          }
          next
        }else{
          if(cds){
            current_feature <- F
            cds <- F
            start <- plotDat$rowNum[i]
            stop <- plotDat$rowNum[i]
            next
          }
          id_pos <- id_pos + 1
          # print(paste(start,stop, id_pos))
          callsDat$start[id_pos] <- start
          callsDat$stop[id_pos] <- stop
          current_feature <- F
          cds <- F 
        }
      }  
      
      
      
      
      
      
      combinedCalls <- callsDat %>% filter(start != 0) %>% mutate_all(as.numeric) %>% filter((stop - start) > 50)
      
      
      
      
      gffMain <- readLines(paste("~/phd/RNASeq/genera/",  genera, "/", accession ,".data/gff_files/", accession, ".gff", sep = ""))
      gffMain <- data.frame(text = gffMain)
      genomeInfo <- as.character(gffMain[8,1])
      genomeBuild <- as.character(gffMain[4,1])
      genomeSpecies <- as.character(gffMain[9,1])
      accession_contig <- strsplit(genomeInfo, " ")[[1]][2]
      
      
      
      gffFwd <- combinedCalls%>%mutate(strand = "+",
                                       source = "sraAlignedncRNAExpression",
                                       seqname = accession_contig,
                                       median.val = 0,
                                       feature = "ncRNA",
                                       frame = ".",
                                       attribute = paste("ID=rna_fwd_", row_number(), sep = ""))%>%
        select(seqname, source, feature, start, stop, median.val, strand, frame, attribute)
      
      
      
      
      fileConn<-file(paste("~/phd/RNASeq/genera/",  genera, "/", accession ,".data/gff_files/", sra_id, "_snra_calls.gff", sep = ""))
      writeLines(c("##gff-version 3",
                   "#!gff-spec-version 1.21",
                   "#!processor R script (local) with manual add of top section",
                   genomeBuild,
                   paste("#!genome-build-accession NCBI_Assembly:", "GCA_000017745.1", sep = ""),
                   paste("#!annotation-date ", Sys.Date(), sep = ""),
                   "#!annotation-source snraCalls (local version)",
                   genomeInfo,
                   genomeSpecies), fileConn)
      close(fileConn)
      
      print(paste("Writing to ~/phd/RNASeq/genera/",  genera, "/", accession ,".data/gff_files/", sra_id, "_snra_calls.gff", sep = ""))
      write.table(x = gffFwd, file = paste("~/phd/RNASeq/genera/",  genera, "/", accession ,".data/gff_files/", sra_id, "_snra_calls.gff", sep = ""), row.names = F, col.names = F, quote = F, sep = "\t", append = T)
      
      
      # plotDat <- plotDat %>% mutate(value = ifelse(is.na(type), value, 0))
      # 
      # 
      # outDat <- plotDat %>% select(value)
      # 
      # 
      # write.table(outDat, paste("~/phd/RNASeq/genera/",  genera, "/", accession ,".data/plot_files/", file_name, "_ncRNA_no_buffer.plot", sep = ""), quote = F, row.names = F, col.names = F)
    }
    
    
  }
}
```



##get_sRNA_sequences.py


```{python get_sRNA_sequences.py, eval=F, include=T}
#!/usr/bin/python
import sys
from Bio import SeqIO
from Bio.Alphabet import generic_dna
import getopt
import os



help = '''
    get_sRNA_sequences.py v 0.1 (August 2020) is a script for taking predicted sRNA regions and extracting the DNA sequence from 
    fasta files.
    Usage:
     get_sRNA_sequences.py <accession>
    
    Options:
        -h	Display this help
        -q  Supress messages
    Input
        -a	<accession> the genome accession to use for the input and output files

    
'''

def usage():
    print help

def rungetopts():
    try:
        opts, args = getopt.getopt(sys.argv[1:], "a:qh", ["accession", "quiet", "help"])
    except getopt.GetoptError as err:
        print(err)
        usage()
        sys.exit(2)
    accession = ""
    for o, a in opts:
            if o in ("-h", "--help"):
                usage()
                sys.exit()
            elif o in ("-a", "--accession"):
                accession = a
            else:
                assert False, "unhandled option"
    if accession == "":
        print "-a <accession> missing. For more help use -h"
        sys.exit(2)
    return(accession)

def main():

    accession = rungetopts()

    try:
        inFile = open("/Users/thomasnicholson/phd/RNASeq/new_calls/%s_new_calls.txt" % accession, 'r')
    except IOError:
        print "/Users/thomasnicholson/phd/RNASeq/new_calls/%s_new_calls.txt not found" % accession
        sys.exit(2)
    try:
        fastaFile = list(SeqIO.parse("/Users/thomasnicholson/phd/RNASeq/sequences/%s.fna" % accession, "fasta"))
    except IOError:
        print "/Users/thomasnicholson/phd/RNASeq/sequences/%s.fna not found" % accession
        sys.exit(2)


    write_path = "/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1"

    print "Combining contigs"
    my_seq = srna.concatenateSequence(fastaFile)

    print "Writing sequences"
    srna.writeSequences(inFile,my_seq,accession,write_path)


if __name__ == "__main__":
    main()






```

##get_random_srna_sequence.py

```{python get_random_srna_sequences.py, eval = F, python.reticulate = FALSE, echo=T}
#!/usr/bin/python

'''
file paths are hard coded
'''


import sys
from Bio import SeqIO
import getopt
import os
from BCBio import GFF
from Bio.Seq import Seq
from Bio.Alphabet import generic_dna
import random
import comparativeSRNA as srna


help = '''

'''

def usage():
    print help

def rungetopts():
    try:
        opts, args = getopt.getopt(sys.argv[1:], "a:sqh", ["accession", "shuffle", "quiet", "help"])
    except getopt.GetoptError as err:
        # print help information and exit:
        print(err) # will print something like "option -a not recognized"
        usage()
        sys.exit(2)
    accession = ""
    shuffled = False
    for o, a in opts:
            if o in ("-h", "--help"):
                usage()
                sys.exit()
            elif o in ("-a", "--accession"):
                accession = a
            elif o in ("-s", "--shuffle"):
                shuffled = True
            else:
                assert False, "unhandled option"
    if accession == "":
        print "-a <accession> missing. For more help use -h"
        sys.exit(2)
    return(accession, shuffled)


def main():

    accession, shuffled = rungetopts()
    print "Reading files"
    try:
        inFile = open("/Users/thomasnicholson/phd/RNASeq/new_calls/%s_new_calls.txt" % accession, 'r')

        fileLength = file_len("/Users/thomasnicholson/phd/RNASeq/new_calls/%s_new_calls.txt" % accession)
    except IOError:
        print "/Users/thomasnicholson/phd/RNASeq/new_calls/%s_new_calls.txt not found" % accession
        sys.exit(2)
    try:
        fastaFile = list(SeqIO.parse("/Users/thomasnicholson/phd/RNASeq/sequences/%s.fna" % accession, "fasta"))
    except IOError:
        print "/Users/thomasnicholson/phd/RNASeq/sequences/%s.fna not found" % accession
        sys.exit(2)

    print "Combining contigs"
    my_seq = srna.concatenateSequence(fastaFile)



    print "Getting intergenic sequence"
    random_seq = srna.intergenicSequence(accession, my_seq, shuffled)


    print "Getting intergenic positions"
    positions = srna.intergenicPositions(accession)

    print "Selecting random sRNAs"
    srna.selectRandomLocation(inFile, positions,fileLength, random_seq, accession)





if __name__ == "__main__":
    main()






```



##single_fasta_files.py

```{python single_fasta_files.py, eval = F}
#!/usr/bin/python
import sys
from Bio import SeqIO
import getopt
import os
from BCBio import GFF
from Bio.Seq import Seq
from Bio.Alphabet import generic_dna
import random
import pandas as pd
import comparativesrna as srna

help = '''
    {script_name} -c com_port [-o output_file] [--loglevel level]

    Reads the temperature data from a radio.  The temperature data is output in csv form.

    examples:
        Read table from radio attached to com4 and write the table to the file
        output.csv.

            {script_name} -c com4 -o output.csv

        Read table from radio attached to com3 and write the table to stdout. 
        You can use IO redirection to send the contents where every you want.

            # just print to the terminal 
            {script_name} -c com3

            # redirect to another file
            {script_name} -c com3 > somefile.csv

            # filter out temperatures that are -100
            {script_name} -c com3 | grep -v '^-100' 


    -c com_port
    --com_port comport
        Name of the COM port attached to the radio

    -o output_file
    --output output_file
        If specified write the table data to the given file.  If not specified
        the data will be written to stdout.

    --loglevel critical | error | warning | info | debug | notset
        Control the verbosity of the script by setting the log level.  Critical
        is the least verbose and notset is the most verbose.

        The default loglevel is {default_loglevel}.

        These values correspond directly to the python logging module levels. 
        (i.e. https://docs.python.org/3/howto/logging.html#logging-levels)


    -h 
    --help 
        print this message

'''

def usage():
    print help

def rungetopts():
    try:
        opts, args = getopt.getopt(sys.argv[1:], "i:f:qh", ["infile", "folder", "quiet", "help"])
    except getopt.GetoptError as err:
        # print help information and exit:
        print(err) # will print something like "option -a not recognized"
        usage()
        sys.exit(2)
    file = ""
    for o, a in opts:
            if o in ("-h", "--help"):
                usage()
                sys.exit()
            elif o in ("-i", "--infile"):
                file = a
            elif o in ("-f", "--folder"):
                folder = a
            else:
                assert False, "unhandled option"
    if file == "":
        print "-f <file> missing. For more help use -h"
        sys.exit(2)
    return(file, folder)

# def single_fasta(fastaFile, folder):
#     for seq in fastaFile:
#         id = seq.id
#         outname = id.split("[")
#         outname = outname[0]
#         my_seq = seq.seq
#         outFile = open("/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/%s/%s.fna" % (folder, outname), "w")
#         outFile.write(">%s\n%s\n" % (id, my_seq))



def main():

    filename, folder = rungetopts()
    print filename, folder
    print "Reading files"
    try:
        fastaFile = list(SeqIO.parse("/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/%s" % filename, "fasta"))
    except IOError:
        print "/Users/thomasnicholson/phd/RNASeq/srna_seqs/version_1/%s not found" % filename
        sys.exit(2)

    srna.single_fasta(fastaFile, folder)


if __name__ == "__main__":
    main()


```

##run_srna_nhmmer.sh

```{bash run_srna_nhmmer.sh, eval=F}
#!/bin/bash

# Setup Variables #

usage(){
    echo "run_sRNA_nhmmer.sh is a script for running nhmmer and sorting the results.  
Usage:
 run_sRNA_nhmmer.sh [opts] [input]

Required:	       
	-d	<database> The nucleotide database to be searched against as the nhmmer target
	-f	<folder> The folder containing the query file for nhmmer
	-e	<extension> The file extension of the query file in <folder>

Options:
	-h	Display this help
	-c	Check if the sequences are >50 nt (only works on fasta files)
"
}

check_seq_lengths=""
database=""
folder=""
extension=""
outfolder="."
missing=""
exitTrue="F"
evalue="1e-5"

# User Input Options #

while getopts "d:o:f:E:e:ch" arg; do
case $arg in
	d) 
	database=${OPTARG};;
	f)
	folder=${OPTARG};;
	o)
	outfolder=${OPTARG};;
	E)
	evalue=${OPTARG};;
	e)
	extension=${OPTARG};;	
	c)
	check_seq_lengths="T";;
    h)
		usage
		exit
      ;;    
	\?) 
	echo "Unknown option: -${OPTARG}" >&2; exit 1;;
    esac
done

# Tests for inputs #

if [[ $database == "" ]]; then
	missing="$missing -d <database> "
	exitTrue="T"
fi

if [[ $folder == "" ]]; then
	missing="$missing -f <folder> "
	exitTrue="T"	
fi

if [[ $extension == "" ]]; then
	missing="$missing -e <extension> "
	exitTrue="T"
fi

if [[ $exitTrue == "T" ]];then
	echo "$missing not found. Use -h for more help."
	exit
fi

if [[ $extension == "stk" ]]; then
	check_seq_lengths=""
fi

echo "extension value: $extension"

if [[ $check_seq_lengths == "T" ]]; then

	echo "checking for short seqs"
	mkdir -p $folder/short_seqs
	
	let "fileNum = 0"
	for file in $folder/*.$extension
	do
	
	seqlength=`grep -v ^">" $file | wc -c`
	if (( $seqlength < 50 )); then
	mv $file  single_seqs/short_seqs/
	fi
	
	done

fi

# Set up folders/files #

echo "making directories in `pwd`"
mkdir -p $outfolder/alignments
mkdir -p $outfolder/hmm
mkdir -p $outfolder/output

# Run nhmmer #

echo "running nhmmer"
let "fileNum = 0"
for file in $folder/*.$extension

do

echo $file
outname=`basename $file`


if [ -f "$outfolder/output/$outname.res" ]; then
	echo "Already exists: $file"
	continue
fi


nseqs=`esl-alistat $file | grep "Number of sequences" | cut -d ":" -f2`
length=`esl-alistat $file | grep "Alignment length:" | cut -d ":" -f2`
echo "Running nhmmer on $file (length: $length, nseqs: $nseqs)"


nhmmer -E $evalue --tblout $outfolder/output/$outname.tbl -A $outfolder/alignments/tmp.stk --tformat FASTA  $file $database > $outfolder/output/$outname.res

lines=`wc -l < $outfolder/alignments/tmp.stk`


if (( $lines > 0 )); then


##esl-weight!!!
esl-alimanip   --lnfract 0.8 --lxfract 1.2 --lmin 50 --lmax 500 --detrunc 30  $outfolder/alignments/tmp.stk | esl-alimask -g --gapthresh 0.8 -p --pfract 0.5 --pthresh 0.5 --keepins - > $outfolder/alignments/$outname



hmmbuild $outfolder/hmm/$outname.hmm $outfolder/alignments/$outname

else

echo "No hits found for $outname"

fi

done





```

